Paper_Id,Reference_Summary,Generated_Summary,ROUGE-1,ROUGE-2,ROUGE-L,BLEU
1,"This article presents a systematic overview of recent deep-learning-based models for multi-document summarization (MDS). It proposes a new taxonomy to categorize network design strategies and provides an overview of objective functions, evaluation metrics, and datasets. The article also discusses open problems and future research directions in the field. The survey aims to provide a comprehensive understanding of MDS tasks and highlight notable advances while shedding light on potential areas for further study.","We propose a taxonomy for organizing and clustering existing publications and devise the network design strategies based on the state-of-the-art methods . We also provide an overview of the existing multi-document objective functions, evaluation metrics, and datasets and discuss some of the most pressing open problems and promising future extensions in MDS research . Our survey, the first of its kind, systematically overviews the recent deep-learning-based MDS models . In this article, we have presented the first comprehensive review of the",0.6163522012578616,0.24203821656050953,0.32704402515723274,0.15710742561931904
2,"The article discusses the importance of text summarization due to the abundance of data available today. Various approaches, including abstractive and extractive methods, as well as query-based techniques, are presented. The paper focuses on structured and semantic-based approaches and discusses the datasets used for testing these methods. While the accuracy of the summaries generated using these methods can be compared, there is no specific model that generates the best summaries. The article suggests that GANs and transfer learning could be used to improve future text summarization models.","Text summarization has become very essential to gain just the right amount of information from huge texts . We see long articles in news websites, blogs, customers’ review websites, and so on. This review paper presents various approaches to generate summary of huge texts. We have seen the use of various algorithms and methods for this purpose. These methods, in individual and together give different types of summaries. Their accuracy score can be compared to find the better and more concise summary. For this purpose, ROGUE score has been used more frequently",0.3777777777777777,0.05617977528089887,0.23333333333333336,0.022227225137757864
3,The article presents a new framework for abstractive text summarization (ATS) called the LSTM-CNN based ATSDL model. This model uses a phrase extraction method called MOSP to extract key phrases from the original text and learns the collocation of phrases to generate a phrase sequence that meets the requirement of syntactic structure. The model also uses phrase location information to solve the rare words problem. Experimental results show that the ATSDL model outperforms existing state-of-the-art approaches in terms of both semantics and syntactic structure on two different datasets.,"Abstractive text summarization using LSTM-CNN based deep learningText mining . Abstractive Text Summarization (ATS), which is the task of constructing summary sentences by exploring more fine-grained fragments than sentences . Experimental results on the datasets CNN and DailyMail show that our ATSDL framework outperforms the state-of-the-art models in terms of both semantics and syntactic structure .",0.48,0.22972972972972971,0.36000000000000004,0.1485863819858312
4,"The paper proposes a method called DEXPERTS for controlled text generation by combining a pretrained language model with expert and anti-expert language models in a product of experts. The approach is applied to language detoxification and sentiment-controlled generation and outperforms existing controllable generation methods. The method is effective with small expert and anti-expert language models, and highlights the promise of tuning language models for efficient decoding-time steering towards safe and user-friendly generations.","DEXPERTS: Decoding-time Experts, Language detoxification, Sentiment-controlled generation, Pretrained language model, Ensemble learning, Small language models . Intuitively, tokens only get high probability if they are considered likely by the experts and unlikely by the anti-experts . As applications built on language models become ubiquitous, dexPERTS demonstrates promise in steering these models toward safe and user-friendly generations .",0.5037037037037037,0.24060150375939848,0.34074074074074073,0.09384487033069254
5,"The paper discusses the challenges in text-to-text generation and how incorporating internal and external knowledge can improve performance. The authors present a comprehensive survey of the research on knowledge-enhanced text generation in the past five years, covering general methods and specific techniques according to different forms of knowledge data. The survey aims to facilitate future research and help practitioners choose and employ methods for various text generation applications.","Various neural encoder-decoder models have been proposed to achieve the goal by learning to map input text to output text . However, the input text alone often provides limited knowledge to generate the desired output . This research topic is known as knowledge-enhanced text generation . In this survey, we present a comprehensive review of the research on this topic over the past five years . The main content includes two parts: (i) general methods and architectures for integrating knowledge into text generation; (ii) specific techniques",0.503225806451613,0.2222222222222222,0.2967741935483871,0.10218583954368957
6,"We used BERT and OpenAI GPT-2 pre-trained NLP models to perform text summarization on the COVID-19 Open Research Dataset Challenge corpus. Our model provides comprehensive information based on extracted keywords and can help the medical community by providing succinct summaries of articles for which abstracts are not available. Abstractive summarization is a challenging task, especially for technical, domain-specific corpora with limited training materials. However, we showed that a multi-loss training strategy could fine-tune a pre-trained language model such as GPT-2 to perform abstractive summarization, though still not at human-level performance. Further training could improve the model's accuracy with new publications becoming available.","COVID-19 Open Research Dataset Challenge has released a corpus of scholarly articles and is calling for machine learning approaches to help bridging the gap between the researchers and the rapidly growing publications . Abstractive summarization still represents a standing challenge for deep-learning NLP . The result is interpretable and reasonable, even though it is not near human-level performance . We think that our model could benefit from further training as the new coronavirus-related literature are becoming available .",0.4631578947368421,0.11702127659574468,0.2736842105263158,0.07666716909808637
7,"This research paper presents a Heart Disease Prediction System (HDPS) that uses data mining and artificial neural network techniques to predict the likelihood of a patient getting a heart disease. The system uses thirteen medical parameters including blood pressure and cholesterol, and two additional parameters, obesity and smoking, for better accuracy. The multilayer perceptron neural network model along with the back propagation algorithm is used for system development. The experimental results show that the system predicts heart disease with nearly 100% accuracy. This system can be a valuable tool for domain experts and healthcare providers to plan for better diagnoses and provide patients with early diagnosis results.","In this research paper, we have presented Heart disease prediction system (HDPS) using data mining and artificial neural network (ANN) techniques . The HDPS system predicts the likelihood of patient getting a Heart disease . For prediction, the system uses sex, blood pressure, cholesterol like 13 medical parameters . Here two more parameters are added i.e. obesity and smoking for better accuracy . From the results, it has been seen that neural network predict heart disease with nearly 100% accuracy.",0.6195652173913043,0.39560439560439553,0.5434782608695652,0.265348295653136
8,"The article discusses the use of natural language processing and sentiment classification using recurrent neural network to analyze sentiments and manifestations of Twitter users on the topic of COVID-19. The RNN model was able to accurately classify emotional polarity in ambiguous tweets and classify emotions into more articulated classes of emotional strength. The analysis showed that despite negative manifestations, overall positivity remained on social media during the pandemic. Comparisons were made against TextBlob, but the RNN model showed better results with less neutral results. The RNN model proved to be effective in categorizing emotions and making decisions even with small details.","In this work, we use a Recurrent Neural Network (RNN) to classify emotions on tweets . The trained model works much more accurately, with a smaller margin of error, in determining emotional polarity in today's ‘modern’ often with ambiguous tweets. We use this fresh scraped data collection based on the main trends (by keyword, which is mostly the ‘covid’ and coronavirus theme in this article) Where we analyse, compile, visualize statistics, and summarize",0.34285714285714286,0.0809248554913295,0.21714285714285717,0.02474856280130981
9,"The article discusses the extension of the Layer-wise Relevance Propagation (LRP) technique to recurrent neural networks, specifically those with multiplicative connections like LSTMs and GRUs. The extended LRP version was applied to a bi-directional LSTM model for sentiment prediction in sentences and produced better results than a gradient-based method. The technique is deterministic and self-contained, and can detect important patterns in text datasets. Future work includes applying the technique to other recurrent architectures and non-NLP applications.","Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions . We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent neural networks such as LSTMs, GRUs, sentiment prediction, word relevances, explanation methods . In the present work, we extend the usage of LRP to a word-based bi-directional model on a five-class sentiment prediction",0.4713375796178344,0.12903225806451615,0.2929936305732484,0.10388626066276554
10,"This study reviews the recent approaches to the medical applications of feature selection, which is a useful preprocessing tool that reduces the number of input features and helps practitioners in understanding the underlying causes of certain diseases. The study covers three main types of medical applications, including medical imaging, biomedical signal processing, and DNA microarray data analysis, and examines recent studies on applications. The suitability of applying feature selection in two real-world ophthalmology problems is also demonstrated. The study highlights the need for developing more sophisticated feature selection methods to handle Big Data and online feature selection methods to provide real-time feedback, which is still a challenge for researchers.","We reviewed the most recent feature selection methods developed for and applied in medical applications . This includes medical imaging, biomedical signal processing, and DNA microarray data analysis . We also demonstrated the suitability of applying feature selection in two real-world ophthalmology problems . In one case, feature selection outperformed previous classification results; in the second case, the feature selection reduced the computation time required to extract the image features that had previously prevented the real-time use of a computer-aided system .",0.5833333333333333,0.3263157894736842,0.42708333333333337,0.21976497247471852
11,"This review article examines the relationship between worry, generalized anxiety disorder (GAD), and cardiovascular function in both disease-free individuals and those with coronary heart disease (CHD). The study draws upon experimental and observational studies and investigates etiological and prognostic factors. The evidence suggests that worry and GAD are associated with diminished heart rate variability (HRV), elevated heart rate, blood pressure, diagnosed hypertension, and medication use. Measures of worry are also linked to fatal and nonfatal CHD. However, the association between worry, GAD, and established CHD is less clear. The research highlights the need for further investigation into the effects of GAD on CHD and cardiovascular risk, particularly as it disproportionately affects females. The study recommends greater attention to GAD research in CHD and its underlying cognitive processes.","aims of this review article are to present psychophysiological and behavioral pathways for the involvement of worry and generalized anxiety disorder (GAD) upon cardiovascular function . Articles (1975–2011) reporting on GAD or worry affecting CHD prognosis or cardiovascular function were found using MEDLINE, EMBASE, SCOPUS and PsychINFO database searches . Results: Available evidence in experimental and observational studies in CHD free samples consistently showed that worry was associated with diminished heart rate variability .",0.44000000000000006,0.18181818181818182,0.24000000000000005,0.0894013234010382
12,"This systematic review discusses the prevalence of oropharyngeal dysphagia in neurological patients and its serious health threats, including aspiration pneumonia. Early identification and accurate diagnosis of this condition are crucial. The review focuses on available bedside screenings for oropharyngeal dysphagia in neurological patients and identifies two relevant screenings with minimum sensitivity and specificity of 70% and 60%, respectively. The review stresses the importance of considering methodological study quality, psychometric screening characteristics, and workplace-related criteria to determine the most suitable screening tool. No single bedside screening can be considered superior without taking all these factors into account.","Bedside Screening to Detect Oropharyngeal Dysphagia in Patients with Neurological Disorders: An Updated Systematic ReviewBedside screening , Videofluoroscopy, Fiberoptic endoscopy , Psychometrics , Deglutition disorders .Oropharyndgeal dysphagya is a highly prevalent comorbidity in neurological patients and presents a serious health threat . An early identification of risk followed by an accurate diagnosis is fundamental .",0.3401360544217687,0.13793103448275862,0.17687074829931973,0.03930660586741136
13,"This study aimed to assess the birth prevalence and spatial distribution of congenital heart disease (CHD) in China using spatial epidemiological methods. The researchers conducted unrestricted searches on seven electronic databases, collected data on the birth prevalence of CHD and its subtypes, and performed subgroup sensitivity analyses. The study found that the total CHD birth prevalence in China had increased continuously over the past 40 years, with significant differences in gender, geographic regions, income levels, and monitoring models. The researchers suggested the need for population-wide prospective birth defect registries covering the entire Chinese population to determine the exact birth prevalence of CHD.","Total CHD birth prevalence increased continuously over time, from 0.201 in 1980–1984 to 4.905 in 2015–2019 . Significant differences in gender, geographical regions, income levels, and monitoring models were found for birth prevalence of CHD . In the future, population wide prospective birth defect registries covering the entire Chinese population need to determine the exact birth prevalence . The solid line is the estimated birth prevalence, and dotted lines represent the 95% confidence intervalRecords identified through database searching .",0.5934065934065935,0.4000000000000001,0.39560439560439553,0.2735290600470334
14,"The prevalence of stroke is higher than that of coronary heart disease (CHD) in Asian countries, possibly due to a higher prevalence of hypertension and lower serum total cholesterol levels. The population-attributable fraction of hypertension for CVD is high in Asian countries, and reduction in salt consumption is important for reducing CVD, especially stroke. Smoking is also a significant risk factor for CVD in most Asian countries, especially for men. Recent westernization in Asian countries has increased fat consumption, which may have caused an increase in CHD. Management of traditional risk factors for CVD, including hypertension, smoking, and obesity, is essential for the prevention of CVD in Asian and Western countries.","Asian countries and regions such as Japan, the Republic of Korea, the People’s Republic of China, Hong Kong, Taiwan, and the Kingdom of Thailand have greater mortality and morbidity from stroke than from coronary heart disease (CHD) Despite this increase, the specific characteristic of lower CHD incidence and mortality for CVD is as high as 60% in Asian countries . In Asian countries, stroke is most likely due to a higher prevalence of hypertension and a lower level of serum total cholesterol .",0.5051546391752576,0.21875,0.25773195876288657,0.1613289179352157
15,"Pre-eclampsia, a common complication of pregnancy, is associated with an increased risk of cardiovascular disease (CVD), cerebrovascular events, and hypertension later in life. This systematic review and meta-analysis analyzed 50 articles to quantify the risks associated with pre-eclampsia. Women with a history of pre-eclampsia or eclampsia were at significantly increased odds of fatal or diagnosed CVD, cerebrovascular disease, and hypertension. Among pre-eclamptic women, pre-term delivery was not associated with an increased risk of future cardiovascular events. The increased risk of CVD may reflect shared common risk factors for both pre-eclampsia and cardiovascular and cerebrovascular disease. Women who experience pre-eclampsia should be aware of their increased risk and may benefit from formal postnatal screening for accepted risk factors for CVD.","Pre-eclampsia is associated with an approximate twofold increase in odds of CVD and cerebrovascular disease, with an estimated doubling of odds compared to unaffected women . This association may reflect shared common risk factors . Women with a history of . pre-employees are at significantly increased risk of future cardiovascular . or hypertension . Medline and Embase were searched with no language restrictions, as were core journals and reference lists .",0.4742268041237113,0.2604166666666667,0.27835051546391754,0.12735544587481976
16,"Childhood interstitial lung disease (chILD) is a rare and complex group of disorders with variable pathology, morbidity, and mortality. There is a lack of consensus on chILD classification, which hinders the consolidation of research evidence. The incidence of chILD is estimated to be 0.13-16.2 cases/100,000 children/year, with a median mortality rate of 13% in developed countries. Corticosteroids and hydroxychloroquine are commonly used treatments. There is a need for active disease surveillance, international patient registries, and randomized controlled intervention trials to advance the understanding and management of chILD. Additionally, studies that go beyond subjective outcomes and describe quality of life, as well as the impacts of chILD on families and health services, are necessary. Determining the burden of chILD on health services requires descriptive statistics beyond simply counting the number of cases.","The incidence of chILD has been estimated at 0.13–16.2 cases/100,000 children/year . One to five new cases presented to individual hospitals each year . In developed countries, the median mortality was 13% (6–19%) . childhood interstitial lung disease is a group of rare chronic and complex disorders of variable pathology . There has been no systematic review of published research .",0.42000000000000004,0.21212121212121213,0.22999999999999998,0.039779587869350895
17,"This study aimed to investigate the neurological manifestations and evidence of neurological involvement in COVID-19 through a systematic review of published articles on the topic. The study found a wide spectrum of neurological symptoms in COVID-19 patients, with fatigue, anorexia, dyspnea/shortness of breath, and malaise being the most common unspecific symptoms. Olfactory and gustatory disorders were also prevalent, particularly in mild cases. The study also found evidence supporting neurologic involvement of COVID-19 through laboratory, electrophysiological, radiological, and pathological evidence. The study concludes that neurological involvement in COVID-19 is an important aspect of the disease that is often underestimated and calls for more clinical and experimental research to explore its underlying mechanisms and role in disease progression.","Clinical manifestations and evidence of neurological involvement in COVID-19 . The meta-analysis for unspecific neurological symptoms revealed that the most common manifestations were fatigue (33.2% [23.1–43.3]), anorexia (30.0% [23.2–36.9]), dyspnea/shortness of breath (26.9% [19.2–34.6]), and malaise (27.7% [13.3–40.1]). Emerging clinical evidence suggests neurological involvement is an important aspect of the",0.4021164021164021,0.2245989304812834,0.30687830687830686,0.12105055852610769
18,"This systematic review of literature explores the potential and challenges of applying Big Data analytics in healthcare. The review considers articles published in English language literature from January 2013 to January 2018 and identifies the sources and applications of Big Data analytics in healthcare, the techniques used, and the challenges to its adoption. The study finds that Big Data analytics has the potential to improve the quality of care, reduce waste and error, and reduce the cost of care. However, researchers lack consensus on the definition of Big Data in healthcare, and there is a paucity of evidence of real-world use. The review concludes that Big Data analytics has emerged as a new frontier for enhancing healthcare delivery, and its application will maximize healthcare value through promoting the extensive usage of insights.","A systematic review of literature aims to determine the scope of Big Data analytics in healthcare including its applications and challenges in its adoption in healthcare . A systematic search of the articles was carried out on five major scientific databases: ScienceDirect, PubMed, Emerald, IEEE Xplore and Taylor & Francis . Big Data Analytics increasingly provides value to healthcare by improving healthcare quality and outcomes and providing cost-effective care . The predictive nature and pattern-recognition aspect of BigData analytics enable the shift from experience-based medicine to evidence-based",0.44545454545454544,0.12844036697247704,0.2909090909090909,0.0797238822082702
19,"This study reviewed 14 research articles published in 2020 that used machine learning algorithms for investigating and dealing with COVID-19. The study found that machine learning has an important role in COVID-19 investigations, prediction, and discrimination, and can be involved in health provider programs and plans. The review showed that supervised learning algorithms, particularly logistic regression, had better results than unsupervised learning algorithms in detecting COVID-19 cases. The study concludes that machine learning applications in medicine showed promising results with high accuracy, sensitivity, and specificity using different models and algorithms.","The purpose of this study is to detect the role of machine-learning applications and algorithms in investigating and various purposes that deals with COVID-19 . The total articles obtained were 16,306 overall but after limitation; only 14 researches of these articles were included in this study . In the future recurrent supervised learning can be used for superior accuracy by having 92.9% testing accuracy . Our findings show that machine learning can produce an important role in COVD-19 investigations, prediction, and discrimination .",0.5084745762711865,0.26285714285714284,0.28248587570621464,0.13789330960596688
20,"This review article provides an overview of diffusion-tensor imaging (DTI) as a noninvasive medical imaging tool used to investigate the structure of white matter. DTI scalars, such as FA, AD, RD, MD, and MO, can be used to evaluate changes in brain tissue caused by various neurological diseases, including amyotrophic lateral sclerosis, multiple sclerosis, Parkinson’s disease, Alzheimer’s dementia, epilepsy, ischemic stroke, traumatic brain injury, spinal cord injury, and depression. The review also highlights the importance of suitable DTI postprocessing tools for clinical research, including advanced robust postprocessing techniques that yield novel anatomical and structural pathway information about the brain. The article concludes that improvements in DTI acquisition techniques and standardization of postprocessing methods will ensure the utilization of DTI in clinical research and even as a diagnostic tool.","Diffusion-tensor imaging (DTI) is a noninvasive medical imaging tool used to investigate the structure of white matter . The signal contrast in DTI is generated by differences in the Brownian motion of the water molecules in brain tissue . Postprocessed DTI scalars can be used to evaluate changes in the brain tissue caused by disease, disease progression, and treatment responses . Advanced robust postprocessing techniques have yield novel anatomical and structural pathway information about the brain .",0.5560975609756097,0.3842364532019705,0.45853658536585357,0.20435550736880573
21,"This study provides a systematic review of published information on the use, effectiveness, and adverse effects of cyclophosphamide (CYC) in the management of idiopathic inflammatory myopathies (IIM) and IIM-related interstitial lung disease (IIM-ILD). The study analyzed 12 non-randomized studies that used intravenous CYC (IVCYC) in 11 of the studies to treat IIM. The analysis showed that IVCYC treatment improved muscle strength and function, CK levels, pulmonary function, and HRCT lung images in refractory IIM and IIM-ILD patients. It also improved survival rates among patients with acute or subacute ILD. However, there were adverse effects, including 18 deaths due to diffuse alveolar damage (DAD), with a ground glass (GrG) pattern found in 66.7% of the deaths. The conclusion suggests that CYC may be an effective immunomodulatory agent in managing IIM and IIM-related ILD, but large-sample, double-blind, placebo-controlled studies are needed to confirm this conclusion.","The purpose of this study is to review and summarize published information on the use, effectiveness, and adverse effects of cyclophosphamide (CYC) in the management of idiopathic inflammatory myopathies (IIM) and IIM-related interstitial lung disease . The initial search involved 310 articles, and the 12 articles that met the study criteria were analyzed in detail . All studies were non-randomized .",0.43396226415094336,0.26666666666666666,0.3490566037735849,0.11220059270344687
22,"The paper reviews recent developments in wearable sensors for health monitoring and provides an overview of the latest data mining techniques used to analyze data from such sensors for physiological monitoring. The paper outlines common data mining tasks such as anomaly detection, prediction, and decision making in continuous time series measurements, and describes the suitability of particular data mining and machine learning methods used to process physiological data. The review also highlights key challenges for data mining methods in health monitoring systems, and discusses data sets and their properties, including time horizon, scale, and labeling. The study concludes by addressing future challenges in data mining for wearable sensors in healthcare.",Data Mining for Wearable Sensors in Health Monitoring Systems: A Review of Recent Trends and Challengesdata mining; wearable sensors; healthcare; physiological sensors; health monitoring system; machine learning technique; vital signs; medical informatics . This increase has been due to several factors such as development in sensor technology as well as directed efforts on political and stakeholder levels to promote projects which address the need for providing new methods for care given increasing challenges with an aging population . An important aspect of study in such system is how the data is treated and,0.4577114427860696,0.13065326633165827,0.20895522388059704,0.08748160105596596
23,"This article discusses the use of machine learning techniques to forecast repeat visits to emergency departments (EDs) by utilizing patient data from electronic health records and health information exchange. The study suggests that utilizing patients' longitudinal data and integrating information from distributed sources can enhance risk prediction at the point of care. The study utilizes hidden Markov models (HMMs) to capture the relationships between observed and hidden progressions over time through a series of hidden states, and applies pre-analysis of patient data using latent class models to improve the performance of the prediction models. The article suggests that leveraging patients' longitudinal data is a prospective approach to advanced risk prediction and provides a methodological and practical contribution to the field. Future research should explore the application of these techniques to other points of care besides the ED and test additional latent class models to generalize the findings.","Data mining techniques utilizing latent class models to evaluate emergency department revisitsHidden Markov Models , Emergency department revisit , Electronic health records , Predictive analytics . The use of machine learning techniques is especially pertinent to the composite and challenging conditions of emergency departments (EDs) Repeat ED visits (i.e. revisits) are an example of potentially inappropriate utilization of resources that can be forecasted by these techniques . We carried out forecasting of future ED revisits with various data mining models .",0.375,0.13513513513513514,0.19642857142857142,0.07745911260948712
24,"The article discusses how deep learning can revolutionize modern medicine by analyzing the massive volume of electronic data compiled by hospital systems. The clinical neurosciences are particularly well positioned to benefit from deep learning algorithms due to the subtle presentation of symptoms typical of neurologic disease. The article reviews the various domains in which deep learning algorithms have already provided impetus for change, including medical image analysis, connectome mapping, and mining of microscopic EEG signals and granular genetic signatures. However, important challenges remain a barrier to integration of deep learning tools in the clinical setting, such as data privacy, accessibility, ownership, and data quality. The article concludes that interdisciplinary teams of physicians, computer scientists, engineers, legal experts, and ethicists working in concert can overcome these hurdles to truly realize the potential of deep learning in medicine to augment the capability of physicians and enhance patient care delivery.","Deep learning is uniquely suited to address these challenges, and recent advances in techniques and hardware have poised the field of medical machine learning for transformational growth . The clinical neurosciences are particularly well positioned to benefit from these advances given the subtle presentation of symptoms typical of neurologic disease . Here we review the various domains in which deep learning algorithms have already provided impetus for change . We also note important challenges in the integration of deep learning tools in the clinical setting and discuss the barriers to tackling the challenges that currently exist .",0.5416666666666666,0.3529411764705882,0.44166666666666665,0.22556241380097686
25,"This review discusses the application of machine learning algorithms, particularly convolutional neural networks, in medical image analysis. It highlights the advantage of machine learning in discovering hierarchal relationships within medical big data without laborious hand-crafting of features. The review covers various research areas and applications of medical image classification, localization, detection, segmentation, and registration. However, the lack of publicly available and high-quality labeled data is a major challenge in medical image analysis. Despite this, satisfactory performance is reported in various tasks with small training datasets. The review concludes by discussing research obstacles, emerging trends, and possible future directions, including new areas of research such as prognostication, content-based image retrieval, and manipulation of physical objects with LSTMs and reinforcement learning. An interesting application involves the use of GANs to generate CT brain images from MRI images, potentially avoiding ionizing radiation from a CT scanner altogether and improving patient safety.","The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging . We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration .We conclude by discussing research obstacles, emerging trends, and possible future directions . In general computer vision tasks, attempts have been made to circumvent limited data by using smaller filters on deeper layers .",0.3947368421052631,0.2300884955752213,0.2982456140350877,0.14499823344087207
26,"The paper discusses the limited applications of deep learning models in clinical decision-support systems despite recent developments in the field. It highlights the growing use of electronic health records (EHR) for personalised prediction of risks and health trajectories and provides a comparative review of key deep learning architectures that have been applied to EHR data. The paper introduces the Clinical Practice Research Datalink (CPRD) as a new asset for training data-hungry models, provides a guideline for working with EHR data for deep learning, and shares best practices for assessing the goodness of deep-learning models in clinical risk prediction. The paper concludes that recurrent neural networks are better suited to deal with the temporal nature of EHR data and proposes future research ideas for making deep learning models more suitable for EHR data from different healthcare systems.","Recent digitalisation of health records has provided a great platform for the assessment of the usability of such techniques in healthcare . As a result, the field is starting to see a growing number of research papers that employ deep learning on electronic health records (EHR) for personalised prediction of risks and health trajectories . This can be a promising trend, but vast paper-to-paper variability (from data sources and models they use to the clinical questions they attempt to answer) have hampered the field’s ability",0.43555555555555553,0.14349775784753363,0.25777777777777783,0.11425276609832681
27,"This study analyzes the research growth and current understandings of depression among HIV-infected individuals, which has become an urgent issue. The study shows that depression is common among HIV patients, and it is associated with poor health outcomes. The research landscape in this field includes risk behaviors, causes of depression, effects of depression on health outcomes, and interventions for PLWH. The study also identifies a lack of empirical studies in countries where PLWH face a high risk of depression and a modest level of interest in biomedical research. The study suggests that more efforts should be made to fulfill the research gaps, especially in developing countries and biomedical investigation on the correlation between HIV and depression.","In this study, we analyzed research growth and current understandings of depression among HIV-infected individuals . The number of papers and their impacts have been considerably grown in recent years, and a total of 4872 publications published from 1990–2017 were retrieved from the Web of Science database . We identified a lack of empirical studies in countries where PLWH face a high risk of depression . This study provides a basis for future studies and interventions in addressing the critical issue of HIV epidemics .",0.5,0.29292929292929293,0.4,0.20745302443220728
28,"This paper discusses the use of machine learning techniques, specifically the Heterogeneous Modified Artificial Neural Network (HMANN), for the early detection and diagnosis of chronic kidney disease (CKD) using ultrasound images on the Internet of Medical Things (IoMT) platform. The proposed algorithm achieves high accuracy in kidney segmentation and significantly reduces the time for delineating the contour. The paper also includes a discussion of the importance of feature selection in classification algorithms and the use of support vector machine, artificial neural networks, and multilayer perceptron classifiers. The paper concludes that the proposed HMANN method helps to reduce noise and segment kidney images for clear identification of kidney stone location and improves the accuracy of CKD detection.","HMANN is classified as a Support Vector Machine and Multilayer Perceptron (MLP) with a Backpropagation algorithm . In kidney segmentation, the proposed method achieves high accuracy and significantly reducing the time to delineate the contour . This paper presents a deep learning-based Heterogeneous Modified Artifical Neural Network (HMANN) method for the detection of chronic kidney disease . There are some noisy and complexity during image segmentation .",0.5111111111111112,0.2696629213483146,0.28888888888888886,0.08595644905730046
29,"This paper analyzes the economic impact associated with HIV/AIDS in a European context by conducting a systematic literature review for five different countries. The study includes 26 papers containing 76 cost estimates, most of which analyze the health care costs of treating HIV/AIDS. The study finds a high degree of variability in estimated annual costs per patient across countries, and a great disparity in total health care costs for patients with different disease stages. Few studies have estimated the non-medical costs of HIV/AIDS, despite its potential impact on productivity losses and cost of care. The study concludes that there is a need for improvement in the methodology used in many of the studies carried out and for these studies to reflect the economic impact of HIV/AIDS beyond health care. Lastly, the paper emphasizes the importance of reflecting the social burden of the disease beyond the healthcare realm.","The HIV/AIDS disease represent a priority for all health authorities in all countries and it represents serious added socioeconomic problems for societies over the world . We conducted a systematic literature review for five different countries (France, Germany, Italy, Spain and United Kingdom) and searched five databases. Three types of analyses were undertaken: descriptive statistics; quantitative analysis to calculate mean costs; and comparison across countries . Most of the studies analyzed the health care cost of treatment . Only 50% of the cost estimates provided mean lymphocyte count describing the patient’",0.35684647302904565,0.17573221757322174,0.22406639004149378,0.07759506665351588
30,"This article provides a comprehensive review of the latest deep learning practices in the detection and diagnosis of colon cancer. It starts with an overview of popular deep learning architectures used in colon cancer analysis, followed by a collection of all studies related to colon cancer analysis and their division into five categories: detection, classification, segmentation, survival prediction, and inflammatory bowel diseases. The article provides detailed summaries of the studies in each category and lists them in tables for a more detailed comparison, including datasets, imaging techniques, and results. The article concludes by discussing the successes and challenges of deep learning in colon cancer analysis and providing suggestions for future research, such as increasing the number of public datasets and establishing common experimental setups and evaluation criteria. Overall, this article is a useful resource for researchers interested in using deep learning techniques for the diagnosis of colon cancer.","In this article, we hope to bring a perspective to progress in this area by reviewing deep learning practices for colon cancer analysis . We gathered all the works together and organized them into five main categories . These categories are listed as follows according to the number of studies conducted: detection, classification, segmentation, survival prediction, and inflammatory bowel diseases . This study differs from other studies by including 135 recent academic papers, separating colon cancer into five different classes .",0.4,0.15246636771300448,0.2488888888888889,0.10671015962576617
31,"This paper reviews current methods for building cancer risk models using structured clinical patient data, exploring trends in statistical and machine learning techniques. The importance of cancer risk prediction models is highlighted, as they can inform patient screening and treatment patterns, potentially improving patient outcomes and reducing healthcare costs. The paper identifies gaps in the transfer of point-of-care data and suggests that advanced modeling methods using state-of-the-art machine learning techniques must be employed for future research. The paper concludes that research must continue in this area for these models to be embraced for clinical decision support of both practitioners and patients.","A review of statistical and machine learning methods for modeling cancer risk using structured clinical dataCancer prediction , Cancer recurrence , Data mining , Electronic health records . To help reduce the impact and deadlines of cancers, they must be detected early . Additionally, there is a risk of cancer recurring after potentially curative treatments are performed . For large-scale predictive models to be built, structured data must be captured for a wide range of diverse patients . The key impact of these models is reducing costs ",0.45989304812834225,0.15135135135135133,0.23529411764705882,0.0670594155292511
32,"This paper explores the use of deep learning techniques in healthcare systems to analyze and uncover meaningful information from large amounts of data. The focus is on disease detection in preprocessing, feature extraction, feature selection, classification, and clustering steps. The paper evaluates the technical aspects of machine learning and deep learning architectures, including the accuracy of disease detection and algorithm parameters. The top architectures of deep learning methods applied to healthcare are also analyzed and discussed. The potential of hybrid and ensemble methods is highlighted, but the challenges of memory and time consumption are noted. Future research efforts should focus on developing efficient technologies and improving neural network models, as well as implementing explainable artificial intelligence in distributed systems. Overall, the paper concludes that deep learning models have tremendous potential in medicine and healthcare systems, given the complexity of health data.","In the last few years, the application of Deep Neural Network (DNN) models have become more attractive in the healthcare system given the rising complexity of the healthcare data . Machine Learning algorithms provide efficient and effective data analysis models to uncover hidden patterns and other meaningful information from the considerable amount of health data that conventional analytics are not able to discover in a reasonable time . In this paper, we focused on those problems in healthcare that have been addressed using deep learning with promising results .",0.4405286343612335,0.14222222222222222,0.18502202643171803,0.019315896399797368
33,"The article highlights the importance of identifying and diagnosing obesity as early as possible due to its negative impact on public health. The use of machine learning techniques for the prevention and treatment of obesity is promising as it can offer quick and accurate identification of risk factors and condition likelihoods. The study reviews 93 papers from 2010 to 2020 and identifies significant potential factors that influence and cause adult obesity, main diseases and health consequences of obesity and overweight, and machine learning methods that can be used for the prediction of obesity. The article concludes that obesity is a healthcare concern and epidemic worldwide and deserves serious consideration from policymakers, healthcare providers, and researchers alike. Obesity prevention must be multifaceted and should actively involve stakeholders at different levels, including individual lifestyle changes.","Obesity is considered a principal public health concern and ranked as the fifth foremost reason for death globally . Overweight and obesity are one of the main lifestyle illnesses that leads to further health concerns and contribute to numerous chronic diseases . The World Health Organization also predicted that 30% of death in the world will be initiated with lifestyle diseases in 2030 . Therefore, the machine learning approach is a promising solution to early predictions of obesity and the risk of overweight because it can offer quick, immediate, and accurate identification of risk factors and condition likelihoods ",0.46491228070175433,0.17699115044247787,0.21052631578947367,0.11237778601890552
34,"The paper provides an overview of deep learning methods for multimodal medical data analysis, which has become increasingly popular due to the success of deep learning algorithms in various fields. The paper explains the popular modalities, fusion strategies, deep learning architectures, and learning strategies such as transfer learning, end-to-end learning, and multitask learning. The authors review articles published in the last four years and divide them into supervised, semi-supervised, self-supervised, and unsupervised methods. They conclude that multimodal data improve neural networks' performance by providing complementary information, and transfer learning is valuable when data is limited, such as during a pandemic. The paper also identifies common problems and open challenges in this field and provides links to some of the most well-known multimodal datasets. The authors believe that deep learning methods in multimodal medical data analysis will remain an active research area in the coming years.","Deep learning methods have achieved significant results in various fields . This paper introduces the most popular modalities, fusion strategies, and deep learning architectures . We also explain learning strategies, including transfer learning, end-to-end learning, and multitask learning . Then, we give an overview of the current state-of-the-art, common problems, and directions for future research. We conclude transfer learning methods are invaluable in situations such as pandemics when not enough data is available.",0.4711111111111111,0.25112107623318386,0.32,0.11545503321352175
35,"This paper provides a review of deep learning techniques applied to 2-D fundus and 3-D Optical Coherence Tomography (OCT) retinal images for automated classification of retinal landmarks, pathology, and disease classification. The authors discuss the importance of early detection and prevention of retinal diseases, and how deep learning algorithms can aid in this process. They analyze the methodologies in terms of sensitivity, specificity, accuracy, and F score on publicly available datasets, and conclude that while deep learning has shown promise in retinal image analysis, there is still much progress to be made. They suggest that deep neural networks (DNNs) can be efficiently applied for segmentation of various retinal pathologies, and that DNNs have the potential to replace traditional ophthalmologic screening practices.","De-noised sparse auto-encoder , Softmax , Random forest , Rectified linear unit , Hidden layers. Automated identification of retinal diseases is a big step towards early diagnosis and prevention of exacerbation of the disease . A number of state-of-the-art methods have been developed in the past that helped in the automatic segmentation and identification . The current unprecedented advancements in deep learning and modern imaging modalities in ophthalmology have opened a",0.310880829015544,0.05235602094240837,0.1761658031088083,0.014335976213146888
36,"This paper comprehensively reviews the role of Machine Learning (ML) and Artificial Intelligence (AI) in screening, predicting, forecasting, contact tracing, and drug development for SARS-CoV-2 and its related epidemic. The review shows that the use of modern technology with AI and ML dramatically improves the screening, prediction, contact tracing, forecasting, and drug/vaccine development with extreme reliability. Majority of the paper employed deep learning algorithms and is found to have more potential, robust, and advance among the other learning algorithms. However, the current urgency requires an improved model with high-end performance accuracy in screening and predicting the SARS-CoV-2 with different kinds of related disease by analyzing the clinical, mammographic, and demographic information of the suspects and infected patients. Finally, it is evident that AI and ML can significantly improve treatment, medication, screening & prediction, forecasting, contact tracing, and drug/vaccine development for the Covid-19 pandemic and reduce the human intervention in medical practice.","The evidence of Machine Learning (ML) and Artificial Intelligence (AI) application on the previous epidemic encourage researchers by giving a new angle to fight against the novel Coronavirus outbreak . This paper addresses on recent studies that apply ML and AI technology towards augmenting the researchers on multiple angles . It also addresses a few errors and challenges while using such algorithms in real-world problems . The paper also discusses suggestions conveying researchers on model design, medical experts, and policymakers in the current situation .",0.29999999999999993,0.08403361344537814,0.18333333333333332,0.06740429421698467
37,"This review analyzes the application of deep learning in medical diagnosis and concludes that deep learning methods have a wide range of applications in the medical field, particularly in bioinformatics, medical diagnosis, and similar fields. The review notes that convolutional neural networks are the most widely represented in deep learning and medical image analysis. While deep learning technology is widespread, the majority of its applications are focused on medical diagnosis. The review suggests that deep learning methods can be superior to other high-performing algorithms and will continue to diversify their uses, particularly in the domain of medical diagnosis. However, deep learning cannot replace the role of doctors/clinicians in medical diagnosis, but can provide good support for experts in the medical field. Additionally, the review suggests that deep learning will find many other uses in various fields in the near future.","A thorough analysis of various scientific articles in the domain of deep neural networks application in the medical field has been conducted . More than 300 research articles were obtained, and after several selection steps, 46 articles were presented in more detail . The results indicate that convolutional neural networks (CNN) are the most widely represented when it comes to deep learning and medical image analysis . In this case, medical diagnosis is conducted through use-cases of deep learning networks .",0.37272727272727274,0.20183486238532108,0.2818181818181818,0.107605836549257
38,"This review discusses the application of deep learning in medical data analysis. It highlights the need for scientific decision-making in the diagnosis and treatment of diseases using massive medical information resources. The review explores the scope, characteristics, and structure of heterogeneous medical data and discusses various deep learning models involved in medical data analysis, including their variants and hybrid models. The review also examines different tasks in medical data analysis and provides a brief introduction to useful online resources of deep learning development tools. Deep learning has shown promising results in medical data analysis, but there are challenges such as the lack of solid theoretical basis and the need for considerable skill and experience in configuring deep networks. Furthermore, deep learning technology cannot completely replace other technologies, and exploring the combination of deep learning and traditional models can lead to new models and algorithms for large-scale problems. Overall, deep learning is a powerful technology that can provide abstract level representations of static data, sequence data, and decision-making data.","Deep learning for heterogeneous medical data analysis has been effectively applied in many fields and has outperformed most of the machine learning methods . In this survey, we focus on reviewing and then categorizing the current development . Deep learning is a powerful technology to realize complex medical data analyses tasks, including variants and various hybrid models . The main advantage of deep model is that when the node size of the deep network remains roughly unchanged, more powerful function expression can be obtained by increasing the number of node layers .",0.3706563706563707,0.11673151750972763,0.23938223938223935,0.055395087812893734
39,"This study explores the emerging applications of deep learning technology in cancer imaging, highlighting its potential to improve the detection and classification of cancer in its early stages. The study discusses the trajectory of deep learning technology in cancer imaging research and its potential to revolutionize cancer management through new and effective diagnostic approaches. However, the study also notes that further research is needed to determine the feasibility of applying deep learning technology in different clinical settings and to determine whether its use can improve healthcare and efficiency in hospitals and research labs. The study acknowledges that the results and arguments presented are tentative and subject to the Amara's law, which suggests that the short-term effects of a new technology may be overestimated while the long-term effects may be underestimated.","Deep learning technology is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior . Applications of deep learning technology to cancer imaging can assist pathologists in the detection and classification of cancer in the early stages of its development . This new technology can also generate benefits for poor regions because they can send digital images to labs of other developed regions to have diagnosis of cancer types, reducing as far as possible current gap in healthcare among different regions .",0.41409691629955947,0.13333333333333333,0.22026431718061673,0.09725435520159001
40,"This study presents a novel approach to designing a multiepitope vaccine against Hepatitis C Virus (HCV) using immunoinformatics and molecular docking. The study identified 17 conserved epitopes from eight viral proteins and linked them together using a linker and adjuvant to enhance immunogenic potential. The modeled structure was successfully docked to antigenic receptor TLR-3, and in-silico cloning confirmed the expression efficiency. However, the proposed construct needs further experimental validation to ensure its safety and immunogenic profile. This approach offers a template for research on other emerging viruses and their subtypes. The study concludes that the multiepitope vaccine designed may contribute to the control and prevention of HCV.","HCV vaccines eliciting specific T-cell responses, have been considered potent method to prevent HCV infection . In this study we integrated both immunoinformatic and molecular docking approach to present a multiepitope vaccine against HCV . The prioritized epitopes were then linked together by AAY linker and adjuvant (-defensin) were then scanned for non-homologous to host and antigenicity .",0.3614457831325301,0.13414634146341461,0.22891566265060243,0.040458207420590225
41,"This paper discusses the challenges of diagnosing heart disease and the potential benefits of data mining in healthcare. The authors propose an approach to extract significant patterns from heart disease data warehouses using clustering and frequent pattern mining algorithms. The significant patterns can then be used in the development of a heart attack prediction system. The authors acknowledge the heterogeneous and voluminous nature of healthcare data, as well as ethical, legal, and social constraints related to privacy. They suggest that their approach has the potential to improve healthcare decision-making and call for further development of artificial intelligence techniques in this area.","The diagnosis of diseases is a significant and tedious task in medicine . The detection of heart disease from various factors or symptoms is not free from false presumptions oftenaccompanied by unpredictable effects . Thus the effort to utilize knowledge and experience of numerous specialists and clinical screening data of patients collected in databases to facilitate the diagnosis process is considered a valuable option . In this paper, we have proposed an efficient approach for the extraction of significant patterns from the heart disease data warehouses for heart attack prediction .",0.43386243386243384,0.11764705882352942,0.2433862433862434,0.060934161178407144
42,"This study investigated the relationship between ""Velcro-type"" crackles heard on chest auscultation and radiologic features of pulmonary fibrosis on High Resolution Computed Tomography (HRCT). The study found that bilateral ""Velcro-type"" crackles predict the presence of Fibrotic Interstitial Lung Disease (FILD) and are closely associated with the extent of different interstitial abnormalities in the lung parenchyma. Individual features of pulmonary fibrosis, such as ground glass change and reticulation, were found to generate ""Velcro-type"" crackles. The study suggests that lung sounds could be a cost-effective tool for early identification of FILD if combined with computerized methods for analysis and classification.","“Velcro-type” crackles predict specific radiologic features of fibrotic interstitial lung disease, Idiopathic pulmonary fibrosis, Velcro crackles, Lung sounds, Breath sounds . Such evidence provides grounds for further investigation of lung sounds as an early identification tool in FILD . The clinical utility of chest auscultation for assisting diagnosis and clinical management of ILD has been historically hampered by the subjectivity of standard chest Auscultation and the poor signal transmission of standard",0.46511627906976744,0.16470588235294117,0.2558139534883721,0.07417474027260859
43,"This review article provides an overview of the use of EQ-5D in cancer patients and summarizes evidence supporting its validity and reliability. The article presents a catalog of utility scores based on the use of EQ-5D in clinical trials and studies of patients with cancer. A literature search of EMBASE and MEDLINE identified 34 studies reporting EQ-5D responses or summary scores and 12 studies reporting evidence of validity or reliability. The majority of studies using EQ-5D concerned patients with prostate cancer, breast cancer, cancers of the digestive system, and Hodgkin and/or non-Hodgkin lymphoma. Mean index-based scores ranged from 0.33 to 0.93, and visual analogue scale scores ranged from 43 to 84 across subtypes of cancer. The article concludes that the EQ-5D is a valid and reliable tool for assessing health-related quality of life in cancer patients, and that there is much opportunity for future research to fill gaps in knowledge relating to values/utility scores associated with cancer stage, type of cancer, common sites of metastates, and treatment-induced toxicities.","A substantial and growing body of literature using the EQ-5D in cancer that supports validity and reliability has emerged . This review provides utility estimates for cancer patients across a wide range of cancer subtypes, treatment regimens and tumor stage(s) that may inform the modelling of outcomes in economic evaluations of cancer treatment . The Y-error bars represent the 95% confidence interval about the mean score . ABMT = colon and rectum (colorectal) cancer; HOD = Hodgkin disease; MTM",0.3488372093023256,0.078125,0.17829457364341086,0.01216845312034424
44,"The abstract describes a study that analyzed the trends in Nigeria's HIV/AIDS research output between 1980 and 2006 using bibliometric analysis. The study aimed to identify deficiencies and strengths in HIV/AIDS research output from Nigeria and the impact of international collaboration on the quality of publications. The results showed a significant increase in the number of SCI publications and collaborations in HIV literature from Nigeria between 1987 and 2005. However, there is a need for improved international collaboration beyond historical, political, and cultural lines. The study recommends further comparison analyses of HIV/AIDS literature production in Nigeria with other countries in sub-Saharan Africa to obtain a more complete regional picture of the situation.","Nigeria is home to more people living with HIV than any other country in the world, except South Africa and India-where an estimated 2.9 million [1.7 million – 4.2 million] people were living with the virus in 2005 . The aim of this study was to analyse the trends in Nigeria's SCI publications in HIV/AIDS from 1980 to 2006 . International collaboration was deemed to exist in an article if any co-author's affiliation was located outside Nigeria .",0.3819095477386935,0.1116751269035533,0.18090452261306533,0.052532851940911215
45,"This review examines the prevalence of HIV-related suicidality, measurement within studies, and effectiveness of interventions. The review shows a high-suicidal burden among people with HIV, with notable presence of suicidal thoughts, plans, and acts resulting in self-harm as well as death. However, there is a gap in both provision and evaluation of interventions, with scant evidence of direct interventions to reduce any aspect of suicidality. The review calls for routine monitoring and tracking of all aspects of suicidality as a standard component of clinical care, and for urgent redress of the gap in interventions. The review also highlights the need for sub-analysis of participant characteristics, and the importance of considering the impact of HIV and AIDS across the globe, not just in the West.","Systematic reviewsuicidal behaviour; HIV; mental healthSuicide has long been associated with serious illness generally and HIV specifically . This review examines all published suicide and HIV data for a definitive account of (1) prevalence of HIV-related suicidality, (2) measurement within studies and (3) effectiveness of interventions . From the search, 332 papers were generated and hand searched resulting in 66 studies for analysis . Of these, 75% were American/European, but there was representation from developing countries .",0.3251231527093596,0.12935323383084577,0.2167487684729064,0.06485421488670626
46,"This paper presents two novel and powerful Convolutional Neural Network (CNN) architectures for COVID-19 detection and virus classification using chest X-ray images. The first architecture is designed to detect COVID-19 with an average accuracy of 98.92%, while the second architecture can classify chest X-ray images into three classes (COVID-19 vs. Normal vs. Pneumonia) with an average accuracy of 98.27%. The hyper-parameters of both CNN architectures are automatically determined using the Grid Search Optimizer method. The proposed CNN models are fully automatic and do not require the extraction of diseased tissue. The study uses a large clinical dataset, including 1524 COVID-19, 1527 pneumonia, and 1524 normal X-ray images. The proposed models show high accuracy and effectiveness on large clinical datasets, which can help physicians in diagnosing COVID-19 disease. The study emphasizes the importance of hyper-parameter analysis and establishing a standard in deep learning studies.","In this paper, two novel, powerful and robust CNN architectures are designed and proposed for two different classification tasks using publicly available datasets . The first architecture is able to decide whether a given chest X-ray image of a patient contains COVID-19 or not with 98.92% average accuracy . This study is the first CNN based CNN study which uses the largest possible clinical dataset . In such cases, how to move, which hyper parameters will be changed, and how they achieve success are not discussed .",0.4315352697095436,0.13389121338912133,0.2987551867219917,0.046818143622194976
47,"This research paper explores the use of advanced data mining techniques to predict the likelihood of heart disease in patients. It analyzes the performance of three classification models, Decision Trees, Naive Bayes, and Neural Networks, based on 15 input attributes including two newly added attributes, obesity and smoking. The results show that Neural Networks outperforms the other two models in terms of accuracy, achieving 100% accuracy. The paper suggests further expanding the system by incorporating more input attributes and utilizing other data mining techniques, such as clustering and text mining.","Improved Study of Heart Disease Prediction System using Data Mining Classification TechniquesData Mining, Heart Disease, Neural Networks, Naive Bayes . The system uses medical terms such as sex, blood pressure, cholesterol like 13 attributes to predict the likelihood of patient getting a Heart disease . This research paper added two more attributes i.e. obesity and smoking. The data mining classification techniques are analyzed on Heart disease database .",0.5128205128205128,0.2207792207792208,0.2435897435897436,0.13309942553318158
48,This paper proposes a machine learning model called multimodal deep belief network (DBN) to cluster cancer patients using multi-platform observation data. The model encodes relationships among features from each input modality and fuses common features to extract a unified representation of latent features. Tests on two cancer datasets show that the approach can effectively identify meaningful disease subtypes and key genes/miRNAs that may play distinct roles in cancer pathogenesis. The model can also be used to predict missing values and drug use for each patient based on available genetic information. The approach may have practical applications in cancer pathogenesis studies and personalized cancer therapy.,"In this paper, we propose a new machine learning model, called multimodal deep belief network (DBN), to cluster cancer patients from multi-platform observation data . In our integrative clustering framework, relationships between inherent features of each single modality are first encoded into multiple layers of hidden variables . A practical learning algorithm, called contrastive divergence (CD), is applied to infer the parameters of our multimodal DBN model in an unsupervised manner .",0.3977272727272727,0.19540229885057472,0.3295454545454546,0.1274550858012284
49,"This paper discusses the importance of using machine learning and data mining techniques in biosciences, particularly in the field of diabetes research. The study conducted a systematic review of the applications of these techniques in diabetes research, focusing on four main categories: prediction and diagnosis, diabetic complications, genetic background and environment, and health care and management. The results showed that supervised learning approaches, particularly support vector machines, were the most successful and widely used algorithms, with clinical datasets being the most commonly used type of data. The study concludes that the use of machine learning and data mining techniques in diabetes research can lead to the extraction of valuable knowledge and new hypotheses, ultimately contributing to deeper understanding and further investigation in the field.","DM is defined as a group of metabolic disorders exerting significant pressure on human health worldwide . Extensive research in all aspects of diabetes (diagnosis, etiopathophysiology, therapy, etc.) has led to the generation of huge amounts of data . The aim of the present study is to conduct a systematic review of the applications of machine learning, data mining techniques and tools in the field of diabetes research .",0.38947368421052636,0.2021276595744681,0.2526315789473685,0.10967569708007921
50,"The paper presents a novel ensemble approach for predicting the risk of cervical cancer, which addresses the challenges associated with previous studies on cervical cancer. Due to scarce awareness, lack of access to medical centers, and highly expensive procedures in developing countries, vulnerable patient populations cannot afford to undergo examination regularly. The proposed method includes a data correction mechanism and a gene-assistance module as optional strategies to enhance the robustness of the prediction. Multiple measurements are performed to evaluate the proposed method, and the results indicate that the likelihood of developing cervical cancer can be effectively predicted using the voting strategy. The proposed method is more scalable and practical compared to other methods. The study implies that machine learning has infinite potentials in the field of medical research, and future investigations will focus on more distinctive data, including colposcopy images.","A novel ensemble approach is presented in this paper to predict the risk of cervical cancer . By adopting a voting strategy, this method addresses the challenges associated with previous studies on cervical cancer. A data correction mechanism is proposed to improve the performance of the prediction . Multiple measurements are performed to evaluate the proposed method . The results indicate that the likelihood of developing cervical cancer can be effectively predicted using the voting strategy . In future, our investigations will focus on more distinctive data including colposcopy images.",0.6784140969162996,0.5155555555555555,0.5991189427312775,0.32728920741571876
51,"The field of metabolomics, which involves analyzing all small molecules or metabolites present within an organism or specific body compartment, is rapidly expanding and gaining attention in biomedical research. Metabolomics complements genomics and proteomics and provides valuable insights into metabolic changes associated with disease. Metabolomics can provide a snapshot of all metabolites present in a biological sample, and recent reports suggest that metabolomics analysis may identify biomarkers that predict disease progression and severity. Metabolomics has potential clinical applications in the development of biomarkers and precision medicine, but there is still a need to improve sensitivity and reproducibility across centers. While progress has been made in applying metabolomics to acute lung diseases, more data are needed to substantiate metabolomics biomarker credentials for clinical decision-making and trial design.","Metabolomics is a rapidly expanding field of systems biology that is gaining significant attention in many areas of biomedical research . Also known as metabonomics, it comprises the analysis of all small molecules or metabolites that are present within an organism or a specific compartment of the body . In this article, we review the burgeoning field of metabolomics in its application to acute lung diseases, specifically pneumonia and acute respiratory disease syndrome (ARDS)",0.4623115577889447,0.1725888324873096,0.24120603015075376,0.09874501644638906
52,"The article discusses the potential of using natural language processing (NLP) methods to extract useful information from electronic health records (EHRs) related to chronic diseases. The review of 106 studies highlighted the challenges faced by NLP in understanding clinical narratives and the need for improvement in the progression of clinical NLP methods. The studies focused on diseases of the circulatory system and used machine learning methods for disease phenotype classification. However, deep learning methods and the extraction of word embeddings from clinical notes remain relatively new. The scarcity of publicly available data also limits the development of NLP methods. The article suggests that shared tasks and access to data could increase participation in clinical NLP and contribute to improvements in NLP methods for clinical applications.","Novel approaches that complement and go beyond evidence-based medicine are required in the domain of chronic diseases . Methods based on machine learning to process EHRs are resulting in improved understanding of patient clinical trajectories and chronic disease risk prediction, creating a unique opportunity to derive previously unknown clinical insights . However, a wealth of clinical histories remains locked behind clinical narratives in free-form text . The majority of studies focused on diseases of the circulatory system (n=38) while endocrine and metabolic diseases",0.38461538461538464,0.11650485436893203,0.22115384615384615,0.08577890327026898
53,"The article discusses the potential of using deep neural networks (DNNs) for detecting heart disease based on routine clinical data, and presents a novel five layer DNN architecture named HEARO-5 that yields best prediction accuracy. The study is performed on the publicly available Cleveland dataset of medical information and the results show that DNN data analysis techniques can yield very high accuracy (99% accuracy and 0.98 MCC), which significantly outperforms currently published research in the area. The article emphasizes the need for further research and development to turn this into a robust diagnostic tool, including automatic search for best features, feature expansion or reduction, and extending the analysis to construct a more thorough model that includes heart visualizations and CT image data. The HEARO software framework will be released as an open source, and HEARO-5 as a benchmark, making the software available for comparison and further research on the use of DNN techniques in medicine.","On Deep Neural Networks for Detecting Heart DiseaseMachine learning, DNN, cardiology, translational medicine, diagnosis, cardiovascular disease, diagnostic medicine, hyperparameter optimization.Heart disease is the leading cause of death, and experts estimate that approximately half of all heart attacks and strokes occur in people who have not been flagged as ‘at risk’ Thus, there is an urgent need to improve the accuracy of heart disease diagnosis . To this end, we investigate the potential of using data analysis, and in particular the design and",0.3166666666666667,0.07563025210084034,0.18333333333333332,0.03223565379055558
54,"This paper discusses the need for long-term management of cancer and the importance of patient empowerment in achieving this. The iManageCancer project is presented as a novel methodology for cancer patient empowerment, which combines personal health systems, serious games, psycho-emotional monitoring, and other decision-support tools into an integrated platform. The paper details the ICT infrastructure developed and evaluated through a large-scale pilot for adults and a small-scale test for children. The evaluation showed mixed evidence on the improvement of patient empowerment but demonstrated an increase in coping with cancer and improvement in mood and resilience to cancer for the adult pilot. The platform was shown to be effective in integrating all involved stakeholders, ensuring continuity and consistency of clinical management, providing and sharing information, and coordinating patient care. The work reported in this manuscript provides evidence that continuity is valuable and important for both doctors and patients and can result in improved clinical outcomes.","In this paper, we present a novel methodology employed in the iManageCancer project for cancer patient empowerment . We present in detail the various technological components developed and their integration in a unique, modular platform . The platform was tested on two sites with the involvement of cancer patients, a large-scale pilot for adults and a small-scale test for children . Our evaluation showed mixed evidences on the improvement of patient empowerment, while ability to cope with cancer, including improvement in mood and resilience to cancer, increased for the participants",0.5483870967741936,0.36585365853658536,0.40322580645161293,0.17496404644120664
55,"This systematic review examines the available evidence for an association between periodontal disease and rheumatoid arthritis. Nineteen studies were analyzed, and moderate evidence was found for biochemical markers, while stronger evidence was found for clinical parameters such as tooth loss and clinical attachment levels. The study suggests that common risk factors or pathologic processes may be responsible for the association between these two inflammatory conditions. However, larger population-based studies with well-defined populations and outcomes are needed to confirm this link and consider potential confounding factors. The review highlights the need for more rigorous studies in the future to fully explore the relationship between periodontal disease and rheumatoid arthritis.","MEDLINE/PubMed, CINAHL, DOSS, Embase, Scopus, Web of Knowledge, MedNar, and ProQuest Theses and Dissertations were searched from the inception of the database until June 2012 for any quantitative studies that examined the association between periodontal disease and rheumatoid arthritis . These results provide moderate evidence based on biochemical markers and stronger evidence with regard to clinical parameters . There is a need to move from case-control studies to",0.37078651685393255,0.14772727272727273,0.23595505617977527,0.08911012905956567
56,"This study reviews the use of machine learning (ML) and deep learning (DL) methods in the field of cancer prognosis modeling. The study focuses on the development of predictive models for cancer treatment, and the use of ML and DL methods in detecting key features from complex datasets. The review compares the findings of various machine learning and deep learning techniques that have been implemented in cancer prognosis. The study identifies trends in the types of machine learning approaches used, the types of training data incorporated, the types of endpoint forecasts made, and the overall performance of cancer prediction or outcome methods. The study concludes that the use of ML and DL classification tools will likely become more common in clinical and hospital settings if the quality of research continues to improve. The authors suggest that improving the experimental design and biological validation of machine learning classification systems will increase the general quality, replicability, and reproductivity of these systems. The study proposes using other state-of-the-art machine learning algorithms and extraction methods to allow for more intensive comparative analysis in future research.",The timely screening and course of treatment of a cancer form is now a requirement in early cancer research because it supports the medical treatment of patients . Many research teams studied the application of ML and Deep Learning methods in the field of biomedicine and bioinformatics in the classification of people with cancer across high- or low-risk categories . These techniques have therefore been used as a model for the development of predictive models for predicating a cure for cancer .,0.34090909090909094,0.11450381679389314,0.18181818181818182,0.04007685285900324
57,"This paper discusses the importance of data mining in building intelligent models for detecting heart disease. The paper explores various data mining techniques, including classification techniques like Naïve Bayes, decision tree, neural network, genetic algorithm, artificial intelligence, and clustering algorithms like K-NN and support vector machine. The paper also provides a review of available prediction models using data mining from 2004 to 2016, and a comparison of their accuracy levels. The study concludes that combining data mining techniques with big data analytics can help identify key patterns and features in patient medical data to predict heart disease and reduce data sets while increasing prediction model accuracy.","Data mining plays an important role in building an intelligent model for medical systems to detect heart disease . The large data available from medical diagnosis is analyzed by using data mining tools and useful information known as knowledge is extracted . Mining is a method of exploring massive sets of data to take out patterns which are hidden and previously unknown relationships . There are many DM techniques available namely Classification techniques involving Nave bayes (NB), Decision tree (DT), Neural network (NN), Genetic algorithm (GA), Artificial intelligence (AI)",0.4536082474226804,0.16666666666666666,0.25773195876288657,0.07544788854248996
58,"This study aimed to investigate the prognostic value of Krebs von den Lungen-6 (KL-6) levels in patients with rheumatoid arthritis-associated interstitial lung disease (RA-ILD). The study retrospectively reviewed the medical records of 84 RA-ILD patients and measured plasma KL-6 levels. The study found that high KL-6 levels were independently associated with a usual interstitial pneumonia (UIP) pattern and were an independent prognostic factor for mortality in RA-ILD patients, along with age, sex, and lung function. The study suggests that KL-6 levels might be useful as a biomarker for the presence of a UIP pattern and prognosis in patients with RA-ILD and calls for further validation in larger-scale studies.","Prognostic role of blood KL-6 in rheumatoid arthritis–associated interstitial lung disease (RA-ILD) has a variable clinical course for which predicting prognosis is difficult . However, the role of . blood biomarkers in RA .ILD is ill-defined . The medical records of 84 patients with RA–ILD were retrospectively reviewed . Our results suggest that high KL6 levels might be useful as a biomarker",0.4725274725274725,0.28888888888888886,0.3516483516483517,0.11333720833167533
59,"This paper proposes a method for improving the performance of text generation models by incorporating contextual information during training. The authors explore different methods for extracting context vectors and find that those extracted from word clusters in word vector spaces work best. They also evaluate the performance of their model using cosine similarity measures and find that context-based models perform better than base models. Overall, the authors show that incorporating context during training can improve the semantic consistency of generated text.","In Natural language generation, LSTM networks are providing impressive results on text generation models by learning language models with grammatically stable syntaxes . But the downside is that the network does not learn about the context . The proposed model is trained to generate text for a given set of input words along with a context vector . A context vector is similar to a paragraph vector that grasps semantic meaning(context) of the sentence .",0.38961038961038963,0.06578947368421052,0.16883116883116883,0.045690268708699244
60,"This paper discusses the importance of using given starting words to generate sentences and filling in sentences in natural language processing tasks. The paper focuses on using OpenAI GPT-2 and BERT models for text generation and prediction, and presents experiments using two new corpora to train the GPT-2 model for generating long sentences and articles, and BERT model for predicting intermediate words based on context. The paper concludes with a comparative analysis of the performance of the two models in text generation.","The OpenAI GPT2 and BERT models are currently widely used language models for text generation and prediction . We train the machine for specific tasks and then use it in natural language processing, which will help solve some sentence generation problems . This paper will use two new corpora to train GPT-2 model, used to generate long sentences and articles . At the same time, we will use the BERT model to complete the task of predicting intermediate words based on the context .",0.6424242424242423,0.35582822085889576,0.39999999999999997,0.24522479020275714
61,"This survey discusses the importance of Automatic Text Summarization in dealing with the problem of information overload on the internet. It reviews different methods and evaluation metrics with a focus on the latest trends of neural network-based and pre-trained transformer language models. The article introduces the background of Automatic Text Summarization, its classification into extractive and abstractive summarization, and the current trend of pre-trained language models like GPT, BERT, and XLNet. The paper proposes a model based on XLNet for summarization and identifies future works such as decoder alternatives and batch size implementation. The survey concludes that pre-trained language models effectively improve the performance of Automatic Text Summarization, leaving room for more applications of XLNet in the field.","Survey on Automatic Text Summarization and Transformer Models Applicability . The main attention is on the applications of the latest trends, neural network-based, and pre-trained transformer language models . We introduced the background including its history from its beginning to the current state, application, and its taxonomy . After Transformer published, it became the new trend in NLP field . In this survey, we reviewed the task of Automatic Text summarization .",0.4712041884816754,0.23280423280423282,0.34554973821989526,0.09585241360399727
62,"This paper discusses the need for bilingual (Hindi and English) unsupervised automatic text summarization using deep learning, as there is an increase in the amount of big data available on the internet and social media. The proposed algorithm uses Restricted Boltzmann Machine to generate a shorter version of the original document without losing important information. Eleven features are extracted from each sentence of the document to enhance the relevance of the summary. The proposed algorithm has an 85% accuracy rate and preserves the meaning of the original document. Future enhancements can be made by adding more features for a more relevant and meaningful summary.","Bilingual (Hindi and English) unsupervised text summarization Using Unsupervised Deep Learning Automatic Summarization, Deep Learning RBM, Bilingual, dataset, unsupervised . The huge data in English and Hindi is available on internet and social media which need to be extracted or summarized in user required form . We are using restricted Boltzmann machine to generate a shorter version of original document without losing its important information . In this algorithm we are exploring the features to improve the relevance of relevant sentences .",0.5714285714285715,0.2888888888888889,0.4505494505494505,0.21562195805518192
63,"This paper compares global and local attention mechanisms in LSTM models for abstractive text summarization using a dataset of Amazon reviews. The global attention-based model produces more words in the summary, while the local attention-based model generates more word pairs. However, since the dataset contains informal words and unknown phrases, ROUGE scores are not high. Resetting parameters or using other datasets could improve performance.","The Impact of Local Attention in Long Short-Term Memory (LSTM) model for Abstractive Text Summarization . The global attention-based model produces better ROUGE-1, where it generates more words contained in the actual summary . However, the local attention based gives higher ROUGe-2 . Since the dataset is written using informal words, it contains a lot of symbols and unknown phrases those are not listed in the word embedding dataset . Resetting all parameters may give higher scores for both models .",0.6438356164383561,0.3194444444444444,0.4931506849315069,0.1669571826869525
64,"This paper proposes four novel ATS models utilizing a Seq2Seq structure with an attention-based bidirectional LSTM to improve the Automatic Text Summarization task. The proposed models include an enhanced semantic network, a DA-PN model, a coverage mechanism, and a mixed learning objective function. The models were compared to baselines and state-of-the-art models on short and long-text corpora, and the results showed their superiority. The best-performing model, 'DA-PN + Cover + MLO,' could further improve the accuracy of generated summaries by optimizing evaluation indexes. The study suggests future research directions to explore this possibility.","The automatic generation of a text summary is a task of generating a short summary for a relatively long text document by capturing its key information . In the past, supervised statistical machine learning was widely used for the Automatic Text Summarization task, but due to its high dependence on the quality of text features, the generated summaries lack accuracy and coherence . The computational power involved, and performance achieved, could not easily meet the current needs . This paper proposes four novel ATS models with a Sequence",0.4239130434782608,0.14285714285714285,0.18478260869565216,0.12295228215868874
65,"The paper presents a new abstractive text summarization model, called MAPCoL, that uses multi-layered attentional peephole convolutional LSTM to generate summaries from long texts. The model is optimized using central composite design and response surface methodology, resulting in higher accuracy and semantic coherence compared to state-of-the-art models. MAPCoL also outperforms traditional LSTM-based models. However, the model is less efficient in generating long summaries. Overall, MAPCoL is a promising approach to abstractive text summarization.","In this paper, we present an abstractive text summarization model, multi-layered attentional peephole convolutional LSTM (long short-term memory) that automatically generates a summary from a long text . We record the accuracy of our model (MAPCoL) using central composite design (CCD) in combination with the response surface methodology (RSM), which gives the highest accuracy in terms of summary generation . The developed model achieves better performance than any state-of-the-art model with respect",0.5751633986928104,0.26490066225165565,0.41830065359477125,0.15363301426808051
66,"The study explores the use of Bidirectional GRU with attention to summarize Bahasa Indonesian text data. The proposed model outperforms extractive methods and can generate summaries with high similarity to the provided abstracts. However, the evaluation scores are lower than those for English text models due to linguistic factors and the size of the source text. The model can learn individual words but has poor grammar structure and cohesion among sentences. The authors conclude that the proposed model has successfully learned words from the source text, but challenges remain in improving grammar structure and linguistic problems for better summary results.","Recurrent Neural Network (RNN) has experienced success in summarizing abstractive texts for English and Chinese texts . The Bidirectional Gated Recurrent Unit (BiGRU) RNN architecture is used so that the resulted summaries are influenced by the surrounding words . In this research, such a method is applied for Bahasa Indonesia to improve the text summarizations that are commonly developed using some extractive methods with low inter-sentence cohesion .",0.3734939759036144,0.04878048780487805,0.14457831325301204,0.00886607204963146
67,The increase in data shared online presents a threat to privacy. This study analyzed how well people can be recognized in social media data and proposed a robust person recognition system that can handle variations in pose and clothing. The results showed that even obfuscation had limited effect and only a handful of tagged heads were enough for recognition. The study highlights the need for the computer vision community to quantify and disseminate the privacy implications of online image sharing. Future challenges and directions on privacy implications of social visual media are discussed.,"This works contributes to the understanding of privacy implications of such data sharing by analysing how well people are recognisable in social media data . To facilitate a systematic study we define a number of scenarios considering factors such as how many heads of a person are tagged and if those heads are obfuscated or not . We propose a robust person recognition system that can handle large variations in pose and clothing, and can be trained with few training samples . From a privacy perspective, the results presented here",0.5222222222222221,0.24719101123595508,0.3111111111111111,0.18306331019689812
68,"The paper proposes a novel interpretable model for personality recognition based on a Chinese personality lexicon constructed using word embedding techniques and prior-knowledge lexicons. The model analyzes the correlations between personality traits and semantic categories of words to extract semantic features of users' microblogs, which are then used to construct personality recognition models using classification algorithms. The proposed model outperforms previous approaches in terms of accuracy. Future work includes using distributional contextual representations of keywords to obtain better word vectors and developing a personality lexicon with more complicated semantic relations for deeper study and interpretation of personality traits.","In this paper, we present a novel interpretable personality recognition model based on a personality lexicon . First, we use word embedding techniques and prior-knowledge lexicones to automatically construct a Chinese language suitable for personality analysis . The proposed model can achieve significantly better performances compared to previous approaches . In future, we will utilize distributional contextual representations of the keywords to obtain better word vectors .",0.5521472392638036,0.36024844720496896,0.47852760736196315,0.16547799111534706
69,"This paper proposes a method for face recognition called the Laplacianface approach, which uses Locality Preserving Projections (LPP) to map face images into a face subspace for analysis. Unlike other methods, LPP preserves local information and detects the essential face manifold structure, which can reduce or eliminate unwanted variations resulting from changes in lighting, facial expression, and pose. The approach is compared with Eigenface and Fisherface methods on three different face data sets, and results show that Laplacianface provides a better representation and achieves lower error rates in face recognition. The paper also discusses the theoretical analysis of LPP algorithm and its connections to PCA and LDA, and experimental results on PIE, Yale, and MSRA databases demonstrate the effectiveness of the method.","Face Recognition Using LaplacianfacesFace recognition, principal component analysis, linear discriminant analysis, locality preserving projections, face manifold, subspace learning . We propose an appearance-based face recognition method called the Laplacienface approach . By using Locality Preserving Projections (LPP), the face images are mapped into a face subspace for analysis . This linear transformation optimally preserves local information . The results suggest that the proposed approach provides a better representation and achieve",0.4444444444444445,0.2245989304812834,0.3386243386243386,0.11751710365581589
70,"The paper proposes an attention-aware face recognition method based on a deep convolutional neural network and reinforcement learning. The method includes an Attention-Net that selects patches in the input face image and a Feature-Net that extracts discriminative embedding features. The Attention-Net is trained with reinforcement learning to maximize recognition accuracy, and a regularization method is introduced. The method achieves satisfactory recognition performance on a public face verification database. The paper demonstrates the feasibility of using the attention mechanism in face recognition and suggests that subdividing the face area with more points could lead to higher accuracy results.","Attention-Aware and Regularization for Face Recognition With Reinforcement LearningThis paper proposes an attention-aware face recognition method based on a deep convolutional neural network and reinforcement learning . The Attention-Net is used to select patches in the input face image according to the facial landmarks and trained with reinforcement learning to maximize the recognition accuracy . In addition, a regularization method has also been introduced . Our method achieves satisfactory recognition performance on its application to the public prevailing face verification database .",0.6923076923076923,0.47777777777777775,0.5604395604395604,0.38295426542787053
71,"This paper introduces a new method for face recognition called Local Binary Pattern Network (LBPNet), which combines the deep learning architecture of Convolutional Neural Network (CNN) with the computer vision descriptor LBP. The LBPNet is able to extract and compare high-level over-complete features in a multilayer hierarchy, achieving high recognition accuracy without requiring costly model learning on massive data. The method was evaluated using public benchmarks FERET and LFW and was shown to be comparable to other unsupervised methods, demonstrating promising performance in face recognition.","Local Binary Pattern, PCA, Convolutional Neural NetworkDeep learning is well known as a method to extract hierarchical representations of data . The LBPNet retains the same topology of CNN - one of the most well studied deep learning architectures - whereas the trainable kernels are replaced by the off-the-shelf computer vision descriptor (i.e., LBP). This enables the LBPnet to achieve a high recognition accuracy without requiring any costly",0.4774193548387097,0.18300653594771243,0.29677419354838713,0.09893370031229741
72,"This paper discusses the use of deep learning for face detection, using the YOLO library and a convolutional neural network. The paper compares the accuracy of face detection using the traditional approach with that achieved through deep learning. The authors fine-tune the model on various parameters and test it on the FDDB dataset. The paper concludes that deep learning requires a high configuration NVIDIA graphics card and that several factors affect the accuracy of face detection, including learning rate, number of times the dataset is trained, and image resolution. The proposed model achieved an IoU accuracy of 92.2% after 20 epochs. Future work includes optimizing the model for very small face detections, different viewpoint variations, and partial face detection.","A Deep Learning Approach for Face Detection using YOLO, Neural Network, object detection, Convolutional Neural network . It mainly describes the learning at multiple levels of representation which helps to make sense on the data consisting of text, sound and images . Many organizations are using a type of deep learning known as a convolutional neural network to deal with the objects in a video sequence . Effective training needs to be carried out for detection and recognition .",0.33673469387755106,0.1134020618556701,0.22448979591836735,0.05886393879096098
73,"This article discusses the importance of epidemiological data in understanding and predicting the risks associated with the outbreak of COVID-19 caused by the SARS-CoV-2 virus. The authors analyze various open datasets on the outbreak and present an exploratory data analysis with visualizations to understand the number of cases reported in different provinces of China and outside of China. They conclude that user-friendly data visualization models such as map view and tree map view can provide a comprehensive understanding of the outbreak and help monitor its epidemiological data. However, they caution that this is an early data analysis of a situation that is rapidly evolving and that more epidemiological and serological studies are needed to fully understand the virus.","An exploratory data analysis approach has been made to understand the number of different cases reported (confirmed, death, and recovered) in different provinces of China and outside of China . This is the very first attempt on COVID19, which focuses on the VEDA based on different data sources . However, knowledge about this novel SARSCoV2 virus remains limited among general people around the globe .",0.3369565217391305,0.1978021978021978,0.2717391304347826,0.12390830435233016
74,"This systematic literature review evaluates published studies reporting associations between patient-reported symptoms and clinical signs of dry eye disease (DED). The review identified 34 articles assessing associations between signs and symptoms, including 175 individual sign-symptom association analyses. Statistical significance was reported for associations between sign and symptom measures in 64% of studies, but for only 24% of individual analyses. The majority of reported correlation coefficients between signs and symptoms were low-to-moderate, indicating low correlation. The review concludes that associations between commonly used assessments of signs and symptoms of DED are low and inconsistent, highlighting the need for further studies to enhance clinical assessment of DED and the measurement of response to therapeutic interventions.","The accurate diagnosis and classification of dry eye disease (DED) is challenging owing to wide variations in symptoms and lack of a single reliable clinical assessment . In addition, changes and severity of clinical signs often do not correspond to patient-reported symptoms . Results: Thirty-four articles were identified that assessed associations between signs and symptoms, among which 33 unique studies were reported . Of 175 individual analyses, 148 reported correlation coefficients, of which the majority were between -0.4 and 0.4, indicating low-to-",0.48756218905472637,0.21105527638190952,0.2686567164179105,0.12714561027282031
75,"This article discusses the use of machine learning techniques in the early detection of diabetic eye disease, which is a common complication of diabetes. The article provides a comprehensive review of automated approaches to detecting diabetic eye disease, including datasets, image preprocessing techniques, deep learning models, and performance evaluation metrics. The article also categorizes the studies based on the specific types of diabetic eye diseases, such as diabetic retinopathy, glaucoma, diabetic macular edema, and cataract. The review focuses on deep learning-based approaches and identifies limitations associated with the study, such as the narrow timeframe and predefined keywords used in the review. The article concludes by calling for further research in the rapidly developing field of diabetic eye disease detection.","Diabetic eye disease, diabetic retinopathy, deep leaning, glaucoma, image processing, macular edema, transfer learning . Diabetes Mellitus, or Diabetes, is a disease in which a person’s body fails to respond to insulin released by their pancreas, or it does not produce sufficient insulin . A variety of advanced studies relating to the detection of diabetic eye disease have recently been published .",0.32222222222222224,0.10112359550561799,0.17777777777777776,0.06855253104525938
76,"This paper proposes a scalable approach to computing betweenness centrality in graph networks, incorporating node and edge colors to efficiently query on multiple combinations of colored subgraphs. The approach decomposes the graph into subgraphs, computes the betweenness centrality for each subgraph, and merges the results to find the common backbone node (BBN) of multiple subgraphs. Experiments on human disease graph data demonstrate the efficiency of the proposed approach compared to conventional methods. The study concludes that the proposed approach is more efficient for graphs composed of multiple colored subgraphs, and the performance is influenced by the number of subgraphs and their overlap.","In biomedicine, graph structural analytics such as betweenness centrality has played an important role in finding the most central vertices in graph data . Considering color as a property of graph data to represent different categories for the nodes and edges in the graph, we may investigate the betweenness Centrality of each colored subgraph composed of a specific color . In addition, the performance could be worse when the size of the graph grows larger . We propose a scalable approach which is more efficient when finding the global backbone no",0.45263157894736844,0.19148936170212766,0.2526315789473684,0.03193785139183492
77,"This review article discusses the use of machine learning, particularly deep learning, in the detection of kidney tumors through radiology imaging scans. Kidney tumors are common and pose a significant threat to public health, and traditional diagnostic methods are time-consuming and costly. Deep learning algorithms can save diagnosis time, improve test accuracy, and reduce costs. The article highlights previous research in this area, including the techniques used, the data sets analyzed, and the limitations of the studies. The review identifies promising avenues for future research, such as creating multi-models that perform detection, classification, segmentation, and other tasks to diagnose all aspects of the tumor in one process, and incorporating advanced data analytics-based AI techniques into radiology practice in the future. The early detection of kidney tumors through deep learning algorithms can greatly reduce death rates, provide early treatment, and produce preventive measures that reduce the effects of the disease.","Radiology Imaging Scans for Early Diagnosis of Kidney Tumors: A Review of Data Analytics-Based Machine Learning and Deep Learning Approaches . Recent research has focused on studying common diseases in the population to reduce death risks, take the best procedure for treatment, and enhance the healthcare level of the communities . In general, deep learning’s application to kidney radiology imaging is still in its infancy, and attempts are being made to address the current challenges .",0.3964757709251101,0.11555555555555556,0.1938325991189427,0.01629372073557662
78,"The article discusses the importance of active medication stocking in preventive healthcare management, especially in the secondary prevention stage, and the difficulty of predicting preventive or life-saving medication for each patient. The proposed solution is a relation augmented hierarchical multi-task learning framework (RAHM) that can learn multi-level relation-aware patient representation for reasonable medication stocking. The framework leverages the underlying structural relations of Electronic Health Record (EHR) data to learn the low-level patient visit representation, encodes the historical temporal disease information for disease-level patient representation learning, and handles the relations between diseases and medication in longitudinal patient records. The results of extensive experiments on a real-world clinical dataset demonstrate that RAHM performs better on disease prediction and medication recommendation for patients compared to previous methods. The authors aim to implement the model in medication management systems for hospitals or clinics.","RAHM is capable of learning multi-level relation-aware patient representation for reasonable medication stocking . Existing models usually overlook the implicit hierarchical relation between patient’s predicted diseases and medications . In the learning process, two pseudo residual structures are introduced to mitigate the error propagation and preserve the valuable relation information of EHRs . Extensive experiments on a dataset demonstrate that RAMH performs better on disease prediction and medication recommendation for patients compared with previous methods .",0.506787330316742,0.2831050228310502,0.37104072398190047,0.13110632029064034
79,"This paper focuses on the analysis and mining of large sports medical data, aiming to achieve effective prediction and risk assessment of sports medicine-related diseases. The paper proposes an improved convolutional neural network algorithm based on the resampling algorithm with self-adjusting function, supplemented by the tensor convolution self-coding algorithm. The paper also introduces a cloud-based hardware-in-the-loop simulation model to build an intelligent medical data platform for sports medicine. The experiments show that this method provides reference and technical support for the realization of a real cloud-based fusion system. The paper concludes that efficient and precise sports medical data mining methods are important and meaningful due to the increase of sports medical data year by year, and suggests further work focusing on the application and analysis of the improved convolutional neural network in time series data feature learning.","In order to achieve effective prediction and risk assessment of sports medicine-related diseases, this paper innovatively proposes a cloud-based hardware-in-the-loop simulation model . This paper will focus on the information mining and analysis of large sports medical data, focusing on the loss of training mode and the accuracy of convolution algorithm . The paper systematically analyses and studies the disadvantages of the current convolutional neural network algorithm combined with sports medicine data .",0.5454545454545454,0.3302752293577982,0.37272727272727274,0.1521304609522877
80,"This project proposes a deep convolutional neural network (CNN) model with image augmentation (IA) technique for person recognition using gait features. The model was adapted to improve its performance, including the CNN parameters and design. The IA technique was used to increase the dataset size and make the model robust to variations in the images. The results show that the adapted model with IA outperformed the model without adaptation in person recognition accuracy. The study suggests further improvements in the model, such as using genetic algorithms, exploring activation functions, and adding more IA conditions. The proposed model has potential applications in real-time systems for person recognition.","Analyse and best parameters selection for person recognition based on gait model using CNN algorithm . Image augmentation was used to increase the size of train dataset with many copies of the image to boost the number of diferent images that will be used to train Deep learning algorithms . In addition, the design of CNN model itself was adapted to get best model structure; Adaptation in the design was afected the type . The image in CNN model as matrix is extracted to many images or matrices by the convolution",0.47179487179487173,0.13471502590673576,0.2769230769230769,0.07122483579900983
81,"The study focuses on person recognition from thermal imagery and evaluates the influence of image resolution on recognition accuracy. The researchers tested if a model trained on RGB images can perform well on thermal images without additional training. They also developed a deep super-resolution model to enhance low-resolution thermal images for better recognition accuracy. The preliminary results showed that enhancing image resolution improves person recognition accuracy, and the super-resolution model improved results by 8% on the IRIS dataset. However, no gain in performance was observed on their database under strictly defined measurement conditions. The researchers plan to perform similar studies under various scenarios and evaluate the proposed approach on images with the original bit resolution.","Thermal Imagery Resolution has been widely applied in this area, providing details about recognized objects, people and actions . Thermal imaging has become more popular, as it does not reveal features that are often used for person recognition, i.e. sharp edges, clear changes of pixel values between areas, etc. On the other hand, there are much more visible light data available for deep model training . This study focuses on verifying whether model trained to extract important facial embedding from RGB images can perform equally well if applied to thermal domain,",0.3076923076923077,0.09708737864077671,0.15384615384615385,0.04619940052586475
82,"The article presents a new framework for person recognition under unconstrained settings, which integrates a Region Attention Network to combine visual cues with instance-dependent weights and a model that unifies person identification and context learning in joint inference. The proposed method consistently outperforms previous state-of-the-art methods on both PIPA and a new dataset CIM constructed from movies, demonstrating the importance of adaptive combination of visual cues and the usefulness of social context information in person recognition.","recognizing persons under unconstrained settings remains challenging . Issues like profile views, unfavorable lighting, and occlusions can cause substantial difficulties . Previous works have attempted to tackle this problem by exploiting the context, e.g. clothes and social relations . In this work, we propose a Region Attention Network, which is learned to adaptively combine visual cues with instance-dependent weights . We also develop a unified formulation, where the social contexts are learned along with the reasoning",0.4155844155844156,0.17105263157894735,0.27272727272727276,0.11929450540910264
83,"The paper introduces the People In Photo Albums (PIPA) dataset for unconstrained person recognition, which contains over 60,000 instances of 2,000 individuals from Flickr photo albums. The Pose Invariant PErson Recognition (PIPER) method is proposed, which combines poselet-level person recognizers, a face recognizer, and a global recognizer to overcome challenges such as pose variations, clothing, camera viewpoint, image resolution, and illumination. PIPER outperforms state-of-the-art methods and can also be applied to generic instance co-identification.","People In Photo Albums (PIPA) dataset contains over 60000 instances of 2000 individuals collected from public Flickr photo albums . With only about half of the person images containing a frontal face, the recognition task is very challenging due to the large variations in pose, clothing, camera viewpoint, image resolution and illumination . We propose the Pose Invariant PErson Recognition (PIPER) method, which accumulates the cues of poselet-level person recognizers trained by deep convolutional networks to discount for",0.6329113924050632,0.32051282051282054,0.3924050632911393,0.33072416647688235
84,"This paper focuses on using virtual tasks as sub-tasks in multi-label learning for gait-based person recognition. By incorporating pseudo labels with the real task labels, they achieve improved accuracy in gait recognition. The advantage of using pseudo labels is that multiple types of virtual tasks can be generated without manual annotation. The authors plan to address the issue of fixed subnetworks and class numbers in future work.","Incorporation of Extra Pseudo Labels for CNN-based Gait Recognition is a major model used for image-based recognition tasks . These approaches are sometimes used to improve the accuracy of the main task by incorporating extra labels associated with sub-tasks . The incorporated labels for learning are usually selected from real tasks heuristically; for example, gender and/or age labels are incorporated together with subject identity labels .",0.46715328467153283,0.07407407407407407,0.20437956204379562,0.014716600858969453
85,"Sentiment analysis or opinion mining is the process of computationally analyzing people's opinions and emotions towards entities, individuals, issues, events, topics and their attributes. It is a challenging but useful task for businesses and consumers who want to know the public's opinions about products and services. With the growth of social media, analyzing public opinions on the web has become increasingly important but difficult due to the vast amount of opinionated text on diverse sites. Automated opinion mining and summarization systems are needed to overcome human biases and limitations. The chapter surveys the field of sentiment analysis and opinion mining, discussing various key mining tasks, including sentiment and subjectivity classification, aspect-based sentiment analysis, and opinion spam detection. The chapter concludes that sentiment analysis tasks are challenging, but significant progress has been made, and the field will remain vibrant and essential in the future.","A survey of opinion mining and sentimrnt analysis is the computational study of people’s opinions, appraisals, attitudes, and emotions toward entities, individuals, issues, events, topics and their attributes . The task is technically challenging and practically very useful. For example, businesses always want to find public or consumer opinions about their products and services . Potential customers also want to know the opinions of existing users before they use a service or purchase a product .",0.4363636363636364,0.2018348623853211,0.32727272727272727,0.11196446469435116
86,"The article discusses the problem of classifying documents based on sentiment, rather than topic. Machine learning techniques outperform human-produced baselines for this task, but the performance is not as good as traditional topic-based categorization. Unigram presence information is the most effective feature for sentiment classification, despite previous observations in topic-classification work. The article examines a common phenomenon in the documents, where authors set up deliberate contrasts to earlier discussions, which makes sentiment classification more challenging. The article concludes by discussing factors that make sentiment classification more difficult and how to improve it.","Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines . However, the three machine learning methods we employed do not perform as well on sentiment classification as on traditional topic-based categorization . We conclude by examining factors that make the sentiment classification problem more challenging . The superiority of presence information in comparison to frequency information in our setting contradicts previous observations made in topic-classification work .",0.5238095238095238,0.2530120481927711,0.2857142857142857,0.11770197953375543
87,"The text describes a machine learning framework that uses recursive autoencoders to predict sentiment label distributions for multi-word phrases without using any pre-defined sentiment lexica or polarity shifting rules. The framework outperforms other state-of-the-art approaches on commonly used datasets, such as movie reviews. The model is also evaluated on a new dataset of personal user stories annotated with multiple labels, and it is shown to accurately predict distributions over these labels compared to several competitive baselines. The framework is able to accurately predict sentence-level sentiment distributions without using any hand-engineered resources.","Our method learns vector space representations for multi-word phrases . In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using pre-defined sentiment lexica or polarity shifting rules . We also evaluate the model’s ability to predict sentiment distributions on a new dataset based on confessions from the experience project .",0.5714285714285715,0.41509433962264153,0.34782608695652173,0.2328834037013909
88,"The article discusses the rise of microblogs, such as Twitter, and how sentiment analysis on entities (products, organizations, people) can be used to gauge public opinion for business marketing or social studies. However, Twitter's unique characteristics present new problems for current sentiment analysis methods. The article proposes a new entity-level sentiment analysis method for Twitter, which uses a lexicon-based approach followed by a classifier to improve recall. The proposed method is effective and outperforms state-of-the-art baselines. Experimental results are provided to support the effectiveness of the method.","Sentiment analysis on entities (e.g., products, organizations, people, etc.) in tweets thus becomes a rapid and effective way of gauging public opinion for business marketing or social studies . However, Twitter's unique characteristics give rise to new problems for current sentiment analysis methods . The method first adopts a lexicon-based approach to perform entity-level sentiment analysis . To improve recall, additional tweets that are likely to be opinionated are identified automatically by exploiting the information in the result of",0.6358381502890175,0.3976608187134503,0.47398843930635837,0.34878803883762516
89,"The article discusses movie review mining as a sentiment-based classification problem that is different from topic-based classifications. Two approaches, machine learning and semantic orientation, are used and adapted to movie review mining for comparison. The results show that movie review mining is a challenging application due to the mixture of factual information and real-life review data, ironic words used in writing movie reviews, and the sparsity of words in movie reviews. The study suggests future work for improving existing approaches to movie review mining and states that the findings can contribute to other text classification problems.","Movie Review Mining: a Comparison between Supervised and Unsupervised Classification Approachessemantic orientation, machine learning,, opinion mining . Movie review mining classifies movie reviews into two polarities: positive and negative . The approaches are adapted to movie review domain for comparison . We also find that movie review mining is a more challenging application than many other types of review mining. The challenges lie in factual information is always mixed with real-life review data and ironic words are used in writing movie reviews .",0.6033519553072625,0.30508474576271183,0.4134078212290503,0.19606172980289294
90,"Opinion mining (OM) is a field that focuses on extracting opinions expressed in text, rather than the topic of the text. It has many applications, including tracking user opinions about products and political candidates. Recent research has focused on automatically determining the polarity (positive or negative connotation) of subjective terms. SENTIWORDNET is a lexical resource that provides numerical scores for how objective, positive, or negative terms in a synset are. It was developed by analyzing the glosses associated with synsets and using vectorial term representations for semi-supervised synset classification. SENTIWORDNET has a web-based graphical user interface and can be useful for opinion mining due to its wide coverage and fine-grained numerical scores.","SENTIWORDNET: A Publicly Available Lexical Resource for Opinion Miningsentiwordnet, opinion mining,, synset, NLPOpinion mining (OM) is a recent subdiscipline at the crossroads of information retrieval and computational linguistics . In order to aid the extraction of opinions from text, recent research has tried to automatically determine the “PN-polarity” of subjective terms, i.e. identify whether a term that is indeed a marker of opinionated content (",0.4222222222222222,0.1348314606741573,0.2555555555555556,0.07021057622510478
91,"This study is a review of recent research on the use of neural networks in the early diagnosis of melanoma, a highly aggressive type of cancer. The study found that neural networks, specifically convolutional and deep-learning neural networks, combined with fuzzy clustering or World Cup Optimization algorithms, show highly sensitive, specific, and accurate results. The study concludes that neural networks have greater sensitivity and specificity than dermatologists, can evaluate features that might be unavailable to the naked human eye, and provide the possibility of early detection of signs of melanoma and early treatment. Additionally, the study suggests that the need for staff training and expensive equipment for creating dermatoscopic images can be replaced by software using FC-neural networks. Overall, the study highlights the potential of using neural networks as an auxiliary or even the main diagnostic tool for the early diagnosis of melanoma.","In our opinion, due to the increasing incidence of the disease, it is necessary to find new, easy to use and sensitive methods for the early diagnosis of melanoma in a large number of people around the world . Over the last decade, neural networks show highly sensitive, specific, and accurate results . All of them require an ABCD algorithm and its derivates to provide high specificity, accuracy and sensitivity than dermatologists .",0.35348837209302325,0.13145539906103287,0.22325581395348837,0.08456083931596162
92,"This paper presents a survey of various cancer diagnosis and prognosis models using data mining and machine learning approaches. The study discusses the application of deep learning and machine learning models for modeling the development and treatment of cancer conditions. The paper analyzes the different algorithms, datasets, and environments utilized in cancer prediction models using intelligent approaches. It provides detailed information on the research gaps and challenges concerning cancer diagnosis and prognosis models through machine learning approaches. The study identifies research gaps, such as the development of pre-clinical trials, handling complex cancer images, precise and early treatment, and innovative and intelligent strategies for fast detection of disease. The paper concludes that while machine learning models have shown promise in cancer detection, there is still a long way to go, and most models lack sufficient data and suffer from bias. Overall, the survey provides useful insights for developing a robust model in the future compared to traditional models and gives hope for further research in cancer detection.","The early detection and prognosis of a cancer type have turned into a major requirement, as it facilitates successive medical treatment of patients . The research team has classified the cancer patients into high or low-risk groups . As per the current survey, the detection rate is about 99.89%, which shows the prediction models’ efficiency and precise decision making . However, ML models are still in testing as well as the experimentation phase for cancer prognoses .",0.28099173553719003,0.041666666666666664,0.16528925619834708,0.004874793179737567
93,"This study aimed to investigate the feasibility of using high-throughput gene expression data and clinical data for predicting cancer patients' survival risk. The researchers performed cross-laboratory validations for the cancer patient data from four hospitals and identified five survival-time correlated genes from four microarray gene expression data sets. They used artificial neural networks (ANN) to construct a prediction model and achieved an overall accuracy of 83.0% based on survival time trusted data. The study showed that predicting cancer patients' survival was feasible using cross-laboratory gene expression data, and the key to this analysis was identifying the pertinent genes. The results of the study provide a foundation for further clinical studies and research into other types of cancer to improve the prognostic methods of cancer patients.","Gene expression , Neural network , Machine learning , Survival analysis , Outcome prediction , Lung cancer.Numerous cancer studies have combined gene expression experiments and clinical survival data to predict the prognosis of patients of specific gene types . However, most results of these studies were data dependent and were not suitable for other data sets . We investigated the feasibility of survival risk predictions using high-throughput gene expression data and clinical data .",0.49494949494949486,0.17346938775510204,0.22222222222222224,0.07859317946799155
94,"This systematic review examines the relationship between diabetes and the incidence of dementia. The study identified 14 eligible longitudinal population-based studies, which revealed that individuals with diabetes have a higher risk of developing dementia than those without diabetes. This risk includes both Alzheimer's disease and vascular dementia. However, there are few detailed epidemiological data for risk factors, and the contribution of vascular disease and other comorbid conditions to dementia needs to be established. Mechanistic studies suggest that vascular disease and alterations in glucose, insulin, and amyloid metabolism underlie the pathophysiology, but it is unclear which of these mechanisms are clinically relevant. Further high-quality studies are needed to identify the risk factors and mechanisms that drive the association between diabetes and accelerated cognitive decline and dementia. Longitudinal studies that include detailed assessment of cognition, preferably in combination with neuroimaging, as well as detailed assessment of diabetes-related factors and comorbid conditions, will be best suited for this approach.","This systematic review examines the incidence of dementia in people with diabetes mellitus . We identified 14 eligible longitudinal population-based studies of variable methodological quality . The incidence of “any dementia” was higher in individuals with diabetes than in those without diabetes in seven of ten studies reporting this aggregate outcome . Further high quality studies need to be initiated, with objective diabetes assessment, together with reliable methods to establish the contribution of vascular disease and other comorbidity to dementia .",0.4621848739495798,0.2542372881355932,0.3025210084033614,0.09390561202043352
95,"This review paper aimed to assess the risk of developing interstitial lung disease (ILD) with the use of epidermal growth factor receptor tyrosine kinase inhibitors (EGFR-TKIs) gefitinib, erlotinib, and afatinib in patients with advanced non-small cell lung cancer. The study found that treatment with EGFR-TKIs was associated with a significantly increased risk of developing ILD, with an incidence of 1.6% for all-grade ILD and 0.9% for high-grade ILD, and a mortality rate of 13%. The study recommends that clinicians should monitor patients for respiratory symptoms and consider pulmonary toxicity as a diagnosis in patients receiving EGFR-TKI treatment. Further investigation is needed to determine whether concomitant use of corticoids and EGFR-TKIs can reduce the incidence of ILD associated with EGFR-TKIs.","Patients treated with EGFR-TKIs had a significantly increased risk of developing all-grade (OR, 1.74; 95% CI, 1.0–2.4%) and 0.9% (grade 3) ILD . No significant difference in the risk of ILD was found in sub-group analysis according to EGF-TKis . The potential role of insulin in the pathogenesis of dementia Hyperinsulinaemia, in the context of the insulin resistance syndrome, is a risk factor for artherosclerosis",0.3880597014925373,0.1306532663316583,0.22885572139303487,0.06308307430714659
96,"This survey paper provides a systematic literature review of various machine learning and deep learning techniques used for medical data analysis in recent years. The paper identifies a clear shift in the use of artificial intelligence techniques in the medical domain, with deep learning methods taking precedence over machine learning methods. The review discusses the challenges that medical data faces with respect to its analysis and presents various ML and DL techniques that have been used for medical image segmentation, classification, medical diagnosis, and dementia prognosis. The paper concludes that DL has been preferred more by researchers to work with medical data in recent years. This survey paper can be of high importance for researchers to observe relevant details and trends about the current research in computer science and medical research.","This literature review identifies a clear shift of artificial intelligence techniques used in the medical domain, with deep learning methods taking precedence over machine learning methods . This survey provides a comprehensive overview of the ML techniques including support vector machines, K-means clustering, decision trees, random forests, Nave Bayes, K nearest neighbors, neural networks, and convolution neural networks . Further this survey paper discusses the current influx of medical data and the challenges that medical data faces with respect to its analysis .",0.5283018867924528,0.3619047619047619,0.3584905660377359,0.23675637588197998
97,"The study investigated risk and protective factors associated with pediatric dry eye disease (DED) in relation to smartphone use rate according to region and age. The prevalence of DED was higher in the urban group and in older children, and smartphone use was found to be strongly associated with pediatric DED. The mean daily duration of smartphone use was longer in the DED group than controls, and outdoor activity appeared to be protective against pediatric DED. Older-grade students in urban environments had DED risk factors (long duration of smartphone use), and a short duration of outdoor activity time. The study recommends close observation and caution during VDT use, especially smartphones, for older children in urban areas. DED in children must be detected early and should be treated with appropriate medical and environmental interventions and education.","In 2014, the overall rate of smartphone use in Korea was 83 and 89.8 % in children and adolescents . We investigated risk and protective factors associated with pediatric dry eye disease (DED) in relation to smartphone use rate according to region and age . Methods: We enrolled 916 children and performed an ocular exam that included slit lamp exam and tear break-up time . In total, 9.1 % of children in the older-grade group were diagnosed with DED compared to 4 %",0.45161290322580644,0.2697674418604651,0.29493087557603687,0.1798407182627818
98,"The study aimed to explore patients' perceptions of sensitive health information and how such perceptions affect data sharing preferences. After conducting a systematic literature review, the researchers designed a mixed-method approach that used an individual's electronic health records (EHRs) to assess content sensitivity and preferences for granular data sharing for care and research. The study involved 25 patients with behavioral health conditions who were asked permission to access their EHRs, including those available through the state's health information exchange. The results showed that participants considered mental health, sexual and reproductive health, and alcohol use and alcoholism sensitive information, while they were willing to share information related to other addictions, genetic data, and general physical health information. The study concluded that patient views on EHR sensitivity and data sharing preferences are diverse, and there is a need for more patient-centered electronic consent mechanisms to accommodate patient needs. The proposed methodology provides new information about patient attitudes towards sensitive data and sharing preferences that can inform policy formation and guide the ongoing development of an electronic, patient-driven, informed consent platform for granular data sharing with personalized on-demand education.","Methods: A systematic literature review of methodologies employed to assess data sharing willingness and perceptions on data sensitivity was conducted . Twenty-five patients with behavioral health conditions, English and Spanish-speaking, were recruited . On average, participants recognized 82.7% of the 30 items from their own EHRs . Participants considered mental health (76.0%), sexual and reproductive health (75.0%) and alcohol use and alcoholism (50.0%) sensitive information .",0.3384615384615385,0.15503875968992245,0.24615384615384617,0.04883296981904997
99,The study investigates the early debates about the dietary causes of coronary heart disease (CHD) and the role of the sugar industry in shaping these debates. The authors examine internal documents and historical reports of the Sugar Research Foundation (SRF) and assemble their findings chronologically into a narrative case study. The study suggests that the sugar industry sponsored a research program in the 1960s and 1970s that successfully downplayed evidence that sucrose consumption was a risk factor for CHD while promoting fat as the dietary culprit. The authors recommend that policymaking committees should consider giving less weight to food industry-funded studies and include mechanistic and animal studies as well as studies appraising the effect of added sugars on multiple CHD biomarkers and disease development.,"Sugar Industry and Coronary Heart Disease Research : A Historical Analysis of Internal Industry Documentscoronary heart disease, sugar, research, industry sponsorship, risk factors, policy making, health consequences, biomarkers . The SRF sponsored its first CHD research project in 1965, a literature review published in the New England Journal of Medicine, which singled out fat and cholesterol as the dietary causes of CHD . As of 2016, sugar control policies are being promulgated in international,61 federal, state, and local venues .",0.39603960396039606,0.09999999999999999,0.19801980198019803,0.04434375515758637
100,"The article discusses the problem of the lack of proper indication of uncertainty in most prognostic models, which hampers their translation to primary care settings. The authors studied different methods for transforming classifiers into probabilistic/confidence-based predictors, where predictions are complemented with probability estimates/confidence regions reflecting their uncertainty. The analysis was performed with a Portuguese cohort of around 400 patients and validated in the publicly available ADNI cohort. The proposed approach can be applied to other diseases and prognostic problems. The main contributions of this work are an outright comparison between different methods to target uncertainty of predictions at patient-level, an ensemble-based approach combining different classifiers and methods to target uncertainty of predictions, and a new conformity measure for SVM.","A case study in ADPrognostic prediction , Mild cognitive impairment , Alzheimer’s disease , Uncertainty at patient-level , Venn-ABERS , Conformal prediction . To address this problem, we studied different methods for transforming classifiers into probabilistic/confidence-based predictors . We evaluated whether these methods produce valid predictions, where uncertainty estimates reflect the ground truth probabilities . Finally, we proposed an ensemble-based approach where predictions from multiple pairs of (classifier, uncertainty",0.4293193717277487,0.16931216931216933,0.2513089005235602,0.08849946901392203
101,"This scoping review provides a comprehensive summary of 91 studies that investigated the use of neural networks, specifically deep learning algorithms, for early diagnosis of Parkinson’s disease (PD) based on various data collected from different public and private sources, including medical image, biomedical voice, and sensor signal, for both PD and healthy control samples. The review identified the most commonly used data types and highlighted the best performance models based on the detection of specific symptoms of PD. Additionally, all technical experiment methods were reported, including submodel, dataset volume, training, testing, evaluation metrics, and validation type. The review concluded that neural networks play an integral and substantial role in combating PD, and suggested particular recommendations for healthcare professionals. The future work could be a meta-analysis to examine each study and provide a comprehensive comparison between them in terms of quality.","The Role of Neural Network for the Detection of Parkinson’s Disease (PD) is a chronic neurodegenerative disorder that has been ranked second after Alzheimer’s disease worldwide . There is no medical test(s) available to diagnose PD conclusively. Therefore, computer-aided diagnosis systems offered a better solution to make the necessary data-driven decisions and assist the physician . Results: Out of 1061 studies, 91 studies satisfied the eligibility criteria in this review .",0.30697674418604654,0.08450704225352113,0.1767441860465116,0.05205391507780102
102,"This paper provides a comprehensive survey of automatic text summarization (ATS), which is the method of reducing source text into a compact variant while preserving its knowledge and actual meaning. The paper outlines the different architectures of ATS, including extractive and abstractive text summarization technologies, and provides a deep taxonomy of the ATS domain. The taxonomy presents classical algorithms and modern deep learning ATS architectures, and reviews the significance and limitations of each approach. The paper also presents the past, present, and future research directions in the ATS domain, and highlights the challenges that need to be addressed in order to improve the quality of summaries. Overall, the paper emphasizes the importance of ATS as an eminent domain of research that is widely implemented and integrated into diverse applications to summarize and reduce text volume.","Text summarization is the method to reduce the source text into a compact variant, preserving its knowledge and the actual meaning . The taxonomy presents the classical ATS algorithms to modern deep learning ATS architectures . This paper presents the past, present, and future research directions in the ATS domain . It also presents the current limitations and challenges of ATS methods and algorithms, which would encourage researchers to try to solve these limitations and overcome new challenges .",0.5714285714285714,0.3173076923076923,0.4571428571428572,0.18915586219932246
103,"This article presents a qualitative review and meta-analysis of 42 English articles to assess the strength of evidence for an association between smoking and passive exposure to tobacco smoke and various manifestations and outcomes of tuberculosis (TB). The evidence was rated as strong for an association between smoking and TB disease, moderate for the association between second-hand smoke exposure and TB disease and between smoking and retreatment TB disease, and limited for the association between smoking and tuberculous infection and between smoking and TB mortality. The study concludes that smoking can have an important impact on many aspects of TB, and clinicians can confidently advise patients that quitting smoking and avoiding exposure to others’ tobacco smoke are important measures in TB control. The article aims to raise awareness among clinicians and public health workers about the importance of considering smoking as a factor in TB care and research.","Tobacco and tuberculosis: a qualitative systematic review and meta-analysis . To assess the strength of evidence in published articles for an association between smoking and passive exposure to tobacco smoke . Clinicians and public health workers working to fight TB may not see a role for themselves in tobacco control because the association between tobacco and TB has not been widely accepted . METHODS: Reference lists, PubMed, the database of the International Union Against Tuberculoses and Lung Disease and Google Scholar were",0.43478260869565216,0.23684210526315788,0.3130434782608696,0.12266810951675385
104,"This study proposes a mathematical model to improve the efficiency of patient scheduling for Intensive-Modulated Radiation Therapy (IMRT) in Taiwan. The research consists of two stages, with the first proposing an online stochastic algorithm to improve the performance of the present scheduling system, and the second considering the impact of future treatment to reduce patients' waiting time. The study validates the proposed model with real data and contributes to theory and practice by proposing a practical model to assist medical institutes in implementing patient scheduling more efficiently. The results show that the adaptive genetic algorithm performs better than traditional genetic algorithms and the waiting time of patients can be reduced by considering future scenarios under the base demand. However, the study has some limitations, such as assumptions regarding the biological growth of tumors and the absence of a cancellation mechanism, which could be addressed in future studies.","The Intensive-Modulated Radiation Therapy (IMRT) is one of the most important radiotherapies of cancers . For patients, if they can receive the treatment at the earliest possibility while diagnosed with cancers, their survival rate increases . The discussion of effective patient scheduling models of IMRT to reduce patients’ waiting time is still limited in literature . This research contributes to both theory and practice by proposing a practical model to assist the medical institute in implementing patient scheduling .",0.44642857142857145,0.2252252252252252,0.3214285714285714,0.10548120229892383
105,"This paper proposes a new method, called the Weight-based Multiple Empirical Kernel Learning with Neighbor Discriminant Constraint (WMEKL-NDC) method, for predicting mortality in patients with heart failure. The proposed method includes feature selection, assigning different weights to different kernel spaces, and integrating neighbor discriminant constraint into the classifier. The method is evaluated on a real clinical dataset and compared to state-of-the-art multiple kernel learning methods and basic methods. The results show that the proposed method achieves superior performance and identifies the top 10 clinical features that have a significant impact on heart failure mortality. These features are also described in terms of their medical meaning to provide crucial decision information for clinicians in heart failure treatment.","Weight-based multiple empirical kernel learning with neighbor discriminant constraint for heart failure mortality predictionHeart Failure Mortality Prediction Electronic Health Records Feature Selection Multiple Kernel Learning Heart Failure (HF) is one of the most common causes of hospitalization and is burdened by short-term (in-hospital) and long-term (6–12 month) mortality . However, due to the lack of a simple and effective prediction model, mortality prediction of HF is difficult, resulting in a low rate of control .",0.39195979899497485,0.16243654822335024,0.2613065326633166,0.0974775885326747
106,"The article discusses the use of Convolutional Neural Networks (CNN) for person recognition, specifically in addressing the issue of appearance-based identification. The authors propose a method that combines both image-based techniques and lengthy image sequences to improve the accuracy of person recognition. They fine-tune the CNN features using a unique loss function that combines pedestrian attribute data, resulting in better discriminative power. The proposed approach outperforms current state-of-the-art techniques, as demonstrated by promising outcomes on four hard person identification datasets. Overall, the authors aim to increase the amount of training samples and improve CNN features by combining pedestrian characteristics datasets with person recognition datasets.","On huge annotated datasets like Image Net, recent studies have demonstrated the effectiveness of features produced from pre-trained Convolution Neural Network (CNN) top layers . In order to address the issue of appearance-based identification, we put forth a feature extraction and matching method . We propose new labels that were produced by integrating a number of attribute labels included to the classification loss for the different pedestrian attribute labels . Features of CNN fared better than well written, hand-crafted descriptions .",0.4210526315789474,0.10638297872340427,0.2526315789473684,0.05951731734223028
107,The article highlights the importance of gait recognition and proposes using machine learning algorithms for human personality recognition based on outline and bounding box. The authors analyze optimal solution methods and find that spatial features play an important role in recognition. They suggest improving accuracy by introducing additional parameters and using other algorithms or neural networks to determine the position of human limbs.,"Gait Based Person RecognitionGait recognition; silhouette; shadow biometrics; computer vision; segmentationThe gait is a special feature that needs to be identified as it affects many parts of the body . Unlike fingerprint or retinal identifiers, gait recognition during epidemic periods is more relevant than face recognition . The study considers splitting the stream into frames and various options for background segmentation such as GrabCut and Mask R-CNN.",0.26356589147286824,0.015748031496062992,0.10852713178294573,0.011990726679243098
108,"This study proposes a novel recurrent network architecture to model the relational information between people in a photo for person recognition. The approach incorporates both contextual cues and visual appearance of person instances, and is trained end-to-end with annotated instances as inputs and corresponding labels as targets. The formulation achieves state-of-the-art performance on the PIPA dataset. ","In this work, we propose to model the relational information between people as a sequence prediction task . At the core of our work is a novel recurrent network architecture . In addition to relational cues, scene context is incorporated in our sequence prediction model with no additional cost . We demonstrate that this simple but elegant formulation achieves state-of-the-art performance on the newly released People In Photo Albums dataset .",0.5343511450381679,0.2945736434108527,0.38167938931297707,0.21945410950215524
109,"The paper discusses the implementation of a story generation system called Story Scrambler using recurrent neural networks. The system aims to generate new stories based on inputted stories with different storylines and characters or similar storylines and characters. The generated stories are evaluated based on grammar correctness, linkage of events, interest level, and uniqueness. By increasing the values of different parameters, the system tries to minimize train loss, and human evaluation shows an accuracy of 63%. The system's accuracy can be improved by considering contextual meaning and using synonyms. The system can be extended for generating messages, news articles, jokes, or posts.","In this paper, we have implemented a recurrent neural network methodology based text generation system called Story Scrambler . Our system aims to generate a new story based on a series of inputted stories . We have considered the stories with different storyline and characters . The results generated by the system are analyzed based upon parameters like grammar correctness, linkage of events, interest level and uniqueness .",0.562874251497006,0.3393939393939394,0.43113772455089816,0.1585245475488916
110,"The paper presents a neural network model for generating social media text using Weibo data. The model utilizes word embedding and RNN with LSTM cells, and introduces an attention mechanism to improve performance compared to traditional models. The study suggests that further improvements can be made by increasing and cleaning the dataset, and adjusting model structure and parameters. Overall, the system outperforms existing NLG systems in the social media field.","This paper presents a neural network model building a social media NLG system . Compared with state-of-art model, our system outperforms the existing NLG systems in the social media field . This paper discusses a kind of Weibo text generating method based on neural networks model . We collect a large number of micro blog as raw data, and use the word embedding in order to map the word to a low dimensional vector space .",0.4861111111111111,0.2112676056338028,0.2777777777777778,0.2105818714408263
111,"The distribution of fake news on social media is a growing problem, and detecting it has become important. The paper presents an ensemble approach called CMTR-BERT that combines multiple text representations to address the sequential limits of transformer-based language models and enable the incorporation of contextual information. CMTR-BERT achieves state-of-the-art results for two benchmark datasets and shows the importance of context information for fake news detection. The authors plan to further explore the use of human summarizations and other datasets to gain a deeper understanding of effective fake news detection.","We present an approach to the problem that combines the power of transformer-based language models while simultaneously addressing one of their inherent problems . Our framework, CMTR-BERT, combines multiple text representations, with the goal of circumventing sequential limits and related loss of information the underlying transformer architecture typically suffers from . Additionally, it enables the incorporation of contextual information . Extensive experiments on two very different, publicly available datasets demonstrates that our approach is able to set new state-of-",0.49142857142857144,0.19653179190751446,0.27428571428571424,0.1277114614960333
112,"This paper discusses the development of a lecture summarization service using BERT and K-means clustering. The service utilizes deep learning models to produce high-quality summaries of lectures, and also includes lecture and summary management features. While the BERT model shows promise for extractive summarization, there is still room for improvement in certain areas. Overall, the lecture summarization service represents an improvement over dated natural language processing models and provides a useful tool for university students.","python-based RESTful service uses the BERT model for text embeddings and K-Means clustering to identify sentences closest to the centroid for summary selection . The lecture summarization service utilizes the most current deep learning NLP model called BERT to produce summaries for users, based on their specified configuration . However, most of the approaches leave room for improvement as they utilize dated natural language processing models .",0.4895104895104895,0.25531914893617025,0.36363636363636365,0.13603406888135514
113,"Generating a summary from multiple documents is challenging due to the lack of parallel data. This paper presents a novel adaptation method that combines an extractive summarization algorithm with an abstractive encoder-decoder model to generate summaries from multiple documents. The method uses the maximal marginal relevance method to select representative sentences and requires no training data. The system performs well compared to state-of-the-art approaches, as judged by both automatic metrics and human assessors. The PG-MMR system outperforms strong extractive and abstractive baselines.","Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization multi-document summarization is a challenging task . The neural encoder-decoder framework has recently been exploited to summarize single documents, but its success can in part be attributed to the availability of large parallel data automatically acquired from the Web . In contrast, parallel data are scarce and costly to obtain .",0.3355704697986577,0.04081632653061224,0.20134228187919465,0.010177073349729792
114,"The paper proposes an attentional encoder-decoder model for abstractive text summarization, which achieves state-of-the-art performance on two different corpora. Several novel models are proposed to address critical problems in summarization, leading to further improvements in performance. Additionally, a new dataset for multi-sentence summarization is introduced, and performance benchmarks are established. Future work will focus on building more robust models for multi-sentence summaries.","Abstractive Text Summarization using Sequence-to-sequence RNNs . We propose several novel models that address critical problems in summarization that are not adequately modeled by the basic architecture . Each of our proposed novel models addresses a specific problem in abstractive summarizing, yielding further improvement in performance . As part of our future work, we plan to focus our efforts on this data .",0.46511627906976744,0.1889763779527559,0.31007751937984496,0.11569381342591695
115,"The use of sequence generative models with RNN variants has shown promise in abstractive document summarization, but they still have limitations when dealing with long sequences. Current models employ a unidirectional decoder which only reasons about the past, resulting in unbalanced outputs. To address these issues, an end-to-end trainable bidirectional RNN model is proposed with a bidirectional encoder-decoder architecture and bidirectional beam search mechanism. Experimental results on the CNN/Daily Mail dataset demonstrate the superiority of the proposed model over current state-of-the-art models. However, there is a need for further research to tackle the OOV problem and propose evaluation metrics beyond ROUGE.","Sequence generative models with RNN variants, such as LSTM, GRU, show promising performance on abstractive document summarization . However, they still have some issues that limit their performance, especially while dealing with long sequences . To this end, we propose an end-to-end trainable bidirectional RNN model to tackle the aforementioned issues . The model has a bidirectional encoder-decoder architecture; in which the encoder and the decoder are bidirectional LS",0.5536723163841808,0.2857142857142857,0.38418079096045205,0.18214268873056239
116,"This paper compares the impact of global and local attention mechanisms on the LSTM model for abstractive text summarization using a dataset of Amazon Fine Food Reviews and evaluating it using the GloVe dataset. The results show that the global attention-based model produces better ROUGE-1, while the local attention-based model gives higher ROUGE-2. However, the dataset contains a lot of symbols and unknown phrases, affecting the ROUGE score. Resetting all parameters may give higher scores for both models, and some methods can be developed to improve the performance, such as changing the dataset or handling OOV in data preprocessing.","The Impact of Local Attention in LSTM for Abstractive Text Summarization . This paper focuses on comparing the impact of the local attention in Long Short-Term Memory (LSTM) model to generate an abstractive text summarization (ATS) The global attention-based model produces better ROUGE-1, where it generates more words contained in the actual summary . The local attention-basing gives higher ROUGe-2, where the mechanism of local attention considers the subset of input words instead of the whole input words",0.4891304347826087,0.25274725274725274,0.3695652173913044,0.13214590298786147
117,"This paper proposes an arbitrary view transformation model (AVTM) for gait recognition in person authentication, which addresses the challenge of robustness to view changes. The AVTM is capable of accurately matching gait traits from an arbitrary view by constructing 3D gait volume sequences and generating 2D gait silhouette sequences of training subjects. The AVTM is further extended with a part-dependent view selection scheme (AVTM_PdVS) to improve recognition accuracy. Experimental results demonstrate that the AVTM improves cross-view matching accuracy, and the AVTM_PdVS achieves higher accuracy than comparative methods in most settings. The proposed arbitrary-view framework also improves the accuracy of other approaches such as RankSVM.","Gait recognition is a useful biometric trait for person authentication . View transformation models (VTMs) have been proposed to solve this problem . The target views may not coincide with discrete training views . We propose an arbitrary VTM (AVTM) that accurately matches a pair of gait traits from a real situation . In addition, we train the AVTM with gait features extracted from the 2D sequences .",0.4186046511627907,0.1176470588235294,0.19767441860465115,0.02367731591082576
118,"The article proposes a model for text summarization called T-BERTSum, which combines BERT's encoding capabilities with topic embedding to improve contextual representation and generate high-quality summaries. The model uses a neural topic model to infer topics and guide generation. The transformer network and LSTM layers capture long-term dependencies and timing information. The two-stage extractive-abstractive model reduces redundancy and achieves state-of-the-art results on CNN/Daily Mail and XSum datasets. The proposed model generates consistent and high-quality summaries.","T-BERTSum: Topic-Aware Text Summarization Based on BERT Bidirectional Encoder Representations from Transformers (BERTs) This is an improvement over previous models, in which the proposed approach can simultaneously infer topics and generate summarization from social texts . In this article, we propose a topic-aware extractive-abstractive model named T-BRETSum, based on neural topic model (NTM), to guide the generation with the topic .",0.45333333333333325,0.14864864864864863,0.21333333333333332,0.03210305042888374
119,"The paper proposes a hybrid approach for stock price movement prediction using machine learning, deep learning, and natural language processing. The study uses historical data of NIFTY 50 index values of the National Stock Exchange of India from 2015-2017 to build various predictive models using machine learning and deep learning techniques. The models are fine-tuned and tested to predict the closing value of NIFTY 50 for the period January 2018 till June 2019 with a prediction horizon of one week. The paper further augments the predictive model by integrating sentiment analysis of social media to correlate public sentiment with the market sentiment. The study concludes that public sentiments in social media serve as a significant input in predictive model building for stock price movement. The sentiment analysis-enhanced model is found to be the best among all models in accurately forecasting the stock price movement of NIFTY 50.","We select the NIFTY 50 index values of the National Stock Exchange (NSE) of India, and collect its daily price movement over a period of three years (2015 – 2017) Based on the data of 2015 – 2017, we build various predictive models using machine learning . For predicting the actual closing price of the stocks, various regression models have been used . We further augment the predictive model by integrating a sentiment analysis module on twitter data to correlate the public sentiment of stock prices with the market sentiment .",0.5254237288135594,0.2820512820512821,0.37288135593220345,0.1490697192281105
120,"The paper proposes an unsupervised method for query-focused multi-document summarization using transfer learning from pre-trained sentence embedding models. The method combines semantic similarity and BM25 to select top-k sentences based on relevance to the query and uses maximal marginal relevance to re-rank them for query-relevant summary. Experimental analysis on DUC'2005-2007 datasets shows that the proposed method outperforms several state-of-the-art systems and achieves comparable results to the best performing systems, including supervised deep learning-based methods. The paper concludes by suggesting exploring the potential of newer models such as T5 and GPT-3 for text summarization and investigating transfer learning for summary generation.","Unsupervised query-focused multi-document summarization (QF-MDS) is the process of automatically generating an informative summary from a collection of documents that answers a pre-given query . In this paper, we propose to leverage transfer learning from pre-trained sentence embedding models to represent documents’ sentences and users’ queries . The proposed method is unsupervised, simple, efcient, and requires no labeled text summarizing training data .",0.39325842696629215,0.1590909090909091,0.2696629213483146,0.08812061087287253
121,"The study developed an automatic abstractive text summarization algorithm in Japanese using a neural network with a BERT encoder and Transformer-based decoder. However, issues were encountered, such as repeated contents in the summary sentence and the model's inability to handle unknown words. The study suggests improvements such as utilizing coverage and copy mechanisms to solve these problems. Future experiments will explore these recommendations and compare results.","We used a sequence-to-sequence encoder-decoder model for experimentation purposes . The encoder obtained a feature-based input vector of sentences using BERT . A transformer-based decoder returned the summary sentence from the output as generated by the encoder . We conducted an experiment to demonstrate Japanese abstractive text summarization using a neural network model . In the future, we will explore these recommendations with new experiments .",0.4925373134328358,0.196969696969697,0.26865671641791045,0.12086114781299016
122,"This paper discusses the use of automatic text summarization and topic modeling in natural language processing. The authors propose an algorithm that combines TFIDF keyword extraction, LSA topic modeling using truncated SVD, and BERT encoder model to extract useful sentences from a text document. The proposed algorithm is shown to achieve higher accuracy in summarization than using LDA topic modeling alone. The authors suggest that the proposed algorithm could be used in abstractive text summarization for even greater accuracy. Overall, the paper highlights the potential for combining different techniques in natural language processing to improve text summarization.","The Branch of NLP that deals with it, is automatic text summaryr . The proposed research work will be summarizing the long textual document using LSA topic modelling along with TFIDF keyword extractor for each sentence in a text document . On the other hand topic modelling is a NLP task that extracts all the relevant topics from the text . This paper has demonstrated an experiment in contrast with the extractive text summarization task of converting the text into short fluent summaries .",0.46327683615819204,0.1142857142857143,0.2598870056497175,0.05536202783933869
123,"The study describes an approach to extractive summarization using BERT model and clustering algorithms to generate summaries of suitable size depending on the text. The main goal is to provide students with a reliable summary of long lecture videos for revision. However, the existing model has the disadvantage of not representing the entire context of the document in a smaller number of sentences. The proposed model overcomes this by dynamically producing summaries of suitable sizes depending on the size of the story. The study mainly focuses on CNN/Dailymail dataset, but the proposed model can be made to run on other standard datasets like DUC and NYT news. Future work includes deploying the model on lectures from various MOOC platforms and developing a website to take the document as input and provide the user with the required summary.","We used the existing BERT model which stands for Bidirectional Encoder Representations from Transformers to produce extractive summarization . This process is aided by scoring functions and clustering algorithms to help choose the most suitable sentences . In the future, the proposed model can be made to run on other standard datasets like document understanding conferences (DUC) and The New York times (NYT) news . Our main goal was to help students who have to go through pages of lectures by providing them with a reliable summary that",0.49327354260089695,0.2171945701357466,0.28699551569506726,0.14000067918191614
124,"The paper proposes a contrastive learning model called SeqCo for supervised abstractive text summarization. The model maximizes similarities between a document, its gold summary, and model-generated summaries during training, leading to improved performance on three summarization datasets. The authors plan to extend SeqCo to multilingual or cross-lingual text generation tasks and develop methods for regularizing different contrastive objectives. The paper also discusses experiments that found using multiple contrastive objectives did not improve results.","We propose a contrastive learning model for supervised abstractive text summarization . We view a document, its gold summary and its model generated summaries as different views of the same mean representation and maximize the similarities between them during training . Our model achieves better faithfulness ratings compared to its counterpart without contrastive objectives . In future, we plan to extend SeqCo in the multi-lingual or crosslingual text generation tasks .",0.5874125874125875,0.326241134751773,0.4195804195804196,0.229287129392762
125,"The exponential growth of web textual data has led to difficulty in analyzing and extracting useful information. Automatic text summarization is used to address this issue. This paper proposes a mechanism using the BART model for text summarization, which consists of an encoder and decoder. BERT, T5, and Roberta are compared with BART. The proposed system can quickly and accurately summarize text even for massive amounts of data. Deep learning-based abstractive summarization models have been created to better balance and enhance the summarization process. Future research can analyze various learning models to improve effectiveness.","Text Summarization is defined as creating a short, accurate, and fluent summary of a longer document . This paper will provide a mechanism where it does the text summarization quickly and effectively even for large data . It is very difficult for human beings to analyze and extract useful information from huge data especially when the text is large in size and longer documents which increases the time taken to summarize it . The main function of ATS is to automatically create a brief and understandable summary by extracting the main ideas from the source",0.4385026737967914,0.11891891891891891,0.21390374331550804,0.030870999276941403
126,"The paper proposes a framework called Timeline-Sumy for summarizing social media data about an entity in chronological order. The framework consists of two phases: episode detecting and summary ranking. In the episode detecting phase, the framework uses life cycle models to detect timeline episodes, which exhibit sudden-rise-and-heavy-tail patterns on time series. The proposed Bayesian nonparametric model captures regular content, hashtag content, and temporal information simultaneously, and Gibbs sampling is employed to infer the model parameters. A fast burn-in strategy based on temporal bursts is further introduced to speed up the model inference. In the summary ranking phase, the framework uses a learning-to-rank approach to rank social media posts in each episode. The approach is flexible to integrate various types of signals from social media data for timeline summarization.","Timeline has been proven to provide an effective and efficient access to understand an entity . However, summarizing the timeline about an entity with social media data faces new challenges . First, key timeline episodes about the entity are typically unavailable in existing social media services . Second, the short, noisy and informal nature of social media posts determine that only content-based summarization could be insufficient . In summary ranking, we explicitly model temporal information with life cycle models to detect timeline episodes .",0.37037037037037035,0.14018691588785046,0.17592592592592593,0.07924863368660977
127,"This paper provides an overview of extractive text summarization, which is the process of obtaining salient information from a text document and presenting it in a concise summary. Extractive summarization focuses on choosing important sentences and paragraphs from the original document based on linguistic and statistical features. The paper reviews various techniques, benchmarking datasets, and challenges associated with extractive summarization. The aim is to provide a less redundant, highly adhesive, and coherent summary with depth information. Although research on summarization has come a long way, there is still much to be done in terms of addressing the challenges of extractive text summarization.","Text Summarization techniques are classified into abstractive and extractive summarization . This technique focuses on choosing how paragraphs, important sentences, etc produces the original documents in precise form . The implication of sentences is determined based on linguistic and statistical features . In this paper, the various techniques, populous benchmarking datasets and challenges of extractive summaryization have been ascertained . Over the time, focused has drifted from summarizing scientific articles to advertisements, blogs, electronic mail messages and news articles ",0.4745762711864407,0.21714285714285714,0.33898305084745767,0.12056076457559396
128,"This paper proposes a new model called Feature-Guiding Generative Adversarial Networks (FGGAN) to improve text generation. FGGAN uses a feature guidance module to extract text features from the discriminator network and convert them into feature guidance vectors to better guide the generator network. Additionally, the paper formulates text semantic rules to restrict the tokens during the sequence generation process, leading to more realistic text. Experimental results demonstrate the effectiveness and superiority of FGGAN over other models in terms of fitting data distribution and generating more realistic text data.","Generative Adversarial Networks (GAN) has been widely used in text generation . In combination with reinforcement learning, GAN uses the output of discriminator as reward signal of reinforcement learning to guide generator training, but the reward signal is a scalar and the guidance is weak . To solve the problem of insufficient feedback guidance from the discriminator network, FGGAN uses a feature guidance module to extract text features, convert them into feature guidance vectors and feed them into the generator network .",0.4999999999999999,0.2891566265060241,0.2857142857142857,0.24632495258154827
129,"This paper proposes the VGAN model, which combines generative adversarial nets (GAN) with variational autoencoder (VAE) to generate realistic text. The generative model uses a recurrent neural network and VAE, while the discriminative model uses a convolutional neural network. The model is trained using policy gradient and evaluated using negative log-likelihood and BLEU score. The results show that VGAN outperforms previous models on three benchmark datasets. The authors suggest future work using deep deterministic policy gradient and different discriminative models.","Text Generation Based on Generative Adversarial Nets . Instead of using standard GAN, we combine variational autoencoder (VAE) with generative adversarial net . The discriminative model is a convolutional neural network . We train the model via policy gradient . In the future, we plan to use deep deterministic policy gradient [11] to train the generator better .",0.5373134328358209,0.2575757575757576,0.3880597014925373,0.14933701547795597
130,"The paper proposes Affect-LM, an LSTM language model for generating conversational text conditioned on affect categories. The model allows for customization of emotional content through a design parameter and produces naturally looking emotional sentences without sacrificing grammatical correctness. Additionally, Affect-LM learns affect-discriminative word representations and improves language model prediction. The paper suggests future work exploring language generation conditioned on other modalities and applications such as dialogue generation for virtual agents.","Affect-LM enables us to customize the degree of emotional content in generated sentences through an additional design parameter . In this paper, we propose an extension to an LSTM (Long Short-Term Memory) language model for generating conversational text, conditioned on affect categories . Perception studies conducted using Amazon Mechanical Turk show that AFfectLM generates naturally looking emotional sentences without sacrificing grammatical correctness .",0.5185185185185185,0.3157894736842105,0.3407407407407407,0.24733151461535574
131,"The paper proposes a new architecture for Variational Autoencoder (VAE) for text generation, which blends feed-forward convolutional and deconvolutional components with a recurrent language model. The new architecture exhibits several advantages, such as faster run time and convergence, better handling of long sequences, and avoidance of some of the major difficulties posed by training VAE models on textual data. The authors have also shown that the feed-forward part of the model architecture makes it easier to train a VAE, and they have introduced a new cost term to encourage the model to rely on the latent vector. The paper evaluates the trade-off between the KL-term and the reconstruction loss and plans to apply the VAE model to semi-supervised NLP tasks in the future.","In this paper we explore the effect of architectural choices on learning a Variational Autoencoder (VAE) for text generation . In contrast to the previously introduced VAE model for text where both the encoder and decoder are RNNs, we propose a novel hybrid architecture that blends fully feed-forward convolutional and deconvolutional components with a recurrent language model . Our architecture exhibits several attractive properties such as faster run time and convergence .",0.47474747474747475,0.25510204081632654,0.303030303030303,0.1617226372095935
132,"This paper focuses on improving the training and convergence of Generative Adversarial Networks (GAN) for text generation, by redefining the loss function and designing a more suitable network structure for the discriminant model. The proposed model, TG-SeqGAN, incorporates a truth-guided method and self-attention mechanism to generate text closer to real data and obtain richer semantic information. Experiments show that the proposed model achieves better results in terms of convergence speed and text quality.","Text Generation Service Model Based on Truth-Guided SeqGAN Text generation, generative adversarial networks, self-attention mechanism, truth-guided . GAN has been successfully applied to the generation of text content such as poetry and speech, and it is a hot topic in the field of text generation . For the generation model, this paper redefines on the loss function . This paper designs a more suitable network structure .",0.5774647887323944,0.21428571428571427,0.23943661971830985,0.11405175707954032
133,"This paper proposes a new approach for Gait Recognition using a deep convolutional neural network with 3D convolutions and a special input format including gray-scale image and optical flow to capture spatio-temporal features. The approach is evaluated on three different datasets, showing comparable to better performance in comparison with previous approaches, especially for large view differences. The proposed approach can handle view, clothing, and walking speed invariance, which are challenging factors in Gait Recognition. The results suggest the high potential of CNNs for Gait Recognition, and future improvements can be made by using larger databases and better hardware.","Convolutional Neural Networks uses 3D convolutions for Gait Recognition in multiple views capturing spatio-temporal features . A special input format, consisting of the gray-scale image and optical flow enhance color invaranice . The approach is evaluated on three different datasets, including variances in clothing, walking speeds and the view angle. The results show a comparable to better performance in comparison with previous approaches, especially for large view differences .",0.7023809523809523,0.45783132530120485,0.4523809523809524,0.31256332554832533
134,"The paper explores the potential of using texture information extracted from millimeter wave (mmW) images for person recognition, focusing on three mmW body parts: face, torso, and whole body. The authors report experimental results using hand-crafted and learned features from convolutional neural networks (CNNs) models. They find that the mmW torso region is the most discriminative body part, followed by the whole body and face. CNN features outperform hand-crafted features on mmW faces and the entire body, but hand-crafted features achieve outstanding results for torso-based person recognition. The authors also analyze different multi-algorithmic and multi-modal fusion techniques, improving verification results to 2% EER and identification rank-1 results up to 99%. The paper suggests future work could explore fusing texture with shape and images from other ranges of the spectrum to achieve improved recognition results.","Different mmW body parts have been considered: face, torso and whole body . In this paper, we analyze different multi-algorithmic and multi-modal techniques . The most common techniques are super resolution [33], 23.25%, and 29.75%, respectively . We have carried out experiments with several hand-crafted features and some state-of-the-art deep learning features . For future work, we will consider fusing texture with shape (see previous work [7] and texture information jointly [",0.35185185185185186,0.205607476635514,0.2407407407407407,0.08050491444799435
135,"The study demonstrates the importance of human-related information in GIFs for emotion recognition and proposes a human-centered approach utilizing a Keypoint Attended Visual Attention Network (KAVAN). The framework incorporates a facial attention module and a hierarchical segment temporal module to extract visual features and learn global GIF representations. The results of experiments conducted on the MIT GIFGIF dataset show that the proposed framework outperforms the existing state-of-the-art techniques. Additionally, the facial attention module provides reliable facial region mask predictions, enhancing the interpretability of the model. Overall, the findings of this study highlight the potential of utilizing GIF's unique properties for emotion recognition and can have significant implications for developing advanced applications in the field of computer vision and social media analysis.","Human-Centered Emotion Recognition in Animated GIFsEmotion recognition,Visualization, Feature extraction , Task analysis , Videos , Heating systems , Social networking (online) Most previous studies on automated GIF emotion recognition fail to effectively utilize GIF's unique properties, and this potentially limits the recognition performance . The facial attention module exploits the strong relationship between GIF contents and human characters, and extracts frame-level visual feature with a focus on human faces .",0.3794871794871794,0.11398963730569948,0.1641025641025641,0.046017433875950024
136,"The article introduces ViT5, a pretrained Transformer-based encoder-decoder model for the Vietnamese language that is trained on a large corpus of high-quality and diverse Vietnamese texts. ViT5 is benchmarked on two downstream tasks, Abstractive Text Summarization and Named Entity Recognition, and achieves state-of-the-art results on Vietnamese Text Summarization and competitive results on Named Entity Recognition. The article also discusses the importance of context length during the self-supervised pretraining stage, which positively influences downstream performance.","ViT5: Pretrained Text-to-Text Transformer for Vietnamese Language GenerationVietnamese language, Transformer-based model, T5 self-supervised pretraining, text generation, Named Entity Recognition, state-of-the-art results, context length.e introduce ViT5, a pretrained Transformerbased encoder-decoder model for the Vietnamese language . We benchmark Vit5 on two downstream text generation tasks, Abstractive Text Summarization .",0.5588235294117647,0.3582089552238806,0.2941176470588235,0.18053536299762124
137,"The article discusses automatic text summarization, which is used to compress documents while maintaining their main ideas. The proposed model, Long-Trans-Extr, uses Longformer as the sentence encoder, Transformer as the document encoder, and an MLP classifier to extract important sentences from long documents. The model is evaluated on three benchmark datasets and shows superior performance on long documents, achieving competitive results on the CNN/DailyMail and the best results on the long CNN dataset.","Extractive text summarization extracts important sentences from the original document to serve as the summary . To effectively represent the document, we propose a hierarchical document representation model Long-Trans-Extr for Extractive Summarization . The model uses Longformer as the sentence encoder and Transformer as the document encoder . This model achieves 43.78 (Rouge-1) and 39.71 (Ruuge-L) on CNN/DailyMail . It achieves 33.75 (R",0.5314685314685315,0.2695035460992908,0.3496503496503497,0.14736550573608087
138,"The study aimed to investigate the recognition of emotional expressions in cartoon faces and the impact of key facial features (mouth, eyes, and eyebrows) on emotion recognition. Three experiments were conducted, and the results showed a happiness recognition advantage in cartoon faces, with happy expressions being recognized more accurately than sad and neutral expressions. The study also found that the mouth was crucial for happiness recognition, while the eyebrows were essential for sadness recognition. The study provides insights into the perception mechanism underlying emotion recognition in cartoon faces and has implications for the development of emotional and social artificial intelligence.","Emotion Residue in Neutral Faces, emotion recognition, facial features, expression intensity, happy, sadCartoon faces are widely used in social media, animation production, and social robots because of their attractive ability to convey different emotional information . Therefore, three experiments were conducted in this study to systematically explore a recognition process for emotional cartoon expressions (happy, sad, and neutral) Across the experiments, three presentation conditions were employed: (1) a full face; (2) individual feature only (with two other features concealed);",0.4044943820224719,0.09090909090909093,0.23595505617977525,0.049889197686752436
139,"The paper proposes PEGASUS, a pre-trained sequence-to-sequence model with a self-supervised objective tailored for abstractive text summarization. The model generates summaries by filling in gaps left by selected sentences, similar to an extractive summary. The authors evaluate PEGASUS on 12 diverse downstream summarization tasks, achieving state-of-the-art performance and demonstrating the model's adaptability to new datasets. The paper also includes a study of different gap-sentence selection methods and the effects of various pre-training configurations.","We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills . Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores . Our model summaries achieved human performance on multiple datasets using human evaluation . In this work, we propose pre-training large Transformer-based encoder-decoder models on massive text corpora with a new self",0.38709677419354843,0.130718954248366,0.21935483870967742,0.0238674748610786
140,"This paper presents an integrated Deep Neural Network (DNN) approach for recognizing emotions from cartoon images, which has not been extensively covered in existing works. The approach utilizes Mask R-CNN for character detection and state-of-the-art deep learning models for emotion classification. The proposed approach was trained on a dataset of size 8K from two cartoon characters ('Tom' and 'Jerry') with four different emotions, and achieved an accuracy score of 0.96. VGG 16 outperformed other deep learning models in emotion classification with an accuracy of 96% and F1 score of 0.85. This integrated DNN approach outperforms state-of-the-art approaches.","Understanding cartoon emotion using integrated deep neural network on large datasetAnimation Cartoon Character Detection Convolutional Neural Network Emotion Face Segmentation Mask R-CNN VGG16Emotion is an instinctive or intuitive feeling as distinguished from reasoning or knowledge . Existing works have mostly focused well on recognizing basic emotions from human faces . However, the emotion recognition from cartoon images has not been extensively covered . In this paper, we present an integrated Deep Neural network (DNN) approach that deals with recognizing emotions from cartoon",0.41935483870967744,0.2391304347826087,0.2043010752688172,0.1622556843099952
141,"The paper discusses the challenges of facial emotion recognition and existing methods for solving it, including deep learning approaches. The authors propose a hybrid approach based on RNN and CNN for facial emotion recognition that performs well on datasets with varying faces, poses, occlusions, and illuminations. They compare their approach with traditional machine learning models and show that it outperforms them on publicly available datasets such as EMOTIC, FER-13, and FERG. The authors plan to incorporate more deep learning methods and conduct experiments on other available datasets in the future.","In the past years, various researches have been introduced framework for facial emotion recognition using deep learning methods . Our hybrid model is also able to produce good results with less training datasets in the publicly available datasets like EMOTIC, FER13, and FERG . In future, we will incorporate more deep learning techniques to improve the results and also try to conduct some more experiments on other available data . The performance of our model for FER14 dataset is best as compare to traditional machine learning models .",0.4914285714285714,0.21965317919075145,0.28571428571428575,0.16665914393073042
142,"The he paper proposes an animated GIF emotion recognition algorithm based on ResNet-ConvGRU, which extracts spatial and temporal features of GIF images for sentiment classification. The proposed method outperforms classical emotion recognition algorithms like VGGNet-ConvGRU, ResNet3D, CNN-LSTM, and C3D on the GIFGIF dataset, providing finer-grained analysis for studying public opinion trends. The model converts GIF short videos into static image sequences and extracts features using ResNet and ConvGRU networks, respectively, and achieves higher accuracy in emotion recognition. However, further research is needed to validate the performance on different datasets and the model's robustness and universality.","Research on Animated GIFs Emotion Recognition Based on ResNet-ConvGRUGIF, emotion recognition, ResNet, ConvGRU, spatial-temporal features, sentiment classification, social media, public opinion trends . At present, most of the research on GIF affection recognition fails to make full use of spatial characteristics of GIF images, which limits the performance of model recognition to a certain extent . The GIFGIF dataset is used to verify the experiment . A GIF emotion recognition algorithm based on Res",0.47398843930635837,0.22222222222222224,0.27745664739884396,0.117686409264064
143,"The use of facial recognition systems in social media video-sharing applications like animoji and memoji is critiqued in this paper due to the ways in which they classify and categorize racial identities. The paper explores the potential dangers of racializing logics in these systems of classification and how data collected through facial recognition systems may interact with identity-based forms of classification. Animated GIFs and animoji/memoji share many similarities as personalizable forms of lively movement used for social purposes online. However, animated reaction GIFs are also racialized and codified by businesses like Giphy, which profits from animation's racializing logics. The paper argues for explicit philosophies of data justice and design justice in the world of digital animation to subvert the racializing tendencies of the digital animate.","racial recognition, emotion and race in animated social media are increasingly common components of commercial smart phones such as the iPhone X and the Samsung Galaxy S9 . These technologies are also increasingly being put to use in consumer-facing social media video-sharing applications, such as Apple’s animoji and memoji, Facebook Messenger’s masks and filters and Samsung’s AR Emoji . This paper examines the ways these facial recognition systems classify and categorize emotional expression into mediated socially legible forms .",0.37142857142857144,0.12500000000000003,0.2,0.04912334186697334
144,"This paper explores the use of OpenAI GPT-2 and BERT models for text generation and prediction, particularly for summary generation, machine translation, and automatic question answering. The authors use two new corpora to pre-train the GPT-2 model and compare its performance to BERT in completing long sentence generation and masked word generation prediction tasks. While both models perform well, there are still some limitations such as readability and training methods. Future work will aim to address these shortcomings.","The OpenAI GPT2 and BERT models are currently widely used language models for text generation and prediction . We train the machine for specific tasks and then use it in natural language processing . This paper will use two new corpora to train the GPT-2 model, used to generate long sentences and articles, and finally perform a comparative analysis . At the same time, we will use the BERT model to complete the task of predicting intermediate words based on the context.",0.5838509316770186,0.2138364779874214,0.3602484472049689,0.15624653061358107
145,"This paper presents a novel model for affective text generation that incorporates emotion as a prior for the state-of-the-art text generation model. The model generates affect-driven and topic-focused sentences without compromising on grammatical correctness, and provides flexibility in controlling the category and intensity of the emotion. The model outperforms existing affective text generation models in automated evaluations and human studies. The model has wide applications in dialogue generation, therapy chatbots, story and advertisement completion.","In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text . The model gives a user the flexibility to control the category and intensity of emotion as well as the topic . Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities .",0.4657534246575343,0.20833333333333331,0.3013698630136986,0.09534756522677007
146,"NUBIA is a methodology for building automatic evaluation metrics for text generation using machine learning models. It consists of three modules: a neural feature extractor, an aggregator, and a calibrator. NUBIA outperforms existing metrics in machine translation and image captioning and matches state-of-the-art metrics in correlation with human judgement. It is modular, explainable, and has potential for unifying evaluation of various text generation tasks.","NUBIA: NeUral Based Interchangeability Assessor for Text GenerationNUBIA, automatic evaluation metrics, text generation, machine learning, neural feature extractor . The model implemented is modular, explainable and set to continuously improve over time . This methodology achieves state-ofthe-art results across evaluation of machine translation and image captioning strongly building on the successes of recent NLP architectures such as RoBERTa and GPT-2 .",0.5,0.23809523809523808,0.3125,0.14407320029919884
147,"This research proposes an abstractive text summarization model that generates summaries based on extracted keywords, and compares it with a summary generated by a philologist. The proposed model increases the accuracy and readability of the summary compared to the human-generated summary. The study develops a deep learning model and compares it with logistic regression and support vector machine algorithms, finding that the proposed model outperforms the other two models in overall performance using F1-measure. The research aims to expand the scope of the procedure by training additional positions and larger models at WebScaleText Corpora.","Abstractive Text Summarization Using Hybrid Technique of Summarizing . The extractive summary can select chunks of sentences that are very related to the document . This research proposed an abstractive text summarization model, it gets data from source data (e.g., Daily Mail/CNN) or other documents and two summaries of this are generated. The summary generated by the philologist kept as a model to compare with the machine-generated summary. The proposed model increased the accuracy and readability of the",0.537142857142857,0.254335260115607,0.29714285714285715,0.15813613732611886
148,"The paper proposes DISCOBERT, a discourse-aware neural summarization model that uses sub-sentential discourse units as selection basis to reduce redundancy in summaries and captures long-range dependencies using structural discourse graphs encoded with Graph Convolutional Networks. DISCOBERT outperforms state-of-the-art summarization models on popular benchmarks. Future work includes exploring better graph encoding methods and applying discourse graphs to other long document encoding tasks.","DISCOBERT extracts sub-sentential discourse units (instead of sentences) as candidates for extractive selection on a finer granularity . Experiments show that the proposed model outperforms state-of-the-art methods by a significant margin on popular summarization benchmarks compared to other BERT-base models . For future work, we will explore better graph encoding methods, and apply discourse graphs to other tasks that require long document coding .",0.5864661654135339,0.30534351145038174,0.45112781954887216,0.12193003116497286
149,"The article proposes a semi-automatic method for collecting emotional animated GIFs from the internet with minimal human labor, in order to create a larger dataset for machine learning models. The method involves training weak emotion recognizers on labeled data and using them to sort through a large quantity of unlabeled GIFs, while exploiting the clustered structure of emotions to reduce the number of GIFs a labeler needs to check. This resulted in the creation of a new dataset called GIFGIF+ with 23,544 GIFs over 17 emotions, providing a promising platform for affective computing research","Existing GIF datasets with emotion labels are too small for training contemporary machine learning models, so we propose a semi-automatic method to collect emotional animated GIFs from the Internet with minimal human labor . The method trains weak emotion recognizers on labeled data, and uses them to sort through a large quantity of unlabeled GIF . This method resulted in the creation of a new dataset called GIFGIF+ with 23,544 gIFs over 17 emotions .",0.7529411764705882,0.6071428571428571,0.6470588235294117,0.40217199857843966
150,"The article explores the idea that iconic representations, such as cartoons, may be more efficient at communicating emotional information than realistic representations. The authors conducted two experiments, one measuring accuracy in identifying emotions on cartoonized images versus realistic images, and the other measuring event-related potentials in response to low-level visual features in schematic stimuli. The results support the hypothesis that iconic representations communicate specific information, including emotion, quickly and efficiently, and that this effect is driven by changes in low-level visual features in the stimuli. The authors suggest that the effective communicative role of iconic images may underlie their ubiquity and popularity in popular culture, and that further research is needed to better understand their communicative function and improve their use in various real-world applications.","In Experiment 1, we manipulated low-level features of emotional faces to create five sets of stimuli that ranged from photorealistic to fully iconic . Results showed that, at short presentation times, accuracy for identifying emotion on more “cartoonized” images was enhanced . In addition, increasing contrast and decreasing featural complexity benefited accuracy . We suggest that iconic representations serve a distinct role – to impart specific information quickly and efficiently – and highlight the advantages of simplifying image features .",0.3725490196078432,0.10891089108910892,0.22549019607843138,0.01753060922210352
151,"The paper proposes a new facial expression database, Acted Facial Expressions in the Wild (AFEW), and its static subset, Static Facial Expressions in the Wild (SFEW), which are extracted from movies to provide a more realistic representation of human facial expressions. The database is created using a semi-automatic recommender system based on subtitles to make the process less time-consuming and complex. AFEW includes natural head poses, close to real-world illumination, multiple subjects, a large age range, and searchable metadata. It covers toddler, child, and teenager subjects, which are missing in other temporal facial expression databases. The paper compares AFEW with the extended Cohn-Kanade CK+ database and SFEW with JAFFE and Multi-PIE databases. The authors believe that these datasets will enable novel contributions to facial expression research and act as a benchmark for experimental validation of facial expression analysis algorithms in real-world environments.





","AFEW is compared with the extended Cohn-Kanade CK+ database and SFEW with JAFFE and Multi-PIE databases. To address this problem, we have collected two new facial expression databases derived from movies via a semi-automatic recommender based method . The database contains videos showing natural head poses and movements, close to real-world illumination, multiple subjects in the same frame, a large age range, occlusions and searchable metadata .",0.47926267281105994,0.33488372093023255,0.28571428571428575,0.1361536640426024
152,"The paper presents the Gabor-based kernel partial-least-squares discrimination (GKPLSD) method for extracting facial features from face images, which involves using Gabor wavelets and kernel partial-least-squares discrimination technique. The GKPLSD approach outperforms other feature-extraction methods such as PCA, LDA, KPCA, and GDA, as well as their combinations with Gabor representations of face images. The KPLSD algorithm used in the method does not suffer from the small-sample-size problem commonly encountered in face recognition. Experimental results based on the XM2VTS and ORL databases confirm the effectiveness of the proposed method.","Gabor-Based kernel partial-least-squares discrimination (GKPLSD) method is performed in two consecutive steps . The proposed feature-extraction method is called the Gabor - a model of facial features . In the first step, a set of forty Gabor wavelets is used to extract discriminative and robust facial features, while in the second step, the kernel partial least -square discrimination technique is used . For optimal performance, the KPLSD-based transformation is implemented using the",0.5,0.2530120481927711,0.2976190476190476,0.11375998093183147
153,"The paper presents an experimental study on detecting emotions from speech for use in driving the expression of computer-based characters such as avatars and virtual chat faces. The study uses a corpus of 721 short utterances expressing four emotions: anger, happiness, sadness, and neutrality. The authors introduce a new concept of emotions as a mixture of multiple emotions and train support vector machines (SVMs) to recognize these four categories. Compared to KNN and NN, SVMs require less training time and are more robust, making them suitable for complex emotional data. The SVM model contains all useful information, and classification can be done in real-time rendering. The authors plan to extend their approach to data from different languages and cultures in future work.","EMOTION DETECTION FROM SPEECH TO ENRICH MULTIMEDIA CONTENTemotion detection, speech, avatars, virtual characters, SVM, KNN, NN, magnitude recognition. The study uses a corpus containing emotional speech with 721 short utterances expressing four emotions: anger, happiness, sadness, and the neutral (unemotional) state . We introduce a new concept to evaluate emotions in speech. Emotions are so complex that most speech sentences cannot be precisely assigned into",0.43617021276595747,0.1827956989247312,0.3191489361702127,0.14874358720268416
154,"The paper describes a framework for social robots to detect and store emotions in a semantic repository, using an ontology called EMONTO. The framework focuses on emotion detection in text and uses a speech-to-text converter, a neural network for emotion labeling, and EMONTO integrated with an ontology for museums to register the emotions that artworks produce in visitors. The framework is a contribution to the interpretation of social behaviors in social robotics and provides a roadmap for improvement, including incorporating more interpretation characteristics and developing a new classification model. The framework could also be part of an autonomous navigation system for social robots, leading to better socially acceptable behavior towards humans.","Social robots gather information from which emotion detection is processed via different media, such as text, speech, images, or videos . The multimedia content is then properly processed to recognize emotions/sentiments, for example, by analyzing faces and postures in images/videos based on machine learning techniques . As a proof-of-concept, we develop a first version of this framework focused on emotion detection in text, which can be obtained directly as text or by converting speech into text to perform emotion detection with natural language processing",0.30150753768844224,0.08121827411167512,0.1708542713567839,0.045927532973429906
155,"The paper discusses Person Re-Identification (Re-ID), which involves recognizing a person from various images captured by different cameras. Re-ID has two categories: Image Re-ID and Video Re-ID, and is applied in robotics, automated video surveillance, forensics, and multimedia using public datasets such as Market1501, VIPeR, and MARS. The paper outlines the process of Re-ID, its challenges, recent work, and deep learning techniques. Despite advancements, there is still a need for in-depth exploration in real-time problems.","Person Re-Identification is the process of person recognition from various images captured by different cameras . Provided two sets of images the purpose is to find that the given set of images are identical or not . It is often a challenging task due to the similarity in nature like people with identical features, color or clothes . Based on the category Re-ID has numerous applications like robotics, automated video surveillance, forensics and multimedia that are deployed using various public datasets .",0.4539877300613497,0.2360248447204969,0.3067484662576687,0.18335306617163252
156,"The study presents a method of identifying underground objects from GPR images using a deep neural network (DNN) trained on several hundred thousand images generated by a fast FDTD simulation with GPUs. The 9-layers CNN extracts and learns the characteristics of underground objects, enabling it to identify six materials with approximately 80% accuracy in inhomogeneous underground media. Future work involves testing the method on experimental GPR images.","Object Identification form GPR Images by Deep Learningonvolutional neural network, ground penetrating radar, FDTD method, GPU, object identification.We have developed an identification method of an underground object form the GPR image by the deep neural network . We have generated several hundred thousand GPR images for training the DNN using a fast finite-differencetime-domain (FDTD) simulation with graphics processing units (GPUs)",0.47692307692307695,0.18750000000000003,0.29230769230769227,0.038638260762293875
157,The article proposes a novel concept for radar-based object classification using deep learning methods. The traditional radar signal processing chain is replaced by applying deep Convolutional Neural Networks (CNNs) directly to regions-of-interest (ROI) in the radar spectrum. This approach outperforms other machine learning approaches on a novel dataset with realistic objects and demonstrates that deep learning methods can greatly augment the classification capabilities of automotive radar sensors. The article identifies deep learning challenges specific to radar classification and introduces a set of novel mechanisms that lead to significant improvements in object classification performance. The best results can be obtained by combining state-of-the-art deep learning with specific radar know-how and prior understanding of the task.,"Automotive radar has shown great potential as a sensor for driver assistance systems due to its robustness to weather and light conditions, but reliable classification of objects in real time has proved to be very challenging . Here we propose a novel concept for radar-based classification, which uses the power of modern Deep Learning methods to learn favorable data representations . We propose to apply deep Convolutional Neural Networks (CNNs) directly to regions-of-interest (ROI) in the radar spectrum and thereby achieve an accurate classification of different objects",0.45933014354066987,0.2318840579710145,0.3062200956937799,0.1864360360233514
158,"This article proposes an intelligent video technology based on deep learning for abnormal behavior identification in massive video monitoring data in smart cities. The technology utilizes a three-layer framework for object detection, identification, and behavior analysis. Object detection based on background and object modeling is used for real-time detection and data retrieval, while optical flow algorithms are used for abnormal behavior identification. The article also introduces deep learning technology based on convolutional neural networks to enhance the identification and real-time upgrade of intelligence video. The article highlights the importance of intelligent video technology for security and post-disaster relief in smart cities.","intelligent video technology based on convolutional neural network deep learning is applied to behavioural recognition in massive video monitoring data . In order to improve accuracy and real-time performance of abnormal behaviour identification, the deep learning technology is applied . This research has a good popularization value in application field of smart video technology. As traditional video management systems could no longer adapt to technological development, the intelligent cities need to adopt intelligent video technologies to help administrators accomplish various tasks .",0.44324324324324327,0.21857923497267764,0.30270270270270266,0.1272934100051653
159,"This paper describes a robotic grasping system that can automatically sort garbage based on machine vision. The system uses deep learning to accurately identify and position target objects in complex backgrounds. The Region Proposal Generation (RPN) and VGG-16 model are used for object recognition and pose estimation, and the information is sent to the manipulator for object grabbing. The results of sorting experiments show that the system can achieve efficient garbage sorting.","This paper proposes a robotic grasping system for automatically sorting garbage based on machine vision . This system achieves the identification and positioning of target objects in complex background before using manipulator to automatically grab the sorting objects . In order to achieve the accurate grabbing of target object, we apply the Region Proposal Generation (RPN) and the VGG-16 model for object recognition and pose estimation . The results of sorting experiment of the bottles in the garbage show that the vision algorithm and the manipulator control method of the proposed",0.7283950617283951,0.45,0.5432098765432098,0.3047922801357744
160,"Facial expression recognition has many applications but is challenging for machine learning as people show expressions differently. Most facial expression recognition research mixes subjects during training and testing, leading to inaccurate results. A proposed solution uses a combination of Convolutional Neural Networks and image pre-processing to extract expression-specific features. The method achieved high accuracy rates, with competitive results compared to other facial expression recognition methods, and real-time recognition with standard computers. The proposed method's normalization procedures significantly improved accuracy rates, making it a promising solution for facial expression recognition.","Convolutional Neural Networks: Coping with few data and the training sample orderfacial expression recognition has been an active research area in the past 10 years . The recognition of facial expressions is not an easy problem for machine learning methods, since people can vary significantly in the way they show their expressions . Even images of the same person in the same facial expression can vary in brightness, background and pose, and these variations are emphasized if considering different subjects (because of variations in shape, ethnicity among others)",0.36871508379888274,0.0903954802259887,0.16759776536312848,0.032826961259003085
161,"This paper presents a multimodal approach for recognizing eight emotions by integrating information from facial expressions, body movement and gestures, and speech using a Bayesian classifier. The approach fuses data at the feature and decision levels, resulting in a significant increase in recognition rates compared to unimodal systems. The paper highlights the importance of considering different channels of information in affective computing and compares different strategies for data fusion in multimodal emotion recognition.","In this paper we present a multimodal approach for the recognition of eight emotions . Our approach integrates information from facial expressions, body movement and gestures, and speech . We trained and tested a model with a Bayesian classifier . The approach gave an improvement of more than 10% when compared to the most successful unimodal system . Further, the fusion performed at the feature level provided better results .",0.6231884057971014,0.35294117647058826,0.44927536231884063,0.28338931403809314
162,The paper describes an experimental study on detecting emotions from speech to improve computer-human interactions. It uses a corpus of emotional speech with four emotions and introduces a new concept to evaluate emotions in speech as a mixture of multiple emotions. The study trains SVMs to recognize utterances in four emotion categories and develops an agent that can recognize and express emotions. It also discusses speech-driven facial animation to produce a facial control model and classification algorithms used in recent studies about emotions in speech recognition.,"The study uses a corpus of emotional speech with 721 short utterances expressing four emotions: anger, happiness, sadness, and the neutral (unemotional) state . We introduce a new concept to evaluate emotions in speech . Emotions are so complex that most speech sentences cannot be precisely assigned to a particular emotion category; however, most emotional states nevertheless can be described as a mixture of multiple emotions .",0.5263157894736842,0.29333333333333333,0.3684210526315789,0.22537595635533983
163,"Facial expression recognition has been a challenging area of research for decades, with traditional methods relying on hand-crafted features and classifiers trained on databases of images or videos. While deep learning models have shown promise, there is still room for improvement. The authors propose a new approach using an attentional convolutional network that focuses on important parts of the face and achieves better results than previous models on multiple datasets. They also use a visualization technique to identify important facial regions for detecting different emotions, and show that different emotions are sensitive to different parts of the face. Overall, the authors believe that attention to special regions is important for detecting facial expressions and that their framework could enable neural networks with less than 10 layers to outperform much deeper networks in emotion recognition.





","Traditional approaches for this problem rely on hand-crafted features such as SIFT, HOG, and LBP, followed by a classifier trained on a database of images or videos . Most of these works perform reasonably well on datasets captured in a controlled condition but fail to perform as well on more challenging datasets with more image variation and partial faces . In recent years, several works proposed an end-to-end framework for facial expression recognition using deep learning models .",0.39436619718309857,0.13270142180094785,0.2535211267605634,0.05175590123953924
164,"The paper proposes a method for creating a personalized voice-emotion user interface that can detect emotions in the user's speech regardless of age, sex, or language. The approach involves creating a speech database for analyzing acoustic similarities among eight emotional states and developing a voice interaction system that analyzes primary parameters of human speech, including pitch, formants, tempo, and power, to detect emotions in the user's speech. The system interacts with the user, changing its response based on the user's utterances. The proposed approach successfully extracts emotional messages from the subject's utterances by analyzing the speaker's voice characteristics in neutral speech, and presents a promising method for creating a personalized and intuitive voice-emotion user interface.","An extensive set of carefully chosen utterances provided a speech database for investing acoustic similarities among eight emotional states . Based on those results, a voice interaction system (VIS) capable of sensing the user's emotional message was developed . In efforts to detect emotions, several primary parameters from human speech were analyzed: pitch, formants, tempo (rhythm) and power of human voice .",0.4505494505494505,0.2555555555555556,0.2747252747252748,0.1076559051877746
165,"The ability to recognize emotions conveyed through non-verbal cues such as facial expressions and tone of voice is crucial for social interactions and relationships. While research has shown that emotion processing from facial expressions improves throughout childhood and adolescence, it is unclear if the same is true for emotions conveyed through vocal expressions. A study tested 225 children and adolescents and 30 adults in a forced-choice labeling task using vocal bursts expressing four basic emotions. Results showed that emotional vocal recognition improves throughout childhood and adolescence, with adult-level performance reached between 14 and 15 years of age. These findings expand on previous research and highlight the importance of continued improvement in emotional recognition skills during this pivotal period for social maturation.



","Emotion recognition, non-verbal cues, vocal expressions, childhood, adolescence, social interactions, developmental disorders . We tested 225 children and adolescents (age 5–17) and 30 adults in a forced-choice labeling task using vocal bursts expressing four basic emotions . Adult-level of performance was reached between 14 and 15 years of age . Overall, female participants obtained better scores than male participants, with no signifcant interaction between age and sex efects",0.4766839378238342,0.33507853403141363,0.41450777202072536,0.2042661923705353
166,"This paper proposes a facial emotion recognition technique that uses two new geometric features extracted from facial landmarks associated with individual components of facial muscle movements. The method combines SVM-based classification with a GA for feature and parameter selection and is evaluated on the CK+ and MUG datasets, demonstrating high accuracy and precision in recognizing facial emotions. The proposed method is compared to a CNN-based approach and shows slightly higher test accuracy for two datasets, making it a promising approach for automatic facial emotion recognition with potential for use in various fields, including psychology, marketing, and human-computer interaction.","The presented method combines support vector machine (SVM) classification with a genetic algorithm (GA) for a multi-attribute optimization problem of feature and parameter selection . The results demonstrate high accuracy and precision in recognizing facial emotions . This technique shows potential for real-time machine vision applications in automated systems, as it employs less complicated models compared to CNN-based approaches . It provides a promising approach for automatic facial emotion recognition and has potential for use in various fields, including psychology, marketing, and human-computer",0.6054054054054056,0.3934426229508197,0.5297297297297296,0.32268437963324137
167,"This paper proposes an algorithm for emotion-based line art colorization using the DenseNet network for emotional recognition of anime faces and a two-stage interactive coloring method based on superpixel color analysis features. The results demonstrate that the proposed algorithm effectively realizes emotion-based line art colorization with high interactivity and reasonable color distribution. The research on hand-drawn manuscript recognition, generation, and retrieval, as well as facial emotion recognition, has contributed to the development of AI technology for automatic colorization of hand-drawn sketches.","researchers have conducted in-depth and meticulous study on hand-drawn manuscript recognition, generation, and retrieval . For the emotion-based line art colorization, facial expression should be also extracted from the image itself . This paper proposes an algorithm with the DenseNet network for emotional recognition of anime faces and performed a two-stage interactive coloring method . After the prediction of superpixel color analysis by GAN (generative adversarial network), the original cartoon image could be rendered with suitable color scheme .",0.5818181818181818,0.38036809815950917,0.3393939393939394,0.3296614881185635
168,"The paper presents a study on summarizing long legal briefs with only 120 available (document, summary) pairs, which is a low-resource setting. The authors propose a novel algorithm based on GPT-2 language model perplexity scores to identify salient sentences and compress the documents, which results in a 6.0 ROUGE-L improvement when fed to a modern pretrained abstractive summarizer BART. The method outperforms several salience detection baselines and is in agreement with independent human labeling by domain experts. The proposed extract-then-abstract pipeline provides a solution for summarizing domain-specific documents with limited training data.","Abstractive summarization is the task of compressing a long document into a coherent short document while retaining salient information . Our method also beats several competitive salience detection baselines . We propose an extract-thenabstract pipeline which uses GPT-2 perplexity . This sufficiently compresses a document, allowing us to use a pretrained model (BART) to generate coherent & fluent summaries .",0.41025641025641024,0.051948051948051945,0.20512820512820512,0.015660624461297474
169,"This paper proposes a scoring system for identifying main objects in complex background images using an improved RCNN network. The size of the candidate region and rarity of the object were found to be related to the image's main objects. However, the method still has some problems, such as inaccurate images and no error alerts. The authors suggest calculating the outline size of the object and working on these issues in future research. Keywords: object recognition, image main objects, RCNN network.","Research of Image Main Objects Detection Algorithm Based on Deep Learning object detection; convolution neural network; scoring system; selective search; deep learning Images have many objects in complex background . How to identify these objects and identify them and understand the relationship between the main objects and other objects are the focus of this parper . In this paper, we use improved RCNN [1] network to detect and recognize multi-object in the image . We found that the image main objects were related to the size of candidate region",0.5917159763313609,0.21556886227544908,0.23668639053254437,0.0837375223345501
170,"The Indian government's recent focus on the welfare of sanitation workers has led to a need for an automated waste management system. The existing system involves manual segregation of waste, which is inefficient and hazardous to the workers. The proposed solution is an automated recognition system that uses deep learning algorithms to classify objects as biodegradable or non-biodegradable. The system can accurately identify and classify objects in real-time, making the waste management process more efficient and environmentally friendly. The project aims to contribute to global waste management policies by transitioning from disposal to source segregation and recycling. The proposed system is simple, affordable, and valuable, making it an important asset to society.","The existing garbage disposal system in India consists of unclassified waste collected from homes which are then segregated at a station manually . This segregation of solid waste done by manual labor can bring about many health hazards for the waste sorters in addition to being less efficient, time consuming and not completely feasible due to their large amount . In our paper, we have proposed an automated recognition system using Deep learning algorithm in Artificial Intelligence to classify objects as biodegradable . The system once trained with an initial dataset can",0.4215686274509804,0.1485148514851485,0.2549019607843137,0.07869668722502775
171,"This paper discusses the importance of object detection based on deep learning technology, which has stronger capabilities for feature learning and representation than traditional methods. It compares classical methods with deep learning methods in object detection and elaborates on the emergence of object detection methods based on deep learning. The paper then discusses the most typical deep learning methods used in object detection, including their framework design, working principles, and real-time detection accuracy. It concludes with a discussion of the challenges in object detection based on deep learning and offers some solutions for reference. The paper suggests that with the innovation of deep learning theories and computer hardware, object detection based on deep learning will continue to improve and have a wide range of applications, especially in current embedded systems.","The Object Detection Based on Deep Learningobject detection; deep learning; framework design; model analysis; performance analysis The object detection based on deep learning is an important application in deep learning technology, which is characterized by its strong capability of feature learning and feature representation compared with the traditional object detection methods . The paper focuses on the framework design and the working principle of the models and analyzes the model performance in the real-time and the accuracy of detection . Finally, this paper makes a further analysis of the challenges in object",0.5675675675675675,0.2545454545454546,0.33333333333333337,0.15012970675544177
172,"The letter discusses the limitations of naive low-latency algorithms used in commercial optical sorting systems, which can result in degraded purity of sorted objects due to difficulty in accurately identifying objects with various shapes, textures, sizes, and colors. The authors propose a super-high purity seed sorting system that utilizes deep learning technology for image recognition, but also addresses the inference latency issue by implementing a batch inference only once strategy. The proposed system partitions the detection task into localization and classification and achieves 500-fps throughput image-recognition. The system eliminates almost all weeds with minimal loss of desired seeds, demonstrating higher purity, classification accuracy, and detection mAP than commercial systems and state-of-the-art detectors. The system is applicable to actual optical sorting systems and has potential for use in other industries due to its ability to classify objects based on shape and texture.","Super-High-Purity Seed Sorter Using Low-Latency Image-Recognition Based on Deep LearningAgricultural automation, deep learning in robotics and automation, computer vision for automation . Current deep learning technology enables robust image detection and classification, but its inference latency requires several milliseconds . We therefore developed a super-high purity seed sorting system that achieves both high throughput and high purity by exploiting deep learning using an inference only once strategy .",0.3761467889908257,0.15740740740740744,0.1651376146788991,0.06095628195634647
173,"This paper proposes using UAV-based videos and deep learning techniques for real-time traffic analysis in urban environments. The study validates the approach by comparing it to manual analysis and visualizations. The paper acknowledges challenges in accurately calculating metrics in complex traffic situations and suggests future research to explore improved measurement methods and expand the approach to other metropolitan areas. The study focuses on the role of motorbikes in traffic congestion in a specific city in China, but the approach can be applied to different areas with different issues causing traffic congestion.","This paper aims to conduct traffic analysis using UAV-based videos and deep learning techniques . The road traffic video is collected by using a position-fixed UAV . This method is real-time in terms of the pretrained model used . In Fig. 6, the traffic deadlock happens because a vehicle in the red box blocks the road due to its moving direction being orthogonal to the road direction . It is a challenging issue for future research offering the opportunity for improved traffic measurement metrics .",0.5000000000000001,0.12643678160919541,0.2727272727272727,0.1015707404651266
174,"The author proposes a virtual space that mimics real communication environments between network users or between humans and machines, using avatars with realistic texture-mapped faces to generate facial expressions and actions controlled by a multimodal input signal. A face fitting tool is introduced to create a realistic 3-D personal face model, and a real-time mouth shape control mechanism is proposed using a neural network. A muscle structure constraint is introduced for making facial expressions naturally with few parameters, and an attempt is made to obtain muscle parameters automatically from a local motion vector on the face calculated by the optical flow in a video sequence. The goal is to provide a more realistic and immersive communication experience in cyberspace.","The author proposes a virtual space that mimics real communication environments between network users or between humans and machines . There should be an avatar that projects the features of each user with a realistic texture-mapped face to generate facial expression and action controlled by a multimodal input signal . Users can also get a view in cyberspace through the avatar's eyes, so they can communicate with each other by gaze crossing . This fitting tool is a GUI-based system using easy mouse operation to pick up each feature point on a face",0.5209302325581396,0.35680751173708924,0.42790697674418604,0.23398648364154392
175,"This thesis proposes an automatic facial expression recognition system that utilizes multistream hidden Markov models (HMMs) to improve performance by modeling the reliability of different streams of facial expression information. The system utilizes facial animation parameters (FAPs) to classify facial expressions and introduces stream reliability weights to model the reliability of different streams of facial expression information. Experiments show that the proposed system achieves a significant reduction of facial expression recognition error compared to the single-stream HMM system, with practical applications in fields such as human-computer interaction, affective computing, and robotics.



","Automatic facial expression recognition using facial animation parameters and multistream HMMsFace recognition , Facial animation , Hidden Markov models , Face detection , Financial advantage program , Human computer interaction , Performance analysis , Eyebrows , Speech recognitionThe proposed system utilizes facial animation parameter (FAPs) to model the reliability of different streams of facial expression information . Experiments are first performed using single-stream hMMs under several different scenarios, utilizing outer-lip and eyebrow FAPs individually and jointly",0.5061728395061729,0.3375,0.3827160493827161,0.2239161504851609
176,"The study argues that the traditional view of cognitive systems as input/output devices with limited interaction between perception and action is incomplete, even in more recent closed-loop models. The researchers present a minimal model of a sensorimotor loop that emphasizes the limitations of a separation principle-based architecture when faced with external forces or interference. An alternative non-modular architecture based on active inference is proposed, which is shown to be robust to unknown external inputs and equivalent to integral control in linear models.","Cognitive systems , Cognitive science , Optimal control , NeuroscienceIn psychology and neuroscience it is common to describe cognitive systems as input/output devices where perceptual and motor functions are implemented in a purely feedforward, open-loop fashion . On this view, perception and action are often seen as encapsulated modules with limited interaction between them . In this work we present a minimal model of a sensorimotor loop implementing an architecture based on the separation principle .",0.4683544303797468,0.2564102564102564,0.29113924050632906,0.19147702237004777
177,"This paper presents a framework for real-time speech-driven face animation with expressions using neural networks. The framework includes facial deformation modeling, automatic facial motion analysis, and audio-to-MUP mapping. The study demonstrates the effectiveness of the proposed approach through quantitative evaluations and the development of the iFACE system. The synthetic expressive talking face of the iFACE system is shown to be comparable to a real face in terms of its influence on bimodal human emotion perception, making it an effective multimodal communication interface in distributed collaboration environments.



","Real-time speech-driven face animation with expressions using neural networksFacial animation , Neural networks , Face , Humans , Real time systems , Audio databases , Collaboration , Deformable models , Motion analysis . We develop an MU-based facial motion tracking algorithm which is used to collect an audio-visual training database . The quantitative evaluation of the mapping shows the effectiveness of the proposed approach through quantitative evaluations and the development of the iFACE system.",0.569620253164557,0.37179487179487175,0.4177215189873417,0.2834184641809441
178,"The paper proposes a deep learning-based approach for personality recognition from text posts on online social networks. The method uses a hierarchical deep neural network to learn deep semantic features from user-generated text posts and combines them with statistical linguistic features to predict the Big Five personality scores. Experimental results show that the deep semantic feature vectors are more effective than other non-trivial baseline features, and the approach that utilizes the concatenation of deep semantic features and statistical linguistic features achieves the lowest prediction error. The proposed approach contributes significantly to the performance improvement of Big Five personality recognition approaches. Future work will focus on utilizing deep semantic features as input for specially designed regression algorithms to further improve prediction accuracy","This paper proposes a deep learning-based approach for personality recognition from text posts of online social networks . We first use a hierarchical deep neural network composed of our newly designed AttRCNN structure and a variant of the Inception structure to learn the deep semantic features of each user’s text posts . Then we concatenate the deeper semantic features with the statistical linguistic features obtained directly from the text posts, and feed them into traditional regression algorithms to predict the real-valued Big Five personality scores .",0.5523809523809524,0.3365384615384615,0.40952380952380957,0.21444503244252985
179,"This paper discusses the potential of leveraging social network context for scalable face recognition systems. The authors argue that social incentives, such as identity tags on Facebook, can provide significant quantities of labeled facial images of millions of individuals. They provide an example of a computational architecture that utilizes contextual information from social networks. The paper suggests that there are many additional sources of information that can be used to improve recognition accuracy, such as photo timestamps, gender information, and scene context. The authors propose exploring techniques that take advantage of the resources and structure of social networks to improve face recognition rates on shared images. Ultimately, the paper concludes that the growth of online social networks and improved tagging systems have the potential to enhance our ability to achieve face recognition at scale.","Toward Large-Scale Face Recognition Using Social Network Context Face recognition; graphical models; social network context; structured prediction Personal photographs are being captured in digital form at an accelerating rate . One promising approach is automatic face recognition, which would allow photos to be organized by the identities of the individuals they contain . However, achieving accurate recognition at the scale of the Web requires discriminating among hundreds of millions of individuals and would seem to be a daunting task . Drawing upon real photo collections from volunteers who are members of a",0.36607142857142855,0.11711711711711711,0.17857142857142855,0.038087634770180206
180,"The paper presents an automatic approach for constructing a Chinese personality lexicon suitable for personality recognition using text-mining methods and clustering algorithms. The identified semantic categories form the first Chinese personality lexicon. Word embedding and prior-knowledge lexicons are used to refine word vectors and construct semantic features of words, which are used to train personality recognition models. The proposed model achieves significantly better performances compared to previous approaches. In future, distributional contextual representations and hierarchical clustering approaches will be used to obtain a more sophisticated personality lexicon. The paper provides a novel, interpretable personality recognition model that enables exploration and interpretation of personality traits using knowledge of words.","In this paper, we present a novel interpretable personality recognition model based on a personality lexicon . We analyze the correlations between personality traits and semantic categories of words . The proposed model can achieve significantly better performances compared to previous approaches . In future, we will utilize distributional contextual representa-tions of the keywords to obtain better word vectors . This will provide psychologists with a vital tool to deeply study and interpret personality traits .",0.5164835164835165,0.26666666666666666,0.37362637362637363,0.1666273801348636
181,"This survey paper reviews the state-of-the-art research in sentiment analysis, categorizing and classifying it from multiple perspectives, including task-oriented, granularity-oriented, and methodology-oriented. The paper explores different types of data and tools used in sentiment analysis research, and suggests their strengths and limitations. The survey also highlights the prospects for future development and suggests possible extensions, including multimodal sentiment analysis. The paper establishes a common terminology, enabling people from different backgrounds to easily understand, and lays a foundation for advanced research in sentiment analysis. Overall, the survey addresses the progress, main advances, and remaining limitations in sentiment analysis.","Social media, Data mining, Machine learning, Survey.Sentiments or opinions from social media provide the most up-to-date and inclusive information due to the proliferation of social media and the low barrier for posting the message . This area lacks a concise and systematic arrangement of prior efforts . It is essential to (1) analyze its progress over the years, (2) provide an overview of the main advances achieved so far, and (3) outline remaining limitations . In this survey, a series of the state-of-the-art literatures have",0.34554973821989526,0.08465608465608467,0.2094240837696335,0.010838730898619581
182,"This study explores the use of emojis in personality recognition tasks and presents two attention-based Bi-LSTM models that incorporate both textual and emoji information at different semantic levels. The proposed models achieve state-of-the-art performance on a real dataset, demonstrating the value of emoji information in personality recognition. The findings suggest that companies could improve their recommendation systems and innovation processes by considering users' personality traits. However, the study has some limitations and suggests future research on the inclusion of visual features and the application of other sequence learning models. Overall, the study highlights the rich semantics of emojis and their potential in NLP tasks.","Attention-based BiLSTM models for personality recognition from user-generated content . This study presents two new attention-based bi-LSTM architectures to incorporate emoji and textual information at different semantic levels to predict the Big Five personality traits . The proposed methods achieve state-of-the-art performance over the baseline models on the real dataset, demonstrating the usefulness and contribution of emmoji information .",0.5116279069767442,0.2705882352941177,0.3488372093023256,0.09146536450339113
183,"The study aims to identify personalities by analyzing self-reported content on Twitter using six ML classifiers and three feature extraction methods: TF-IDF, BOW, and GloVe. The dataset was formed by merging a Kaggle dataset for MBTI personality identification and a Twitter API dataset. The MBTI personality indicators were mapped to four BIG5 personality items. The accuracy achieved by the TF-IDF feature extractor was highest, but GloVe is recommended as a better feature extractor as it maintains spatial information of words. The present work can be extended to data from different SM platforms and by combining different features. The study demonstrates the potential for predicting personality through SM conversation, and its findings could have implications for future research in this area.","Four BIG5 personality items (i.e. Extraversion (EXT), Consciousness (CON), Agreeable (AGR) and Openness to Experiences (OPN) were predicted using six supervised machine learning algorithms . In order to handle unstructured and unbalanced SM conversations, three feature extraction methods (TF-IDF), the bag of words (BOW) and the global vector for word representation (GloVe) were used . This study identifies personalities from self-",0.3804347826086956,0.14285714285714285,0.1847826086956522,0.047335638111306165
184,"The paper introduces a new approach called Kernel Compositional Embedding (KCE) to leverage the advantages of both kernel methods and compositional embedding to provide powerful representations and classifiers for structured data with hierarchical compositional structure and long relation among their subcomponents. The KCE approach is used to propose two methods: Direct KCE (DKCE), and Indirect KCE (IKCE), which are evaluated on two computational linguistic tasks: sentiment analysis and natural language inference. The experimental results show that both proposed methods can provide structured object classifiers with higher or competitive classification performance compared to some well-known related methods. The future work can extend the KCE approach to support non-linear composition and transpose operations and apply it to huge datasets and other applications dealing with structured objects.","Kernel compositional embedding and its application in linguistic structured data classificationStructured data representation KCE . On the other side, the high generalization power of kernel methods is proven in traditional machine learning problems . In the DKCE method, structured objects are embedded into a potentially infinite dimensional space and the necessary transpose and composition H. Ganji, M.M. Ebadzadeh and S. Khadivi / Knowledge-Based Systems 194 (2020) 105553 11 operations",0.3505154639175258,0.0625,0.1752577319587629,0.012099674201325968
185,"The text describes a novel approach for recognizing the Big Five personality traits of people from videos using four modalities: ambient appearance, facial appearance, voice, and transcribed speech. The model learns modality-specific representations through subnetworks and uses an attention mechanism to fuse the information. A consistency constraint is used to ensure equal importance for each trait. State-of-the-art architectures and LSTM layers are employed for effective modeling. The model achieves a mean accuracy of 91.8% on the ChaLearn First Impressions dataset and improves the state of the art. The effectiveness and reliability of the proposed features are evaluated, and future research directions are suggested.","We propose a novel approach to recognize the Big Five personality traits of people from videos . Through a specialized subnetwork, our model learns reliable modality-specific representations and fuse them using an attention mechanism that re-weights each dimension of these representations to obtain an optimal combination of multimodal information . To further enhance the reliability of our model, we employ (pre-trained) state-of-the-art architectures (i.e., ResNet-v2-101, VGGish, E",0.4835164835164836,0.2444444444444444,0.3516483516483516,0.111856746795532
186,"The paper proposes a method called PbSC for sentiment classification in microblogs based on users' personality traits. The Big Five model is used to predict personality traits, and tweets are grouped by personality traits to extract personalized sentiment features and train personality-based classifiers. Ensemble learning is used to integrate personality-based and traditional textual features. The method is shown to be effective in refining the performance of sentiment classifiers on a Chinese microblog dataset. The paper also discusses future directions for improving the method, including exploring other personality dimensions, applying personality information to other textual models, extending PbSC for more fine-grained emotion classification, and accelerating the ensemble learning process with parallel computing","Personality-based refinement for sentiment classification.Sentiment classification, Social media analytics, Personality prediction, Big Five model.Microblog has become one of the most widely used social media platforms for people to express their opinions . This paper proposes a method to facilitate sentiment classification in microblog based on personality traits . In order to leverage more effective but not widely used sentiment features, we then extract those features grouped by different personality traits and construct personality-based sentiment classifiers .",0.4921465968586387,0.20105820105820105,0.2408376963350785,0.056813792311039675
187,This paper proposes an Attention-based LSTM model for predicting personality traits of social network users. The model combines the users' theme preferences and text sentiment features with an attention mechanism and an LSTM network. The attention mechanism is used to focus on specific features during the training process and identify important word information for mining hidden information. The LSTM network receives sequential input of words and identifies differences in the use of text to better identify a user's personality. Experimental results show that the model outperforms currently popular methods in personality trait recognition and has good generalization ability.,The attention-based LSTM model proposed in the paper can achieve better results than the currently popular methods in the recognition of user personality traits . The feature information of the sentences extracted by other algorithms is used to make the model pay close attention to a specific feature during the training process . This paper converts the users’ theme preferences and text sentiment features into attention information and combines different forms with the LDA (Long Short-Term Memory) model .,0.6067415730337079,0.28409090909090906,0.26966292134831465,0.14414447439331932
188,"The paper discusses the prevalence of fake profile creation on social networks and the need for effective detection methods. It surveys existing and latest technical work on fake profile detection in OSNs, comparing different approaches and their strengths and drawbacks. Despite the numerous schemes proposed, there is still no systematic solution for efficient and reliable detection. The paper suggests that big data technologies such as Hadoop and Spark can be used to rapidly access and analyze large amounts of social network data. Scalable algorithms with concurrency should be designed to run on fast data systems and stream input data in real-time for more effective detection.","In the present era, online social networks are the most popular and rapid information propagation applications on the Internet . People of all ages spend most of their time on social networking sites . Huge volumes of data are being created and shared through social networks around the world . These interests have given rise to illegitimate users who engage in fraudulent activities against social network users . On social networks, fake profile creation is considered to cause more harm than any other form of cyber crime . This crime has to be detected even before the user",0.31155778894472363,0.05076142131979696,0.1608040201005025,0.021902486540303506
189,"The paper reviews various face recognition methods, including PCA, LDA, ICA, SVM, Gabor wavelet, and soft computing tools like ANN. It investigates the challenges faced by face recognition, such as illumination, pose variation, and facial expressions. The paper suggests that the combination of soft computing tools like ANN, SVM, and SOM may yield better performance for face recognition. The paper provides a list of references for readers to gain a more detailed understanding of the discussed approaches. The authors apologize to researchers whose contributions may have been overlooked.","A Review Paper on Face Recognition Techniques Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Face Recognition (ICA), Artificial Neural Networks (ANN) This paper attempts to review a wide range of methods used for face recognition comprehensively . This includes PCA, LDA, ICA, SVM, Gabor wavelet soft computing tool like ANN for recognition and various hybrid combination of this techniques . Present study reveals that for enhanced face recognition new algorithm has to evolve using hybrid methods of soft computing",0.46987951807228917,0.2073170731707317,0.30120481927710846,0.14929028906440253
190,"This article discusses the harmful effects of derogatory social media posts about famous individuals and proposes a multimodal deep learning framework for identifying such posts. The framework incorporates computer vision and natural language processing techniques and uses fine-tuned deep learning models for multilingual text analysis, face recognition, and optical character recognition. The proposed approach is tested on a new Facebook meme-post dataset created specifically for the study, with baseline results provided. The research aims to deter the dissemination of malicious campaigns against influential individuals and provides a basis for future research in multimodal social network analysis.","Social network sites have recently been used to carry out harmful attacks against individuals, including political and theological figures, intellectuals, sports and movie stars, and other prominent dignitaries . By classifying the derogatory content of a social media post, this research work helps to eradicate and discourage the upsetting propagation of such hate campaigns . To evaluate a post, we consider three multimodal data forms: Memes (representing a person’s image along with the message), the post text (main text), and related comments",0.39106145251396646,0.03389830508474576,0.16759776536312848,0.009964606243756299
191,"This paper discusses the problem of identifying celebrities from social media interactions. It highlights the difference between identifying celebrities versus influencers or experts, and proposes two models for celebrity identification. The paper compares the two models and provides interpretations for different signals such as acquaintance, affinity, identification, loyalty, and attention. The proposed algorithms can be applied to datasets from other forms of social media and can distinguish between celebrities within social media versus those in the real world. The authors plan to extend this model to identify celebrities in different domains and apply it to other forms of user-generated content in the future.","The celebrity identification problem is argued to be distinct from similar problems of identifying influencers or identification of experts . The proposed algorithms provide promising results to be practically applicable . In the future, we plan to extend this model to identify celebrities in a given domain and apply this model on other forms of user generated content, in addition to social media datasets . This work addresses the problem of celebrity identification from social media interactions .",0.5842696629213484,0.3295454545454546,0.3707865168539326,0.17432334055842783
192,"The text discusses sentiment analysis on social media data using artificial intelligence techniques. Sentiment analysis is used to understand people's sentiments in various situations, and it can be categorized into positive, negative, or neutral. The paper reviews various techniques for sentiment analysis on social media data, including machine learning and deep learning algorithms. Multi-class classification is preferred as it gives more precise results. Emoticons and emojis in social media data are also utilized as they contain sentiment value. Feature extraction techniques are used to extract features from the pre-processed data, and various algorithms are used for sentiment classification. In future work, other data such as biometrics, facial expressions, speech signals, and EEG signals can also be used for depression detection. The combination of different algorithms can also be used to improve precision under different conditions and with different data.","Social media data would be used for the entire process ie the analysis and classification processes and it consists of text data and emoticons, emojis, etc. Many experiments were conducted in the antecedent studies utilizing Binary and Ternary Classification whereas Multi-class Classification gives more precise and precise Classification. Utilizing Social media, sentiment levels can be monitored or analysed . In Machine Learning approach, it can be divided into supervised and unsupervised learning .",0.4392523364485981,0.1320754716981132,0.22429906542056077,0.019764506026915825
193,"This paper discusses the challenge of identifying violent content in social media, which can be categorized into aggregation in comments, cyber-bullying, and incidents like protests and murders. Existing methods, such as deep learning and character n-gram methods, have shown promising results in detecting violent content. However, most research has been based on social media text or images, while social media image posts that contain both text and objects are becoming more prevalent. The paper suggests that deep learning approaches with word embedding and object detection algorithms can be effective in detecting violent content in these types of posts. The creation of a balanced data corpus, followed by text and object detection and embedding, and then classification algorithms are recommended steps for this task.","Violence Detection in Social Media-ReviewMachine learning, natural language processing, violence, social media, convolution neural networkThe social media has become a vital part of humans’ day to day life. Different users engage with social media differently . Many examples in the recent past show, content in the social media can generate violence in the user community . Recent social media image posts which contain both text and objects are a popular way of communicating . We need to address this problem.",0.3251231527093596,0.11940298507462688,0.19704433497536947,0.07366900078226592
194,"This paper reviews machine learning models used for automatic prediction of personality traits, with a focus on deep learning-based methods. The paper discusses the diverse applications of automated personality detection and the need for larger, more accurate, and more diverse datasets for personality detection. Current methods for creating personality detection datasets rely on manual annotation through crowd sourcing using Amazon Mechanical Turk. Multimodal deep learning techniques have performed well in predicting personality traits, and deep learning is expected to continue to advance in the field. The paper concludes with a prediction that there will be more personality detection architectures relying on efficient multimodal fusion.



","Personality detection  Multimodal interaction  Deep learningRecently, the automatic prediction of personality traits has emerged as a hot topic within the field of affective computing . This review paper provides an overview of the most popular approaches to automated personality detection, various computational datasets, its industrial applications, and state-of-the-art machine learning models for personality detection with specific focus on multimodal approaches . The survey only focuses on computational approaches and leaves out psychological studies on personality detection . There is a dire need of larger,",0.49735449735449744,0.1497326203208556,0.23280423280423285,0.09338244844025692
195,"This paper proposes a method for emotion recognition and affective computing on vocal social media, which is becoming increasingly important for social media analytics due to its impact on social psychological cognition and group behaviors. The proposed method estimates complex emotion and its dynamic changes in a three-dimensional PAD space using 25 extracted acoustic feature parameters of speech signals based on a trained LS-SVR model. The method has been shown to be accurate and effective in analyzing the dynamic propagation of mixed emotions on vocal social media, but the performance is affected by the personalized features of social media group members. Further research is needed to optimize the acoustic feature parameters and explore the precise relationship between the parameters and PAD values.",Emotion recognition and affective computing on vocal social media has become a hot area in social media analytics . This paper proposes a computational method to estimate complex emotion as well as its dynamic changes in a three-dimensional PAD (Position–Arousal–Dominance) space . The widespread use of emerging vocal media has greatly facilitated communication and is therefore having greater impacts on social psychological cognition and group behaviors than ever before .,0.5051546391752576,0.30208333333333337,0.35051546391752575,0.16189246218229836
196,"This research evaluates the accuracy of four popular facial recognition tools - Face++, IBM Bluemix Visual Recognition, AWS Rekognition, and Microsoft Azure Face API - in determining user attributes such as gender, race, and age using multiple datasets. The study finds that the tools are generally accurate in determining gender, with accuracy rates above 90% except for IBM Bluemix. However, inferring age appears to be a challenging problem for all four tools. Regarding race, only Face++ provides this capability with an accuracy rate of above 90% but this was evaluated on a high-quality dataset. The study highlights the need for triangulation and manual verification for better computational social science research using these tools. The results suggest a trend of high accuracy for gender but poor performance for age. Future research is needed to determine if the accuracy holds for noisy images and investigate subgroups of gender, age, and race.","Face++, IBM Bluemix Visual Recog-nition, AWS Rekognition, and Microsoft Azure Face API . Re-sults show that the tools are generally proficient at determin-ing gender, with accuracy rates greater than 90%, except forIBM Bluemix . Inferring age appears to be a challeng-ing problem, as all four tools performed poorly, even with therelaxed task of determining an age bin instead of exact age .",0.41706161137440756,0.23923444976076558,0.37914691943127965,0.09532653381088255
197,"This paper discusses the concept of facial recognition technology, which is a computer application used for identifying or verifying individuals from digital images or video frames. The technology compares selected facial features from the image with a facial database and is commonly used in security systems. The paper also highlights the benefits of face recognition technology in various fields such as network security, content indexing, and retrieval, video compression, etc. The 3-D facial recognition system and biometric facial recognition system are also discussed. Although there are some weaknesses associated with facial recognition technology, the paper emphasizes the potential applications of this technology in India, including ATM security, identifying duplicate voters, passport and visa verification, driving license verification, competitive and other exams, and government and private sectors. The paper concludes by emphasizing the importance of promoting and supporting the applications of facial recognition technology in India through government and NGO initiatives.","Face recognition is a computer application for automatically identifying or verifying a person from a digital image or a video frame . It is typically used in security systems and can be compared to other biometrics such as fingerprint or eye iris recognition systems [1]. Network access control via face recognition makes hackers virtually impossible to steal one's ""password"" Certain applications of face recognition technology are now cost effective, reliable and highly accurate .",0.33928571428571425,0.16216216216216217,0.26785714285714285,0.04337085086975603
198,"This paper highlights the increasing need for automated understanding and evaluation of data due to the massive growth in video and image datasets. Facial recognition technology plays a significant role in face detection, appearance recognition, and human-computer interaction. The technology maps the features of an individual's face in mathematical form and stores them in a database as a face print. Deep learning algorithms compare digital images or instantly captured images to the stored images to authenticate an individual's identity. Facial recognition technology has many applications in security and surveillance industries as well as in consumer markets. This paper provides an overview of the techniques used in face recognition and discusses the challenges and potential applications of this technology, including privacy concerns and assessable applications. The future direction of face recognition technology includes further improvement in the presence of obstacles and non-uniform lighting. Facial biometric technology is currently being used in smartphones for access and may have future applications in payments, healthcare, advertising, criminal identification, etc.","A Review Paper on Facial Recognition Techniques . Biometric, Face Detection, Feature Analysis, Support Vector Machine, Neural Network . Face assumes a big component in pleasant sex for passing on personal and sensations of a man or woman . Facial recognition is considered as biometric software which is used for face detection and authentication . This research maps the features of individual’s face in mathematics form and stores in the database as a face print .",0.3651452282157676,0.15062761506276148,0.22406639004149376,0.04923283539812363
199,"This review explores facial emotion recognition (FER) in individuals with ADHD and discusses the inconsistent findings across studies. Fear facial expressions were found to be the most impaired emotion, but other facial expressions were also affected. The FER deficit in ADHD is not entirely accounted for by ADHD symptoms, and further studies controlling for executive functions are needed. FER in ADHD does not improve with age and may require assessment and intervention for social skills improvement.","This review focuses on facial emotion recognition (FER) in individuals with attention- deficit/hyperactivity disorder (ADHD). Across reviewed studies, fear was the most deficient facial expression to be recognized . This review suggested that FER deficit in ADHD does not alleviate across development and is partially distinct from ADHD symptoms . In conclusion, assessment of FER in ADHD and targeting that in interventional plans could lead to social skills improvement in ADHD .",0.5205479452054795,0.3055555555555555,0.4383561643835617,0.2157663320427328
200,"This paper provides a survey of various techniques for face recognition, including local, holistic, and hybrid approaches. The authors compare the advantages and disadvantages of these techniques in terms of robustness, accuracy, complexity, and discrimination, and discuss the most commonly used databases for face recognition. The paper highlights the challenges posed by real-world applications such as lighting conditions and facial expressions. The authors conclude that local feature techniques are the best choice for face recognition systems in terms of discrimination, rotation, translation, complexity, and accuracy. The paper encourages researchers to pay more attention to the use of local techniques in face recognition systems.","Face Recognition Systems: A Survey. face recognition systems; person identification; biometric systems; survey . Various techniques are being developed including local, holistic, and hybrid approaches . The main contribution of this survey is to review some well-known techniques for each approach and to give the taxonomy of their categories . A detailed comparison between these techniques is exposed by listing the advantages and the disadvantages of their schemes in terms of robustness, accuracy, complexity, and discrimination .",0.49438202247191015,0.2840909090909091,0.2696629213483146,0.21555082980463608
201,"This paper reviews recent advances in deep learning methods applied to playing various types of video games, including first-person shooters, arcade games, and real-time strategy games. The authors analyze the unique challenges that different game genres pose to deep learning systems and highlight open challenges in applying these methods to video games, such as dealing with large decision spaces and sparse rewards. The reviewed work focuses on end-to-end model-free deep reinforcement learning, as well as supervised learning and methods that learn a model of the environment. The reviewed methods have achieved above-human-level performance in simpler games, but there are many challenges in more complex games.","Deep Learning for Video Game PlayingAlgorithms, learning, machine learning algorithms, multilayer neural network, artificial intelligence, deep learningIn this paper, we review recent deep learning advances in the context of how they have been applied to video games . We analyze the unique requirements that different game genres pose to a deep learning system and highlight important open challenges . Most of the reviewed work is within end-to-end modelfree deep RL, where a CNN learns to play directly from raw pixels by interacting with the",0.5,0.26804123711340205,0.35714285714285715,0.10459810085460362
202,"This paper discusses how computer animated agents and robots enhance human-computer interaction and introduce a social dimension to daily life. It highlights the importance of real-time communication, which requires relying on sensory rich perceptual primitives rather than slow symbolic inference processes. The paper presents progress on one such primitive, which is the automatic detection and coding of facial expressions in real-time. The system employs a cascade of feature detectors and SVM classifiers to recognize facial expressions and has been tested on various platforms. The system's smooth output provides a valuable representation to code facial expression dynamics in an unobtrusive manner. The paper concludes by stating that the system has potential applications in areas such as automatic reading tutors and human-robot interaction assessment.","Real time systems, Robots, Pixel, Training, Support vector machines, Gabor filters, Facial expression recognitionComputer animated agents and robots bring a social dimension to human computer interaction . The level of uncertainty at this time scale is considerable, making it necessary for humans and machines to rely on sensory rich perceptual primitives rather than slow symbolic inference processes. The system automatically detects frontal faces in the video stream and codes them with respect to 7 dimensions in real time .",0.480392156862745,0.2673267326732673,0.303921568627451,0.14309362581416812
203,"This paper outlines the development of an automatic emotion recognition system that combines various modalities including facial features, prosody, and lexical content in speech. The authors discuss the theoretical foundations of the system based on insights from psychological research on the nature of emotion and its interaction with attention. They also examine input and output-related issues related to emotion recognition, including social norms, deception, and the nature of emotional representation. The authors present an artificial neural network called ANNA that uses a feedback attentional loop to enhance the salient components of the input stream. The results obtained from ANNA indicate that there are differences in the clues individuals pick up from others about emotional states, and environmental conditions can influence input features. The authors highlight the importance of considering these factors when constructing an artificial emotion state detector.","Emotion recognition in human–computer interactionEmotions Emotion classification Attention control Sigma–pi neural networks Feedback learning Relaxation Emotion data sets Prosody Lexical content Face feature analysis . Results from the network are given and their implications discussed, as are implications for future direction for the researchIn this paper we have introduced the framework of the EC project ERMIS . The aim of this project was to build an automatic emotion recognition system able to exploit multimodal emotional markers such as those embedded in the voice, face and words spoken ",0.336283185840708,0.08928571428571429,0.168141592920354,0.04031045541408887
204,"The paper proposes a novel emotion recognition model using the system identification approach, which utilizes an extended Kohonen self-organizing map (KSOM) and a 26 dimensional facial geometric feature vector. The proposed model achieves an average recognition rate of 93.53% on six basic emotions, which is higher than other widely used classifiers such as RBFN and MLP3. The paper also introduces different techniques for automated detection of facial features and evaluates their accuracy. The proposed KSOM-based recognition method using only geometric features shows significant improvement over other classification methods, indicating its effectiveness and accuracy for facial expression recognition.","A comprehensive data driven model using an extended Kohonen self-organizing map (KSOM) has been developed . The proposed method is very efficient in recognizing six basic emotions while ensuring significant increase in average classification accuracy over radial basis function network and multi-layered perceptron . An average recognition rate of 93.53% is achieved using the proposed KSOM based recognition method, with the highest recognition rate as 98.33% .",0.4761904761904762,0.26506024096385544,0.3333333333333333,0.1554344877184854
205,"The study compared the processing of cartoon faces and real faces in 17 university students using event-related potentials (ERPs). The study found that cartoon faces caused larger N170 and VPP amplitudes with briefer N170 latency than real faces, while real faces induced larger LPP amplitudes. The results suggested that cartoon faces showed higher processing intensity and speed than real faces during early processing stages, but more attentional resources were allocated for real face processing during the late processing stage. The study recommended future research with larger sample sizes to examine the interaction between face type and facial expression.","Using event-related potentials, we conducted a facial expression recognition experiment with 17 university students to compare the processing of cartoon faces with that of real faces . Results showed that cartoon faces caused larger N170 and VPP amplitudes as well as a briefer LPP latency than did cartoon faces, and that males showed a higher recognition accuracy for angry faces than happy faces. We used ERPs to measure the brain activity responses induced by the facial expressions of cartoon and real faces.",0.5635359116022098,0.2793296089385475,0.3314917127071823,0.17781620132828857
206,"The study aimed to investigate whether deficits in emotion recognition, understanding of other people's intentions (""theory of mind""), and cognitive flexibility might underlie changes in social behavior following traumatic brain injury (TBI). The study found that patients with TBI were impaired in all three functions compared to orthopedic controls, and there was an increase in behavioral problems 1 year following TBI. However, test performance was not associated with questionnaire data, and severity of impairments was unrelated to severity of behavioral problems. The study concludes that future studies could investigate the contribution of different aspects of executive functioning towards predicting emotional and social behavior following TBI.","Social behavior following traumatic brain injury and its association with emotion recognition, understanding of intentions, and cognitive flexibility . Patients with TBI (n = 33) were impaired in emotion recognition compared with matched orthopedic controls . Proxy ratings of behavior showed increases in behavioral problems 1 year following injury in the TBI group but not in the control group . However, test performance was not associated with questionnaire data . The findings failed to confirm the used model for social behavior deficits .",0.5901639344262295,0.35359116022099446,0.4153005464480874,0.24423719302573274
207,"This article discusses the social differences among individuals with Autism Spectrum Disorder (ASD), particularly in recognizing and producing facial expressions of emotion. The article reviews the research on facial emotion recognition (FER) and facial emotion expression (FEE) in individuals with ASD, proposes a method for teaching FER, and advocates for the use of well-controlled FER stimuli in autism intervention to bridge the gap between intervention and research in this area. The article highlights the difficulties that individuals with ASD face in recognizing emotions of neurotypical people based on their facial expressions and suggests two possible teaching approaches for FER.","Social differences are one of the core characteristics of autism spectrum disorder (ASD) Social differences among individuals with ASD often include difficulty in discerning the emotions of neurotypical people based on their facial expressions . In particular, we highlight subtle emotion recognition and various factors related to inconsistent findings in behavioral studies of FER in ASD . Finally, we propose a method for teaching FER, called the FER teaching hierarchy (FERTH)",0.5207100591715976,0.26347305389221554,0.29585798816568043,0.20354512330659816
208,"This study focused on facial affect recognition in children aged 7-13 with High Functioning Autism (HFA), Social Phobia (SP), and typical development (TD). Results showed that all children were equally able to detect certain emotions, but children with HFA had difficulty recognizing mild affective expressions compared to TD children. Additionally, no evidence was found for negative interpretation biases in children with HFA or SP. The study suggests that recognizing facial affect is important but not sufficient for effective social functioning, and it should be included in comprehensive social skill training programs for children with social skills deficits.","Facial Emotion Recognition in Children with High Functioning Autism and Children with Social Phobiafacial affect recognition . Results indicate that all children identified certain emotions more quickly (e.g., happy  anger, disgust, sad  fear) and more accurately (happy) than other emotions (disgust). Behavioral ratings of social effectiveness or social anxiety were uncorrelated with facial affect recognition abilities across children . Findings have implications for social skills treatment programs targeting youth with skill deficits .",0.4260355029585799,0.17964071856287425,0.2958579881656805,0.07630355327403605
209,"This article discusses how sentiment analysis techniques are used to extract emotions and opinions from texts, and how previous research has focused mainly on text and image analysis with low performance results. The study presents a hybrid approach to analyze internet memes using lexicon-based and machine learning approaches, with positive, neutral, and negative polarities and six emotion classes. The proposed method improves sentiment analysis performance and detects emotions from both text and facial expressions in memes. Future work includes analyzing different levels of texts and emojis, as well as gif, cartoon, and animation memes with various techniques and features.



","The purpose of Sentiment Analysis (SA) techniques are used to extract sentiments, emotions, and opinions from texts . This data is available by different data sources, such as social media, e-sources, etc. The problem of previous research work has done only text or image analysis using different techniques . In sentiment analysis, every meme is denoted as different polarities (positive or negative memes) The emotions contain six classes that are anger, fear, happiness, sadness, disgust, and neutral .",0.46590909090909094,0.1379310344827586,0.2840909090909091,0.09277156805564167
210,"This study aimed to investigate the accuracy of facial emotion recognition in Chinese patients with schizophrenia compared to healthy controls using a new set of facial emotion stimuli. The study found that patients had significantly greater difficulties identifying negative emotions, particularly fear and sadness, compared to healthy controls. Patients also had higher error rates in overidentifying contempt and sadness. However, no significant differences were observed in identifying positive emotions such as happiness. The study suggests that these findings could have implications for the diagnosis and treatment of Chinese patients with schizophrenia.","A new set of facial emotion stimuli with Chinese faces was developed . This test was then used to identify facial emotion recognition accuracy in 44 patients with schizophrenia and 41 healthy controls . Overall, patients identified facial emotions significantly worse than healthy controls (p = 0.018) with a significant main effect for type of emotion . No significant differences were evident in contempt and sadness, but not anger, fear, or happiness . Conclusion, patients of Chinese ethnicity with schizophrenia may have significantly greater difficulties identifying negative emotions, specifically fear and sadness .",0.5921787709497207,0.29378531073446335,0.29050279329608936,0.2376877463889896
211,"The cartoon animation industry has potential in various markets, but animators struggle to find relevant materials due to limited classification of cartoon materials. Polar emotions of cartoon pictures are important for creators to easily obtain the pictures they need. A deep learning-based method is proposed to classify polar emotions of ""Moe"" style cartoon pictures, using facial expression recognition, scene features, and facial features. The method achieves 81.9% accuracy and can be used in the cartoon animation industry.



","We propose a deep learning-based method to classify the polar emotions of cartoon pictures in the ""Moe"" drawing style . The method uses facial expression recognition, scene features, and facial features of the cartoon images to correct the emotions of the pictures obtained . Experimental results demonstrate that this method achieves an accuracy of 81.9%, making it competitive for use in the cartoon animation industry . Some methods for emotion recognition have been proposed, but most focus on expression recognition .",0.6075949367088608,0.358974358974359,0.4050632911392405,0.2955155561691574
212,"Children on the autism spectrum (AS) show comparable emotional recognition (ER) skills to typically developing (TD) children when using music, despite reduced accuracy with facial and vocal emotions. A study examined ER from music, faces, and voices among 25 AS children and 23 TD children. The AS group showed relative strength in ER from music and comparable performance with faces and voices, whereas the TD group performed better with faces. Both groups had similar performance with dimensional ratings. The findings suggest a need to re-examine ER of AS children and consider strengths-based approaches such as music therapy and interventions.



","Children on the autism spectrum (AS) demonstrate comparable ER skills to those of typically-developing (TD) children using music . Twenty-five children on the AS and 23 TD children (6–13 years) completed an ER task using categorical (happy, sad, fear) and dimensional (valence, arousal) ratings . The AS group showed a relative ER strength from music, and comparable performance from faces and voices . These findings highlight a need to re-examine ER",0.6011560693641618,0.3391812865497076,0.4855491329479768,0.2171327928005291
213,"This study focused on the importance of avatar realism in collaborative virtual environments, using face tracking technology to render facial expressions. Participants interacted through video-conference, voice only, or an ""emotibox"" that abstracted facial expressions. Results showed that self-disclosure was lowest in the video-conference condition, while copresence and emotion transmission success were lowest in the emotibox condition. The study suggests a need for a hybrid realism solution and highlights potential benefits for distance learning and therapy.","Effect of Behavioral Realism and Form Realism of Real-Time Avatar Faces on Verbal Disclosure and Nonverbal Disclosure . Participants in dyads interacted with each other via video-conference, voice only, or an ""emotibox"" that rendered facial expressions abstractly in terms of color, shape, and orientation on a rectangular polygon . Previous work demonstrates that avatar realism increases copresence while decreasing self-disclosure .",0.4316546762589928,0.16058394160583941,0.27338129496402874,0.15702970925780152
214,"Recent studies have found that deficits in recognizing facial expressions of fear, disgust, and anger are associated with deficits in producing those emotions. The authors explore the simulation and theorizing approaches to explain this pattern and conclude that the simulation approach offers the best explanation. The authors then examine four alternative models of simulation-style emotion detection, but note that the computational process of simulation is not well understood. They suggest that the next step is to explore different options for a simulation heuristic to attribute a mental state, depending on the causal link between evidence events and the target state.","Simulationist models of face-based emotion recognition Emotion; Fear; Disgust; Anger; Theory of mind; Simulation theory; Facial feedback; Mirror neuronRecent studies of emotion mindreading reveal that for three emotions, fear, disgust, and anger, deficits are paired with deficits in the production of the same emotion . The simulation approach and the theorizing approach are examined to determine their compatibility with the existing evidence . Four alternative models are explored: a generate-and-test model, a variant of the",0.4519774011299435,0.14857142857142858,0.2824858757062147,0.09709928644856017
215,"The report presents evidence supporting the idea that facial identity recognition and facial expression recognition are performed by separate mechanisms in the brain. The evidence comes from studying an individual named NM, who has severely impaired facial identity recognition but normal facial expression recognition. The study involved a variety of tests that assessed NM's abilities in different ways, and the results suggest that facial identity and expression recognition are independent processes.","NM, a 40-year-old prosopagnosic, showed severely impaired performance on five of six tests of facial identity recognition . The tests of identity recognition and emotion recognition assessed her abilities in a variety of ways . Our tests of expression recognition varied in the number of faces involved in the task (one/many), whether recognition of novel views was required, and the time duration between memorization of a face and recognition of the face .",0.42758620689655175,0.16783216783216784,0.2206896551724138,0.051942855891963506
216,"Facial emotion recognition deficits are common in schizophrenia but factors associated with impairment at each stage of the disease are still unclear. This article summarizes studies on facial emotion recognition in schizophrenia, introduces the Bruce-Young face recognition model, and reviews studies on recognition of emotions at each stage of face recognition. Most studies find that patients are more impaired in recognizing negative emotions, but there is variability in tasks used and stimuli presented. Future studies should include all six basic emotions to balance the results.","Deficits in facial emotion recognition are one of the most common cognitive impairments, and they have been extensively studied in various psychiatric disorders, especially in schizophrenia . However, there is still a lack of conclusive evidence about the factors associated with schizophrenia and impairment at each stage of the disease, which poses a challenge to the clinical management of patients . Based on this, we summarize facial emotion cognition among patients with schizophrenia, introduce the internationally recognized Bruce-Young model, and review the behavioral and event-related",0.5380116959064327,0.21301775147928995,0.3508771929824562,0.1353833403713244
217,"This study assessed the effectiveness of The Transporters, an animated series designed to enhance emotion comprehension in children with autism spectrum conditions (ASC). Twenty children with ASC aged 4-7 watched the series daily for four weeks and were tested on emotional vocabulary and emotion recognition at three levels of generalization before and after the intervention. Results showed that the intervention group significantly improved more than a clinical control group and performed comparably to typically developing children at Time 2. The study also found significant differences between the groups on the tasks at Time 1, with typical controls scoring higher than both clinical groups.","n = 20 children with ASC (aged 4–7) watched The Transporters everyday for 4 weeks . Participants were tested before and after intervention on emotional vocabulary and emotion recognition at three levels of generalization . Two matched control groups of children were also assessed twice without any intervention . The intervention group improved significantly more than the clinical control group on all task levels, performing comparably to typical controls at Time 2 . Pre-planned comparisons using Bonferroni corrections showed that these differences were due to the significantly higher scores of the typical controls",0.6494845360824743,0.3645833333333333,0.4639175257731959,0.18854270908441476
218,"Research investigated whether the age-related decline in emotion recognition is due to a tendency to overlook emotion information in the eyes. The study found that younger adults were better at inferring emotions from full faces and eyes than older adults, and young adults looked more to eyes than mouths. However, better emotion recognition performance was significantly correlated with more eye looking in younger adults, but not in older adults. The study highlights the effects of aging on emotion recognition and brain changes with age.","Age Differences in Emotion Recognition Skills and the Visual Scanning of Emotion FacesAge-related decline, emotion recognition, eyes vs mouth, younger adults, older adults, eye tracking, visual scanning . In Experiment 1, younger adults were significantly better than older adults at inferring emotions from full faces and eyes, though not from mouths . Table 1 depicts performance on the six emotion types in the three modalities . We log-transformed and analyzed data with a 2 (Age Group",0.5875,0.2278481012658228,0.3125,0.17176595766703634
219,"This research article discusses the use of Machine Learning (ML) methods in healthcare to predict and classify heart diseases and locomotor disorders. The researchers used an online UCI dataset with 303 rows and 76 properties, and approximately 14 of these properties were selected for testing different ML methods such as Naive Bayes, SVM, Logistic Regression, Decision Tree Classifier, Random Forest, and K- Nearest Neighbor. The experimental results showed that the KNN algorithm outperformed the other methods in terms of precision, F1 score, accuracy, and recall. The researchers concluded that ML methods significantly outperformed statistical techniques and are the best choice for predicting and classifying heart disease even with a smaller database. Future work could involve exploring other ML methods and parameters for improving the accuracy of heart disease predictions.","ML methods help in the protection of heart diseases, locomotor disorders in the medical data set . The discovery of such essential data helps researchers gain valuable insight into how to utilize their diagnosis and treatment for a particular patient . In this research, we are using an online UCI dataset with 303 rows and 76 properties . This analysis is based on supervised learning methods, i.e., Naive Bayes, SVM, Logistic regression, Decision Tree Classifier, Random Forest, and K- Nearest",0.463768115942029,0.2634146341463415,0.3285024154589372,0.19249632327193603
220,"Lung cancer is a major cause of cancer-related deaths, often due to late diagnosis. Pulmonary nodules are the initial presentation in most lung cancers, making accurate classification critical for early detection. Recent advances in artificial intelligence (AI) and deep learning (DL) have shown promising results in pulmonary nodule detection, segmentation, and classification for lung cancer prediction. This review provides an overview of progress in AI-assisted nodule evaluation, but there are still limitations to overcome, including general acceptance of disruptive innovation. Nonetheless, ML has demonstrated promising potential for pulmonary nodule evaluation, and it is important for radiologists and clinicians to be aware of these capabilities and limitations to improve patient care.","Lung cancer remains the leading cause of cancer related death world-wide despite advances in treatment . This largely relates to the fact that many of these patients already have advanced diseases at the time of initial diagnosis . Deep learning (DL) and convolutional neural networks (CNNs) have shown promising results in pulmonary nodule detection and have also excelled in segmentation and classification . There has been much progress in AI assisted nodules segmentation, detection and classification in the recent years .",0.4842105263157895,0.23404255319148937,0.31578947368421056,0.12717585113043708
221,"Despite extensive research efforts, predicting cardiovascular disease risks based on health records has remained unsatisfactory. An ensemble method, XGBoost, achieved high accuracy in predicting 3-year CHD onset by using sophisticated machine-learning methods to tackle the heterogeneity and nonlinear nature of disease prediction. Nonlinear models outperformed linear models on the same datasets, and machine-learning methods significantly surpassed traditional risk scales or fixed models. Using time-dependent features obtained from multiple records helped improve performance compared to using only static features. Accumulated EHR data over multiple time points provided additional valuable features for risk prediction. This study highlights the importance of accumulating big data from EHRs for accurate disease predictions.","Predictions of cardiovascular disease risks based on health records have long attracted broad research interests . This raises the question as to whether data insufficiency, statistical and machine-learning methods, or intrinsic noise have hindered the performance of previous approaches . We demonstrated that accurate risk prediction of CHD from EHRs is possible given a sufficiently large population of training data . accumulated data over multiple time points provided additional features that were valuable for risk prediction .",0.4432432432432432,0.19672131147540983,0.2918918918918919,0.14448932965968048
222,"The study proposes a deep learning model using non-invasive CT images to predict EGFR mutation status in lung adenocarcinoma patients. The model was trained on 14926 CT images from a primary cohort and validated on an independent validation cohort from another hospital. The model achieved encouraging predictive performance in both cohorts, with AUCs of 0.85 and 0.81, respectively. The deep learning model revealed a significant association between high-dimensional CT image features and EGFR genotype, offering an alternative method for non-invasive assessment of EGFR information for patients. The model requires only the raw tumour image as input and predicts EGFR mutation status directly without further human assistance, making it easy to use and very fast. The deep learning score demonstrated significant differences in EGFR-mutant and EGFR-wild type tumours. The model provides a non-invasive and easy-to-use method for EGFR mutation status prediction, which could supplement biopsy and offer a great visual interpretation to clinicians.","Deep learning model was proposed to predict EGFR mutation status in lung adenocarcinoma using non-invasive computed tomography (CT) deep learning model showed encouraging predictive performance in primary cohort (n=603; AUC 0.85, 95% CI 0.83–0.88) by training in 14926 CT images . Deep learning score demonstrated significant differences in EGF-mutant and EGf-wild type tumours (p0.001).",0.4107142857142857,0.27027027027027023,0.3214285714285714,0.06816691768507735
223,"The paper introduces a new blind source separation (BSS) method for separating temporal correlated noncircular sources using a widely linear filter (WLF) model. The algorithm includes a WLF coefficients estimator and a complex matrix joint diagonalization step, which requires a new joint diagonalization algorithm called successive Shear and Givens rotations (SGR). The proposed BSS algorithm is shown to have superior performance compared to other algorithms for both noncircular complex Gaussian and non-Gaussian sources. The paper concludes by suggesting future work on improving separation performance by jointly using time structure and statistical characteristics of the signals.","In the derivation of the new BSS algorithm, we encountered a new matrix joint diagonalization problem . Simulations of SGR show that it converges fast, and it shows a satisfactory antiperturbation performance of matrix . In this paper, the blind separation of stationary complex sources was studied only using the dependency among samples . This paper introduces a blind source separation (BSS) method for temporal correlated noncircular sources that uses widely linear filter (WLF) model .",0.4880952380952381,0.2289156626506024,0.2380952380952381,0.19838854673209333
224,This paper proposes a unified framework for pupil detection using shape augmented cascade regression models learned from adversarial synthetic images. The proposed method introduces a step of parallel imaging using Generative Adversarial Networks (GANs) to refine synthetic eye images with texture and appearance from real images while preserving structural shape from synthetic images. The computational experiments show that the proposed method achieves state-of-the-art performance on three benchmark datasets. Future work will focus on designing powerful nonlinear architectures for mapping appearance and target updates in cascade levels and realizing parallel execution for real-time optimization with unlabeled images. The proposed method addresses the limited availability of accurate eye center annotations and time-consuming manual labeling of training data by leveraging the power of cascade regression and adversarial image synthesis.,"Cascade regression GANs Pupil detectionmage-based pupil detection has been an active research topic in computer vision community . Learning-based approaches can achieve preferable results given large amounts of training data with eye center annotations . However, there are limited publicly available datasets with accurate eye centers annotations and it is unreliable and time-consuming for manually labeling large amounts . In this paper, we introduce a step of parallel imaging built upon Generative Adversarial Networks (GANs) to",0.39613526570048313,0.20487804878048785,0.19323671497584544,0.09660859530159553
225,"This study compared the hazard identification performance and search patterns of experienced and novice workers in the construction industry using eye-tracking technology. The experiment involved four images of workplaces with obvious and unobvious hazards, and the results showed that experienced workers identified hazards faster and with more confidence than novice workers, but accuracy and miss rates were similar. The study suggests that improving safety training and hazard awareness about working at heights is crucial for construction workers, and eye-tracking technology may be used to improve safety training by analyzing search patterns and identifying insufficiencies in novice workers. Overall, the study provides valuable information for safety trainers and educators in the construction industry.","The construction industry accounts for a high number of accidents . The experience helps in training novice inspectors, although extracting and describing tacit knowledge explicitly is difficult . This study created a digital building construction site, and designed a hazard-identification experiment involving four workplaces featuring obvious and unobvious hazards (e.g., falls, collapses, and electric shocks), and an eye-tracker was used to compare the search patterns of experienced and novice workers .",0.42162162162162165,0.1967213114754098,0.23783783783783782,0.1022024910786001
226,"The study compared machine learning approaches with logistic regression analysis to predict acute kidney injury (AKI) after cardiac surgery. They retrospectively reviewed 2010 patients and obtained baseline medical condition, intraoperative anesthesia, and surgery-related data. The following machine learning techniques were used: decision tree, random forest, extreme gradient boosting, support vector machine, neural network classifier, and deep learning. The performance of these techniques was compared with that of logistic regression analysis regarding the area under the receiver-operating characteristic curve (AUC). During the first postoperative week, AKI occurred in 38.3% of patients. The best performance regarding AUC was achieved by the gradient boosting machine to predict all stages of AKI or stage 2 or 3 AKI. The study demonstrated that the machine learning technique of extreme gradient boosting showed significantly better performance than the traditional logistic regression analysis or previous risk scores in predicting both AKI of all stages and stage 2 or 3 AKI after cardiac surgery. Gradient boosting machine may be used for real-time processing of patient data to estimate the risk of AKI after cardiac surgery at the end of surgery.","We retrospectively reviewed 2010 patients who underwent open heart surgery and thoracic aortic surgery . Baseline medical condition, intraoperative anesthesia, and surgery-related data were obtained . The primary outcome was postoperative acute kidney injury (AKI) defined according to the Kidney Disease Improving Global Outcomes criteria . In our comprehensive comparison of machine learning approaches with logistic regression analysis, gradient boosting technique showed the best performance with the highest AUC and lower error rate .",0.3657587548638132,0.1803921568627451,0.23346303501945523,0.06913996858747969
227,"This study used Electronic Medical Record (EMR) data from primary care clinics in seven provinces across Canada to develop predictive models to identify patients with Chronic obstructive pulmonary disease (COPD). The study applied two supervised machine learning models, a Multilayer Neural Networks (MLNN) model and an Extreme Gradient Boosting (XGB) to identify COPD patients from control patients within community-based health care EMRs in Canada. The XGB model achieved an accuracy of 86% in the test dataset compared to 83% achieved by the MLNN. Feature importance analysis was used to identify a set of key symptoms from the EMR for diagnosing COPD, which included medications, health conditions, risk factors, and patient age. The study concludes that the application of the XGB model to primary care structured EMR data can identify patients with COPD from others having similar chronic conditions for disease surveillance and improve evidence-based care delivery. Future studies plan to include free-text EMR chart notes recorded by physicians during patient encounters within the primary care systems to improve care delivery and inform hospital readmission prediction of patients, thus creating improved efficiencies within the healthcare system.","Approximately 10% of Canadians aged 35 years or older are living with COPD . Primary care is often the first contact an individual will have with the healthcare system providing acute care, chronic disease management, and services aimed at health maintenance . We applied two supervised machine learning models, a Multilayer Neural Networks (MLNN) model and an Extreme Gradient Boosting (XGB) to identify COPD patients .",0.3187250996015936,0.20080321285140565,0.2151394422310757,0.07134161493421878
228,"Healthcare data analysis has become a promising research area due to the various types of data available, such as clinical, omics, and sensor data. To handle this raw data manually is difficult, so machine learning has emerged as a significant tool to predict results more accurately. Different types of machine learning algorithms, such as supervised, unsupervised, and reinforcement, are used for analysis. This paper surveys the use of machine learning algorithms for analyzing various healthcare data types, including clinical, omics, and sensor data. The performance parameters used to evaluate these algorithms include accuracy, sensitivity, specificity, precision, F1 score, and Area under Curve. From the survey, it is concluded that various machine learning algorithms and feature extraction techniques have been proposed by various authors for survival prediction of cancer patients.","In recent years, healthcare data analysis is becoming one of the most promising research areas . Healthcare includes data in various types such as clinical data, Omics data, and Sensor data . Clinical data includes electronic health records which store patient records collected during ongoing treatment . To handle raw data manually is very difficult . Machine learning uses various statistical techniques and advanced algorithms to predict the results of healthcare data more precisely . A different type of data is present in healthcare .",0.5,0.1844660194174757,0.3269230769230769,0.07055843167362309
229,"This survey paper provides a comprehensive overview of machine learning techniques used for various medical applications. The paper identifies a shift towards the use of deep learning methods over traditional machine learning methods for medical data analysis. The authors conducted a systematic literature review of highly reputable journals in recent years and identified support vector machines, decision trees, random forests, neural networks, and convolution neural networks as the most commonly used techniques. The paper also discusses the challenges associated with analyzing medical data and the increasing use of deep learning models for medical image segmentation, medical diagnosis, and dementia prognosis. Overall, this survey paper provides important insights and trends in the current research of computer science and medical research.","This literature review identifies a clear shift of artificial intelligence techniques used in the medical domain, with deep learning methods taking precedence over machine learning methods . With the emergence of big data, machine learning techniques are used to learn, analyze, and extrapolate details in medical research . This survey provides a comprehensive overview of the ML techniques including support vector machines, K-means clustering, decision trees, random forests, Nave Bayes .",0.5106382978723405,0.22580645161290325,0.25531914893617025,0.13109111023206502
230,"This paper proposes an evolutionary framework for rule-based classifier induction to address supervised learning problems, particularly in medical data analysis. The framework uses genetic programming to build a search method for classification rules, dealing with problems such as maximum rule length and rule intersection. The experiments show promising results and competitive performance when compared to other approaches. The paper identifies fitness functions, a combination of fitness functions, an ensemble classifier model, and an upper bound for the maximum rule size as significant contributions to the framework. Overall, the proposed framework can be useful in the analysis and knowledge discovery process from medical databases.","This paper proposes an evolutionary framework for rule-based classifier induction . Our proposal introduces genetic programming to build a search method for classification-rules (IF/THEN) From this approach, we deal with problems such as, maximum rule length and rule intersection . The achieved results define a methodology to follow in the learning method evaluation for knowledge discovery from medical data . We have also seen that the most common approaches used in machine learning are classification and regression .",0.56353591160221,0.39106145251396646,0.46408839779005523,0.23576003388314448
231,"
This study aimed to predict cardiac surgery-associated acute kidney injury (CSA-AKI) using artificial intelligence-based machine learning. The study included 671 patients who underwent cardiac surgery, and AKI was defined according to KDIGO criteria. The variables analyzed included demographic characteristics, clinical condition, preoperative biochemistry data, preoperative medication, and intraoperative variables such as time-series hemodynamic changes. Logistic regression, support vector machine, random forest, extreme gradient boosting, and ensemble models were used for analysis. The random forest model exhibited the greatest area under the receiver operating characteristic curve (AUC) of 0.839, and the ensemble model (random forest + extreme gradient boosting) had an even greater AUC of 0.843. The top 3 most influential features in the random forest importance matrix plot were intraoperative urine output, units of packed red blood cells transfused during surgery, and preoperative hemoglobin level. The study concluded that machine learning methods can successfully predict AKI after cardiac surgery, and intraoperative time-series and other features are crucial for AKI prediction. Further software development is ongoing for real-time adjustment of AKI risks following cardiac surgery.",Cardiac surgery–associated acute kidney injury (CSA-AKI) is a major complication that results in increased morbidity and mortality after cardiac surgery . Most established prediction models are limited to the analysis of nonlinear relationships and fail to fully consider intraoperative variables . A total of 671 patients undergoing cardiac surgery from August 2016 to August 2018 were enrolled . The results were evaluated using the area under the receiver operating characteristic curve (AUC),0.35714285714285715,0.152,0.20634920634920634,0.05116144004483763
232,"The text describes a new computer-aided diagnosis (CAD) system called Collaborative CAD (C-CAD) that uses eye-tracking technology and a deep learning algorithm to assist radiologists in reducing diagnostic errors in lung and prostate cancer screening. C-CAD unifies CAD and eye-tracking systems in realistic radiology room settings and incorporates radiologists' search efficiency by processing their gaze patterns. The proposed attention-based graph sparsification method extracts global search patterns and attention regions, while the 3D deep multi-task learning-based CNN performs diagnosis and segmentation tasks jointly inside ROIs. The system has been tested in lung and prostate cancer screening experiments with multiple radiologists, demonstrating its efficiency, accuracy, and applicability in real radiology room settings. The system has the potential to improve true positive findings and reduce missing cases, as well as reduce false positive findings. However, the system has limitations and requires further validation and exploration in different settings.","Vision researchers have been analyzing behaviors of radiologists during screening to understand how and why they miss tumors or misdiagnosis . We propose a paradigm shifting CAD system, called collaborative CAD (C-CAD), that unifies CAD and eye-tracking systems in realistic radiology room settings . The proposed C-CAD system has been tested in a lung cancer screening experiment with multiple radiologists, reading low dose chest CTs . Our proposed sparsification method reduced 90% of data within seconds while keeping mean the square error",0.4085106382978723,0.25751072961373395,0.30638297872340425,0.12399114407455035
233,"The article discusses the limitations of existing healthcare learning models and the difficulty in incorporating expert knowledge from heterogeneous medical data sources. The authors propose a knowledge extraction framework that integrates multiple sources to generate an aggregated dataset for disease characterization, and an end-to-end deep learning based medical diagnosis system (DL-MDS) that provides disease diagnosis for authorized users with personalized queries and explanations for the results. The system shows promising results on real-world data, but future work includes integrating query processing and disease diagnosis models, incorporating additional information like lab test results, and improving the system to support multiple languages.","a deep learning based medical diagnosis system (DL-MDS) can be used to provide disease diagnosis for authorized users . In addition, patients' queries at medical consult websites are often ambiguous in their specified terms and hence the returned responses may not contain the information they seek . To tackle these problems, we first design a knowledge extraction framework that can generate an aggregated dataset to characterize diseases by integrating heterogeneous medical data sources . We also provide explanations for the diagnose results .",0.47826086956521735,0.26373626373626374,0.2282608695652174,0.21115551184741962
234,"The text discusses the importance of social media sentiments for providing up-to-date and inclusive information, and the lack of a systematic arrangement of prior efforts in sentiment analysis. The paper presents typical methods from three different perspectives, categorizing and comparing a large quantity of techniques and methods, introducing different types of data and advanced tools, and identifying the essential prospects for sentiment analysis. The survey establishes a common terminology and lays a foundation for advanced research in sentiment analysis. The paper emphasizes the prospects for future development, including multimodal sentiment analysis, which offers significant opportunities for research in the multi-disciplinary field of multimodal fusion.","Survey of sentiment analysis in social media, Social media, Data mining, Survey.Sentiments or opinions from social media provide the most up-to-date and inclusive information due to the proliferation of social media and the low barrier for posting the message . It is essential to (1) analyze its progress over the years, (2) provide an overview of the main advances achieved so far, (3) outline remaining limitations . On the basis of these materials, the essential prospects lying ahead for sentiment analysis are identified and discussed .",0.40414507772020725,0.1361256544502618,0.24870466321243526,0.06065732486338617
235,"The article discusses a learning-based approach for semantic indexing of multimedia content using cues from audio, visual, and text features. Statistical models are developed for a predefined lexicon, and novel concepts are mapped to the concepts in the lexicon. Multiple modalities are used for robust concept detection, and models such as Gaussian mixture models, hidden Markov models, and support vector machines are employed. The article demonstrates that integrating information from multiple modalities can improve semantic labeling performance, and future research directions include improving atomic and high-level concept classification, determining appropriate low-level features, and identifying schemes for automatic determination of atomic concepts.","Semantic Indexing of Multimedia Content Using Visual, Audio, and Text Cuessentiment indexing, query by keywords, multimodal information fusion, statistical modeling of multimedia, video indexing and retrieval, SVM, GMM, HMM, spoken document retrieval . Novel concepts are then mapped in terms of the concepts in the lexicon . Concept representations are modeled using Gaussian mixture models (GMM), hidden Markov models (HMM), and support vector machines (SVM)",0.4550898203592814,0.2424242424242424,0.3952095808383233,0.17038916423618708
236,"The paper proposes a method for aspect-based sentiment analysis using a cascaded framework of feature selection and classifier ensemble using particle swarm optimization (PSO). The method involves a two-step process for feature selection and ensemble learning using PSO, and builds domain-independent models for aspect-based sentiment analysis that achieve state-of-the-art performance. The proposed approach uses three base learning algorithms, Maximum Entropy, Conditional Random Field, and Support Vector Machine. The results of experiments on benchmark datasets show the effectiveness of the proposed technique with reasonable performance increments. Future work includes exploring multi-objective optimization and testing the proposed system in other domains and languages.","Aspect based sentiment analysis is performed in two steps, viz. aspect term extraction and sentiment classification . We further construct an ensemble based on PSO, and put it in cascade after the feature selection module . As base learning algorithms we use three classifiers, namely ME, SVM and ME . The ensemble learner finds out the most eligible models, that when combined together, maximizes some classification quality measures like F-measure or accuracy (for sentiment classification). The current work focuses on single objective optimization technique, where",0.39583333333333326,0.10526315789473684,0.21875,0.028510380695207435
237,"The article presents a hybrid approach to Sentiment Analysis using NLP techniques, a sentiment lexicon enhanced with SentiWordNet, and fuzzy sets to estimate polarity and intensity. The method is applied to three datasets and compared to Naïve Bayes and Maximum Entropy techniques, demonstrating higher accuracy and precision. The system is effective in identifying strengths in polarity degree and classifying neutral or objective sentences. However, the system faces challenges in dealing with jargon, metaphors, and sarcasm. Future work includes creating an automatic real-time interface, investigating the use of SenticNet, incorporating context, and developing a computing with sentiments approach.","The proposed hybrid method is applied to three different data-sets . It is demonstrated that the presented hybrid approach is more accurate and precise than both Nave Bayes and Maximum Entropy techniques, when the latter are utilised in isolation . This is satisfies our initial hypothesis that a hybrid method using sentiment lexicons, NLP essential techniques and fuzzy sets should be able to perform well .",0.3803680981595092,0.17391304347826086,0.2085889570552147,0.09076129536914054
238,"The text discusses how deep learning techniques have become popular for sentiment analysis, providing better performance than traditional feature-based techniques. The paper proposes models that combine classic hand-crafted features with automatically extracted embedding features, as well as the ensemble of analyzers that learn from these varied features. The authors introduce a taxonomy for classifying the different models found in the literature, conduct several experiments to compare the performance of these models, and confirm that the proposed models surpass the deep learning baseline. The paper also raises possible lines of work for applying these models to aspect-based sentiment analysis and extending them to other languages and paradigms like emotion analysis.","Deep learning techniques for Sentiment Analysis have become very popular . They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods) Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods . In this paper, we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches . Third, we propose two models for combining both surface and deep features to merge information from",0.42786069651741293,0.1407035175879397,0.26865671641791045,0.061591644681728286
239,"The text discusses the challenge of automatic sentiment classification in different domains and the impracticality of annotating corpora for every possible domain. The article presents a study on domain adaptation for sentiment classifiers, particularly for online reviews of various products. The study includes the extension of the structural correspondence learning (SCL) algorithm for sentiment classification, which improves the adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline. The article also identifies a measure of domain similarity that correlates with the potential for adaptation of a classifier from one domain to another, which can be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains. The authors aim to include recent advances in sentiment classification and address the more realistic problem of ranking, as well as testing their techniques on a larger and more varied set of domains.","semantic sentiment classification has been extensively studied and applied in recent years . However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical . We extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline .",0.44247787610619466,0.28571428571428564,0.34513274336283184,0.14295790344205256
240,"The study conducted four experiments to examine the effectiveness of a self-administered computer-based training for emotion recognition ability (ERA) in non-clinical adults. The training covered 14 different emotions and multiple sensory channels. The study found that the training improved ERA in younger and middle-aged adults and that the effects persisted for at least four weeks. However, the training had no effect on older adults. The study suggests that interventions focusing on many emotions and multiple sensory modalities might be more ecologically valid. The study has limitations that need to be addressed in future research.","a short audiovisual emotion recognition training program in adultsemotion recognition ability, audiovisual training, non-clinical adults, lifespan sample, multiple sensory channels, transfer effects, older adults . The training was found to increase ERA in younger and middle-aged adults when completed in the laboratory and online, and the effects persisted over at least four weeks . In older adults, improving ERA might require a longer and more interactive intervention . This study suggests interventions focusing on many emotions and on multiple sensory modalities simultaneously might be more",0.6043956043956044,0.34444444444444444,0.4725274725274725,0.2291406345995451
241,"The article discusses the development of a convolutional neural network (CNN) for real-time facial emotion recognition, which was achieved using transfer learning on a pre-trained CNN for human emotion classification. The model achieved an overall training accuracy of 90.7% and test accuracy of 57.1% and was able to classify an arbitrary number of faces simultaneously in real time. The study demonstrated the feasibility of using neural networks for emotion detection in real time, but identified several key issues that need to be addressed to improve accuracy, including the need for a larger and more diverse dataset, heavier pre-processing of the data, and developing a running average solution for classifying transition frames. The source code for the project is available on Github.



","We use transfer learning on the fullyconnected layers of an existing convolutional neural network which was pretrained for human emotion classification . A variety of datasets, as well as our own image dataset, is used to train the model . An overall training accuracy of 90.7% and test accuracy of 57.1% is achieved . Finally, a live video stream connected to a face detector feeds images to the neural network . The network then classifies an arbitrary number of faces per image simultaneously in real time .",0.5333333333333333,0.2980769230769231,0.35238095238095235,0.1990214347390923
242,"The article discusses a study that aimed to create a set of highly realistic virtual faces for use in virtual reality (VR) cyberinterventions to train people with schizophrenia in social skills. The study found that the VR faces were as valid as standardized natural faces for accurately recreating human-like facial expressions of emotions. The use of virtual agents and environments has several clinical implications, and advances in virtual reality technology can help to overcome some of the limitations associated with the use of static faces. However, there are limitations to the study, and further research is needed to establish the potential of virtual agents in the design of new treatment programs and cyberinterventions for psychiatric and psychological disorders.",The ability to recognize facial emotions is target behaviour when treating people with social impairment . The main objective of the present study was to create a new set of virtual faces with high realism that could be integrated into a virtual reality cyberintervention to train people with schizophrenia in the full repertoire of social skills . A set of highly realistic virtual faces was created based on the Facial Action Coding System . Facial movement animation was also included so as to mimic the dynamism of human facial expressions .,0.4368932038834952,0.19607843137254904,0.2621359223300971,0.12491195866128388
243,"The study aimed to investigate whether improved emotion recognition of novel faces is associated with concomitant changes in visual scanning of these same novel facial expressions in participants with schizophrenia who received emotion recognition training using Ekman's Micro-Expression Training Tool (METT). The results showed that participants had changes in foveal attention to the features of facial expressions of emotion not used in METT training, and improved emotion recognition was paralleled by changes in the way participants viewed novel facial expressions of emotion. However, there were overall decreases in foveal attention to sad and neutral faces that indicate more intensive instruction might be needed for these faces during training. Participant gender may also affect training outcomes.","Effects of facial emotion recognition remediation on visual scanning of novel face stimuliemotion recognition, schizophrenia, visual scanning, facial expressions . Thirty-nine participants with schizophrenia received emotion recognition training using Ekman's Micro-Expression Training Tool (METT), with emotion recognition and visual scanpath (VSP) recordings . Baseline ratings of interpersonal and cognitive functioning were also collected from all participants . The aim of this study was to investigate whether improved emotion recognition of novel faces is associated with concomitant changes in",0.5435897435897437,0.3316062176165803,0.3282051282051282,0.24806101671824107
244,"This paper discusses the increasing interest in emotional computing and focuses on different learning methods for facial emotion recognition, including Support Vector Machines and Deep Boltzmann Machines. The authors use data sets from FERA 2015 and combine geometric and appearance features for prediction. They compare different prediction systems and conclude that decision-level fusion is the most commonly used method, despite limitations in correlation between different feature sets. The authors also note that finding an appropriate joint feature vector remains an unsolved problem.","The interest on emotional computing has been increasing as many applications were in demand by multiple markets . This paper focuses on different learning methods, and has implemented several methods: Support Vector Machine (SVM) and Deep Boltzmann Machine (DBM) Different prediction systems are developed and the prediction results are compared . For model-level fusion, achieving multi-time-scale labeling multimodal fusion is still an unsolved problem .",0.48648648648648646,0.23287671232876714,0.35135135135135137,0.11722193465658362
245,"This paper discusses the challenges of human facial emotion recognition (FER) and proposes a very Deep CNN (DCNN) modeling approach through Transfer Learning (TL) technique to improve FER accuracy. The proposed FER system is verified on eight different pre-trained DCNN models and well-known facial image datasets. The proposed method achieved remarkable accuracy on both datasets with pre-trained models. The evaluation results reveal the superiority of the proposed FER system over the existing ones regarding emotion detection accuracy. Moreover, the achieved performance on the KDEF dataset with profile views is promising as it clearly demonstrates the required proficiency for real-life applications. The current research can be compatible with broader real-life industry applications, such as monitoring patients in the hospital or surveillance security.","The classical FER consists of two major steps: feature extraction and emotion recognition . Currently, the Deep Neural Networks is widely used in FER by virtue of its inherent feature extraction mechanism from images . A notable drawback of the most existing methods is that they consider only the frontal images (i.e., ignore profile views for convenience), although the profile views taken from different angles are important for a practical FER system .",0.27411167512690354,0.041025641025641026,0.15228426395939088,0.007087157843910606
246,"This paper describes a facial emotion recognition model that uses Convolutional Neural Networks (CNN) and Deep Neural Networks (DNN) to classify facial expressions into seven emotions. The proposed Venturi architecture is compared to two existing architectures, and the Karolinska Directed Emotional Faces dataset is used for testing. The Venturi architecture shows significant improvement in accuracy compared to the other architectures. In future work, the authors plan to evaluate the performance of the Venturi architecture on other databases and to use it in a multi-modal deep neural network for improved efficacy.","Modified Convolutional Neural Network Analysis for Facial Emotion RecognitionTraining . This paper uses the Karolinska Directed Emotional Faces dataset . The Venturi Architecture shows significant accuracy improvement compared to the modified triangular architecture and the rectangular architecture . In future, plan to evaluate the performance of the Venturi architecture on other facial emotion database and to use this architecture to evaluate a multi modal deep neural network with both the facial emotion images and emotion audio samples .",0.703030303030303,0.45398773006134974,0.5333333333333334,0.2665136532674101
247,The paper discusses the importance of facial expression recognition in computer vision and artificial intelligence. The paper uses the Cohn-Kanade Database (CK) and the Extended Cohn-Kanade (CK+) database to detect facial landmarks and classify emotions using machine learning algorithms such as Support Vector Machines (SVM). The results showed an accuracy of 94.1%. The system can be extended to deep learning using Convolutional Neural Networks (CNN) to achieve higher accuracy. The study can be expanded to detect multiple emotions of different people in real-time videos. Emotion recognition is important for human-robot interactions in the field of robotics and artificial intelligence.,"There is strong evidence for the universal facial expressions of eight emotions which include: neutral happy, sadness, anger, contempt, disgust, fear, and surprise . It is very important to detect these emotions on the face as it has wide applications in the field of Computer Vision and Artificial Intelligence . In Robotics, emotions classification can be used to enhance human-robot interactions since the robot is capable of interpreting a human reaction .",0.40229885057471265,0.13953488372093023,0.21839080459770113,0.08107182596034289
248,"This paper proposes a multi-channel deep neural network called MDSTFN for recognizing facial expressions in static images by extracting and fusing spatial-temporal features. The method uses optical flow from the changes between emotional-face and neutral-face as the temporal information and gray-level image of emotional-face as spatial information. The feature extraction channels of MDSTFN are fine-tuned from a pre-trained CNN model. The proposed method achieves better recognition accuracy compared to state-of-the-art methods, with rates of 98.38% on CK+, 99.17% on RaFD, and 99.59% on MMI databases, respectively. Replacing neutral-face with average-face improves the practicality of the proposed method.",Multi-channel Deep Spatial-Temporal feature Fusion neural Network (MDSTFN) is presented to perform the deep spatial-temporal feature extraction and fusion from static images . Each channel of the proposed method is fine-tuned from a pre-trained deep convolutional neural networks (CNN) instead of training a new CNN from scratch . The results show that the optical flow information from emotional-face and neutral-face is a useful complement to spatial feature and can effectively improve the performance of facial expression recognition from,0.5204081632653061,0.24742268041237114,0.2857142857142857,0.07779910181771166
249,"The paper discusses the importance of facial expression recognition (FER) in various domains and introduces an FER system that uses Histogram of Oriented Gradient (HOG) features and Support Vector Machine (SVM) for classification. The proposed method extracts shape and appearance features from still images for varying facial expressions, making it subject independent and robust. The accuracy of the proposed system is found to be 92.56% on the Cohn-kanade dataset for six basic expressions. Results show that shape features are better than texture or geometric features for emotion modeling, and HOG features make the FER system robust and suitable for real-time implementation. However, the detection rates for disgust, fear, and sadness are lower than other emotions, which can be improved by combining shape, texture, and geometric features. Future work can focus on addressing the influence of non-frontal faces on the performance of the FER system and optimizing cell sizes for real-time implementation.","The proposed work introduces an FER system, which models the relationship between human facial expression and corresponding induced emotion for static images . This leads us towards Facial Expression Recognition (FER) systems, whose main objective is to detect an expressed emotion and recognize the same . Proposed method incites efficient extraction of shape and appearance features from still images for varying facial expressions . The accuracy of the proposed work is found be 92.56% when implemented using Cohn-kanade dataset for six basic expressions (happy,",0.4686192468619247,0.27004219409282704,0.33472803347280333,0.13979695214161114
250,"This article discusses the use of deep neural networks for facial expression recognition (FER) under challenging in-the-wild conditions. Deep FER systems face challenges related to overfitting and expression-unrelated variations, such as illumination, head pose, and identity bias. The article provides a comprehensive review of deep FER, including datasets and algorithms, and discusses the remaining challenges and future directions for the design of robust deep FER systems. The lack of training data, occlusion-robust and pose-invariant issues, and accurately annotating large volumes of image data are identified as challenges in the construction of expression datasets. The article suggests using crowd-sourcing models and automatic labeling tools under the guidance of expert annotators to address these challenges. Several publicly available facial expression datasets, including EmotioNet, RAF-DB, and AffectNet, are discussed, and the article anticipates the construction of more complementary facial expression datasets in the future.","Deep Facial Expression Recognition: A SurveyDatabases , Face recognition , Three-dimensional displays , Lighting , Training dataWith the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions, deep neural networks have increasingly been leveraged to learn discriminative representations for automatic FER . Recent deep FER systems generally focus on two important issues: overfitting caused by a lack of sufficient training data and expression-unrelated variations, such as illumination, head pose, and identity bias ",0.40358744394618834,0.23529411764705882,0.24215246636771298,0.11909167847109932
251,"The article discusses the influence of social media on consumers' attitudes and behaviors, and how monitoring social media activities can help measure customer loyalty and sentiment towards brands or products. The article describes a sentiment analysis study conducted on over 1000 Facebook posts about newscasts, comparing the sentiment for Rai, the Italian public broadcasting service, with the emerging private company La7. The study maps sentiment analysis on social media with observations and measurable data, highlighting the importance of Facebook as a platform for online marketing. The study was performed using a Knowledge Mining system, which enables research, analysis, and classification of large volumes of heterogeneous documents to help analysts cut through information overload.","Social Media are influencing consumers’ preferences by shaping their attitudes and behaviors . Monitoring the Social Media activities is a good way to measure customers’ loyalty, keeping track of their sentiment towards brands or products . This paper describes a Sentiment Analysis study performed on over 1000 Facebook posts about newscasts, comparing the sentiment for Rai - the Italian public broadcasting service - towards the emerging and more dynamic private company La7 .",0.574585635359116,0.3798882681564246,0.49723756906077343,0.21232199644749447
252,"Sentiment analysis is a technique used to identify and extract subjective information such as opinions expressed in text. It is used to classify attitudes into positive, negative, or neutral categories and has many applications in various domains such as business, politics, and sociology. With the advent of social media and the growth of user-generated data, sentiment analysis has become important in disaster management. Social media can be used to determine how local crowds react during a disaster, assess the extent of devastation, and find people who are in specific need during an emergency situation. However, there are challenges in sentiment analysis such as the lack of emotional correlation information and the need for unsupervised or semi-supervised approaches. In disaster relief, more complex machine learning based approaches with stronger features are required, and leveraging psychological and sociological studies on individual behavior during disasters could be an interesting research direction. Visualization techniques also need to be improved to allow for real-time visual analytics of disaster-related posts to help first responders track changes and make quick decisions.","Sentiment analysis has many applications in different domains including, but not limited to, business intelligence, politics, sociology, etc. In this chapter, we explore applications of sentiment analysis and demonstrate how sentiment mining in social media can be exploited to determine how local crowds react during a disaster . In order to enable quick analysis of real-time geo-distributed data, we will detail applications of visual analytics with an emphasis on sentiment analysis .",0.36,0.16129032258064513,0.27199999999999996,0.06030864050771879
253,"The article discusses using Natural Language Processing and Sentiment Classification with a Recurrent Neural Network to analyze the sentiments and manifestations of Twitter users regarding the COVID-19 pandemic. The article shows that the trained model works accurately and can determine emotional polarity in tweets. The emotional classifications were properly segmented and showed that the overall positive manifestation remained on social media surfaces during the pandemic, with occasional negative and other manifestations. The article also suggests future work in creating an interface that better visualizes and interacts with users and implementing or refactoring potential tensorflow features.","Social media sentiment analysis based on COVID-19natural language processing; recurrent neural network; sentiment analysis; social media; visualizationIn this work, we use a Recurrent Neural Network (RNN) to analyse the emotional nature of various tweets . Where we have classified the various texts into a much more articulated class of emotional strength . This Figure 9. Analysis of sample of 500 tweets by TextBlob and RNN, using ‘covid’ keyword.",0.2822085889570552,0.07453416149068323,0.17177914110429449,0.042352880013987355
254,"This paper provides an overview of NodeXL, a tool for collecting, analyzing, visualizing, and reporting on social media connections. It highlights the potential of NodeXL to provide network insights during emerging news events and develops guidelines for news media teams to measure and map information diffusion on Twitter. The study finds that NodeXL is used across a diverse range of disciplines and can help journalists quickly document the social landscape of a crowd. This is the first empirical study to review literature on NodeXL and provide insight into the value of network visualizations and analytics for the news media domain. The tool requires no technical or programming knowledge and can be utilized across a wide range of disciplines.","NodeXL is an easy to use tool for collecting, analysing, visualizing, and reporting on the patterns found in collections of connections in streams of social media . It then develops a number of guidelines which can be utlised by news media teams to measure and map information diffusion during emerging news events . The abstract provides an interesting starting point in reviewing the literature utilising NodexL for research purposes .",0.4864864864864865,0.2185792349726776,0.2918918918918919,0.14154454610331832
255,"The text discusses sentiment analysis in the context of social media and proposes a method for constructing a vocabulary related to suicide to better analyze tweets related to suicidal ideation. The authors use Weka, a tool for data mining based on machine learning algorithms, to extract useful information from Twitter data and propose an algorithm for computing semantic analysis based on WordNet. The experimental results demonstrate the effectiveness of the method in predicting suicidal ideation with high accuracy and precision. The authors suggest using social media as a preventive force in the fight against suicide and plan to further improve and refine their techniques, including testing multilingual WordNet and working in a big data environment.","We propose to address the lack of terminological resources related to suicide by a method of constructing a vocabulary associated with suicide . We then propose, for a better analysis, to investigate Weka as a tool of data mining based on machine learning algorithms that can extract useful information from Twitter data collected by Twitter4J . This work verify the effectiveness of performance in term of accuracy and precision on semantic sentiment analysis that could thinking of suicide. In our future work, we plan to further improve and refine our techniques in order to enhance the accuracy",0.580952380952381,0.2692307692307692,0.4,0.19349164177843173
256,"This paper evaluates and compares two approaches to automated sentiment analysis, lexicon-based and machine learning, and explores the benefits of combining them for analyzing consumer-generated content on social media. The study finds that both approaches have similar accuracy, but differ in their classification ensembles. The combined approach significantly improves classification performance for positive sentiment. Further research is needed to improve accuracy for negative sentiment classification and to apply the combined approach to other types of CGCs on social media. The findings inform decision-making for marketers analyzing social media conversations and add to industry best practices.","Digital marketers have extensive opportunities to track and analyse consumers’ feelings and opinions about brands, products or services embedded within consumer-generated content . These “Big Data” opportunities render manual approaches to sentiment analysis impractical and raise the need to develop automated tools to analyse consumer sentiment expressed in text format . Results show the two approaches are similar in accuracy, both achieving higher accuracy when classifying positive sentiment than negative sentiment . The combined approach needs to be applied to other kinds of CGCs on social media such as tweets .",0.4408602150537634,0.16304347826086957,0.2795698924731183,0.0997349245490146
257,"The article is about conducting research on machine learning methods for sentiment analysis of Czech social media. The authors created a large dataset of 10,000 posts with human annotation and evaluated various features and classifiers for sentiment analysis. They outperformed the baseline and reported results on other domains. The article aims to extend sentiment analysis research to another family of languages and encourage competition for high-end commercial solutions. The outcomes of this article will help to set the common ground for sentiment analysis for the Czech language and extend research outside the mainstream languages in this field.","Sentiment Analysis in Czech Social Media Using Supervised Machine Learningsentiment analysis, czech social mediaThis article provides an in-depth research of machine learning methods for sentiment analysis of Czech social media . We explore different pre-processing techniques and employ various features and classifiers . In addition, we also report results on other widely popular domains, such as movie and product reviews . To the best of our knowledge, this article is the only of its kind that deals with sentiment analysis in such a thorough manner",0.44808743169398907,0.2099447513812155,0.33879781420765026,0.17021686388189577
258,"The text discusses a review of 24 studies on multilingual sentiment analysis of social media in 23 different languages from 2017 to 2020. The review shows a trend towards cross-lingual and code-switching approaches, and a lack of complex architectures such as transformers-based for more difficult tasks. Aspect-based sentiment analysis is still an understudied domain with potential for future works. The simpler backbone architecture is insufficient for more complex scenarios, and there are still unsolved questions regarding which type of embedding works best. The text concludes that more research is needed to better address the diversity of languages, cultures, and expressions of feelings.","Twenty-four studies on twenty-three distinct languages and eleven social media illustrate the steady interest in deep learning approaches for multilingual sentiment analysis of social media . We improve over previous reviews with wider coverage from 2017 to 2020 as well as a study focused on the underlying ideas and commonalities behind the different solutions . The observed trend evidences the constant interest in this domain, so we expect to see this direction continue . As regards the different MSA setups, the multilingual approach seems to be decreasing in interest .",0.32989690721649484,0.09375,0.18556701030927836,0.07533804735415023
259,"The text discusses the increasing use of social media for sharing and gathering information, and the process of data mining to analyze and categorize this data. Text mining is used to derive information from text, which can be applied to various techniques including information retrieval, extraction, pattern recognition, and data mining. The paper highlights the importance of mining cybercriminal networks in social media to reveal implicit and explicit relationships among cybercriminals based on their conversations. The use of genetic algorithms in text mining is recommended for better time efficiency and more efficient concept extraction. This can help in predicting and preventing cyber attacks, which is crucial given the weaknesses of existing cyber security methods.","Text mining is the process of analyzing data from different context . Text analysis can be used in information retrieval, information extraction, pattern recognition, frequency distribution and data mining techniques . Existing security methods are weak in cybercrime forensics and predictions . Genetic algorithm takes the advantage of giving greater weight to individuals with best fitness score . This process continues until a best solution is obtained from a set of candidate solutions .",0.4262295081967213,0.13259668508287292,0.273224043715847,0.0703559393181494
260,"The text discusses computational intelligence (CI) and its focus on using brain- or nature-inspired models to solve complex real-world problems. Emulating human intelligence, including human language and emotions, is a big challenge for CI. The paper proposes an approach that combines CI and linguistics to understand sentiment associated with text. The approach uses various linguistic patterns based on the syntactic structure of sentences to determine the polarity label of the sentence. The proposed approach outperforms existing approaches on benchmark datasets. Future work includes discovering more linguistic patterns, sarcasm detection, and developing other modules to solve the multi-faceted dynamic sentiment analysis challenge.","Sentiment Data Flow Analysis by Means of Dynamic Linguistic Patternscomputational intelligence (CI) is an established research field that focuses on using brain- or natureinspired models to solve complex real-world problems . One of the biggest challenges of CI is the emulation of human intelligence, which includes not only human-like reasoning but also human interaction, e.g., human language and human emotions . Understanding human emotions and deciphering the way humans reason about them or express them in their language",0.4043715846994536,0.1546961325966851,0.26229508196721313,0.12442927345652309
261,"This article discusses the issue of motor vehicle traffic crashes (MVTCs) as the leading cause of work-related fatal injuries in the United States. The Bureau of Labor Statistics (BLS) and the National Highway Traffic Safety Administration (NHTSA) are two sources that provide data on fatal work-related MVTCs. However, the data sources lack either data on potential risk factors or work-relatedness confirmation and employment characteristics. Therefore, BLS and NIOSH collaborated to analyze a merged data file created by BLS using CFOI and FARS data. The matching algorithm was created to link 2010 data from CFOI and FARS using date of incident and other case characteristics, allowing for flexibility in variables to address coding discrepancies. The study has demonstrated the feasibility and value of matching data on fatal work-related MVTCs from CFOI and FARS, verifying that there are systematic differences between cases captured in both systems and those captured by CFOI alone. The findings emphasize the diversity of the members of the workforce involved in fatal work-related traffic crashes and suggest that crash prevention efforts should encompass a wide range of industries and occupations. The matching process reported in this study is the first step in a collaboration between BLS, NHTSA, and NIOSH to improve the completeness and quality of data on fatal work-related MVTCs. Matching of additional years of data is planned, and subsequent analyses will use the merged dataset to provide richer insights about risk factors for fatal work-related traffic crashes.","In the United States, the Bureau of Labor Statistics (BLS) Census of Fatal Occupational Injuries (CFOI) provides accurate counts of fatal work injuries based on confirmation of work relationship from multiple sources . The National Highway Traffic Safety Administration (NHTSA) Fatality Analysis Reporting System (FARS) provides detailed data on fatal work-related MVTCs . This study is the first step in a collaboration between BLS, NHTSA, and NIOSH to improve the completeness and quality of data",0.40372670807453415,0.26875,0.2919254658385093,0.07054126890675742
262,"The concept of matched filter is commonly used in retina vessel segmentation, but single scale filters have limited performance. Multiscale matched filters are more effective due to their improved noise suppression features, but determining the right parameter values can be a challenge. To address this issue, the proposed approach uses particle swarm optimization to find the optimal filter parameters for achieving better accuracy in retina vessel segmentation. The approach was tested on two retina databases and showed better results compared to other available algorithms. The multiscale matched filter achieved a sensitivity of 71.32-71.72%, specificity of 96.87-98.66%, and accuracy of 95-96.33%. This approach demonstrated that the multiscale matched filter is more effective than the single scale matched filter for vessel segmentation. Future work proposes introducing vessel morphology to improve segmentation results and achieve better performance.","Multiscale matched filter is widely used in the area of retina vessel segmentation . The proposed approach makes use of the improved noise suppression features of multiscale filters . A major performance issue here is the determination of the right parameter values of the filter. The approach is tested on DRIVE and STARE databases to demonstrate the performance advantages over existing approaches . a sensitivity of 71.32%, specificity of 98.66% and accuracy of 96.33% are obtained on STARE database . Future work proposes to introduce vessel ",0.5814977973568282,0.2755555555555556,0.39647577092511016,0.128067523602431
263,"The study aimed to describe the clinical characteristics and dynamic changes of chest CT features in the first three weeks of COVID-19 pneumonia patients in Jiangsu Province. The study enrolled 307 patients classified as common type and analyzed their symptoms and chest CT features. The most common manifestation was ground-glass opacities (GGO), followed by consolidation and fibrosis, mainly distributed in the lower lobe or subpleural region. Male patients had a slower recovery than females in the second week, with higher consolidation and fibrosis scores. Although chest CT scores had correlations with arterial blood gas indices, long-term follow-up of pulmonary function test is needed to determine lung recovery. Chest CT plays an important role in the diagnosis of COVID-19 pneumonia, but changes in chest CT are difficult to assess quantitatively in the first three weeks.",Chest CT played an important role in the diagnosis of COVID-19 pneumonia . Results: Fever (69.1%) and cough (62.8%) were common symptoms . Lower lobe or subpleural region was the most common distribution form of lesion . Men had higher consolidation score and fibrosis score than female in the third week . Total CT score and GGO score had weak to moderate correlation with arterial blood gas indices .,0.4854368932038835,0.30392156862745096,0.29126213592233013,0.10448413335688124
264,"The paper proposes a method for automatically recovering 3D rib motion from 2D x-ray videos, while keeping the radiation dose low. The method involves 2D-3D registration of x-ray video and single-time-phase computed tomography, with the introduction of a uniaxial rib-motion model and local contrast normalization to improve the accuracy and robustness of the registration process. Simulation and real-image experiments were conducted to evaluate the proposed method, with statistically significant improvements observed when optimizing the rotation axis and using LCN. The paper concludes that the proposed method is a robust and accurate way to recover 3D rib motion from dynamic radiography.","Dynamic chest radiography (2D x-ray video) is a low-dose and cost-effective functional imaging method with high temporal resolution . The analysis of rib-cage motion has been shown to be effective for evaluating respiratory function but it has been limited to 2D . To achieve this, we developed a method for automatically recovering 3D rib motion based on 2D-3D registration .",0.3905325443786982,0.16766467065868262,0.21301775147928997,0.08245857527756087
265,"The paper proposes a retinal vessel segmentation method based on the dense conditional random field (CRF) model. The proposed method learns discriminative unary features from a convolutional neural network (CNN) model and applies a combo of filters to enhance thin vessels for pairwise potentials. The retinal vessel segmentation is achieved by efficient inference in the trained dense CRF model. The proposed method outperforms other state-of-the-art methods in terms of F1-score, Matthews correlation coefficient, and G-mean on four public datasets. The method can be further integrated into computer-aided diagnostic (CAD) systems to facilitate retinal diagnosis.","a dense conditional random field (CRF) model has been successfully used in retinal vessel segmentation . Its corresponding energy function is formulated as a linear combination of several unary features and a pairwise term . This method is based on the dense CRF model . Discriminative features are learned from a CNN model, which is properly trained using the superpixel-level balanced sample selection . The segmentation performance is evaluated on four public datasets .",0.47058823529411764,0.21428571428571427,0.2941176470588235,0.1695441451631387
266,"This paper proposes a new method for classifying lung nodules using x-ray screening. The method involves localizing and extracting the nodules using a variance image, followed by using a probabilistic neural network as a classifier to discriminate the true nodules. The performance of the approach is 92% correct classification with 95% sensitivity and 89.7% specificity. The proposed method is simpler and capable of detecting low-contrast nodules compared to other methods in the literature. Additionally, a new algorithm for training PNN neural networks is presented, allowing for fewer neurons and lower computational burden while maintaining performance.","In medical examinations doctors use various techniques in order to provide accurate analysis of their actual state of health . One of the commonly used methodologies is the x-ray screening . This examination very often help to diagnose some diseases of chest organs . The most frequent cause of wrong diagnosis lie in the radiologist’s difficulty in interpreting the presence of lungs carcinoma in chest X-ray . In such circumstances, an automated approach could be highly advantageous as it provides important help in medical diagnosis .",0.21978021978021978,0.044444444444444446,0.12087912087912088,0.017195723366957977
267,"The objective of this study is to develop and validate an analytical model incorporating actual cranial thickness and curvature for child aged 0–1YO and investigate their effects on child head dynamic responses at different head locations. The proposed model is compared with cadaver test data of children aged 0–1 years old and it is shown to be accurate in predicting head injury metrics. The results show that the injury metrics increased obviously with the increasing of cranial thickness and elastic modulus, and the injury metrics at forehead location are significantly higher than those at other locations due to large thickness it owns. The proposed model shows good biofidelity and can be used in quickly predicting the dynamics response at any location of head for child younger than 1 YO.","Results: The proposed analytical model is compared with cadaver test data of children aged 0–1 years old and it is shown to be accurate in predicting head injury metrics . The injury metrics at forehead location are significant higher than those at other locations due to large thickness it owns . In addition, the injury metrics of 11 MO child are apparently higher than that of the 5 MO child . This study is based on a theoretical dynamic model which can be used in quickly predicting the dynamics response at any location of head for child",0.7168141592920354,0.5714285714285714,0.5752212389380531,0.4546161984406329
268,"This study proposes an effective deep learning method using a fully convolutional DenseNet (FC-DenseNet) for automatically delineating posterior ribs, anterior ribs, and clavicles in chest radiographs (CXRs) to reduce their effects for chest radiography analysis. The proposed method significantly outperforms two other fully convolutional networks for edge detection and a state-of-the-art method without deep learning models in terms of quantitative evaluation metrics and visual perception. The proposed method is also validated for its usefulness in bone suppression of CXRs and shows generalizability across multiple databases.","In chest radiographs (CXRs), all bones and soft tissues are overlapping with each other . Delineating ribs and clavicles automatically is difficult by methods without deep learning models . We consider a pixel-weighted loss function to mitigate uncertainty issue during manually delineating for robust prediction . The proposed method significantly outperforms these methods in terms of quantitative evaluation metrics and visual perception .",0.4832214765100671,0.2857142857142857,0.28187919463087246,0.221211473292489
269,"This study reviews and compares retinal vessel segmentation methods using publicly available databases of color fundus photographs containing ground truth for vessel segmentation. Two supervised and three unsupervised methods are studied and quantitatively compared using five publicly available databases. Two types of image preprocessing approaches were tested, and the method parameters were optimized for the best performance on each database. The results show that the parameter optimization does not significantly improve the segmentation performance of the methods when the original data is used, but the performance of the methods in new image data differs significantly. The performance of the tested methods with respect to accuracy was very close, with the highest performance achieved on ARIADB by the Azzopardi method, on CHASE and DRIVE by the Soares method, and on HRF and STARE by the Nguyen method. The Soares and Azzopardi methods usually provide higher area under the ROC curve than the other methods. Preprocessing of the images with CLAHE improved the overall performance of the unsupervised methods, and parameters yielding the reported performance are provided to support optimization on new data. Finally, it was possible to predict parameters that give the best segmentation performance for each method.","In this study, two supervised and three unsupervised segmentation methods with a publicly available implementation are reviewed and quantitatively compared with each other on five public databases with ground truth segmentation of the vessels . Each method is tested under consistent conditions with two types of preprocessing, and the parameters of the methods are optimized for each database . The methods show similar performance for segmentation accuracy, with the best performance achieved by the method by Azzopardi et al. (Acc 94.0), on CHASEDB1 and ",0.4857142857142857,0.23741007194244604,0.2785714285714286,0.050375408281290314
270,"This study evaluates the performance of newly constructed descriptive statistical features in retinal vessel segmentation for the early detection of diabetic retinopathy, glaucoma, and age-related macular degeneration. The features are formed by statistical moments, mean and median measurements of image pixels’ intensity values in four directions. A fuzzy logic classifier, an artificial neural network classifier (ANN), a support vector machine (SVM), and classifier fusion are designed and evaluated on publicly available databases. The results show that all classifiers achieved compatible classification accuracies with sensitivity and specificity values, and the classifier fusion achieved the best performance among all four classifiers. The proposed statistical features are straightforward to calculate and hold valuable information to segment pixels that belong to retinal blood vessels.","In this work, the performance of descriptive statistical features in retinal vessel segmentation is evaluated by using fuzzy logic, an artificial neural network classifier (ANN), a support vector machine (SVM), and classifier fusion . Newly constructed eight features are formed by statistical moments . Features, F1, F2, F3, and F4 are calculated as the mean values . For the STARE database, the fuzzy classifier achieved the best performance among all by using the proposed statistical features . The overall accuracy, sensitivity, and specificity",0.63,0.41414141414141414,0.45,0.3043424246061345
271,"This systematic review analyzes sentiment analysis in relation to infectious diseases, outbreaks, epidemics, and pandemics over a 10-year period from 2010 to 2020. The motivation for this study was the massive spread of COVID-19, and the review categorized the articles into four main categories: lexicon-based models, machine learning-based models, hybrid-based models, and individuals. The study emphasized the importance of social media and sentiment analysis in understanding people's sentiments regarding current events and the need for further research in this area. The authors also highlighted the potential for integrating other technologies, such as AI and ML, to make a difference in future outbreaks.","The COVID-19 pandemic caused by the novel coronavirus SARS-CoV-2 occurred unexpectedly in China in December 2019 . Tens of millions of confirmed cases and more than hundreds of thousands of confirmed deaths are reported worldwide according to the World Health Organization . For computer scientists and researchers, big data are valuable assets for understanding people’s sentiments regarding current events . To the best of our knowledge, previous related studies have focused on one kind of infectious disease .",0.3118279569892473,0.08695652173913045,0.16129032258064516,0.03146198564993347
272,"This study reports a case of a patient who was simultaneously infected with SARS-Cov-2 and HIV, which resulted in a longer disease course and slower generation of specific antibodies. The case highlights the severe impairment of the immune system in patients with a co-infection of SARS-Cov-2 and HIV. The paper concludes that the immune response may be destroyed by the two viruses together and emphasizes the importance of monitoring patients with HIV for COVID-19.","The ongoing outbreak of COVID-19 began in Wuhan, China, become an emergency of international concern . This study reports a case simultaneously infected by SARS-Cov-2 and HIV, which showed a long disease course of > 2 months . It was not until later that the IgM in serum could be detected, which may have been due to the immune response being destroyed by the two viruses together .",0.5306122448979592,0.28965517241379307,0.3945578231292517,0.1990129138709165
273,"This meta-analysis aimed to investigate the relationship between lymphocyte count and the severity of COVID-19. Thirteen case-series with a total of 2282 cases were included in the study, and the results showed that lymphocyte count was significantly lower in severe COVID-19 patients, and the presence of lymphopenia was associated with a nearly threefold increased risk of severe COVID-19. The study concluded that lymphopenia is a prominent part of severe COVID-19, and a lymphocyte count of less than 1.5 x 10^9/L may be useful in predicting the severity of clinical outcomes. However, further studies are needed to confirm the predictive ability of lymphopenia in COVID-19.","Lymphopenia is a prominent part of severe COVID-19 and a lymphocyte count of less than 1.5 x 109 /L may be useful in predicting the severity of clinical outcomes . Results: Overall 13 case-series with a total of 2282 cases were included in the study . This meta-analysis aimed to explore the relationship between lymphocyte counts and the severity . Fig. 3. Adaptive histogram equalization (AHE), (b) Background image, (c",0.6162162162162163,0.5573770491803278,0.3567567567567567,0.3471298608457055
274,"The article discusses the challenges that Syria faces in responding to the COVID-19 pandemic due to the country's protracted conflict, which has led to the fragmentation of its health systems and inadequate resources for water, sanitation, and healthcare. The article highlights the need for locally implementable interventions to rapidly build WASH and health system capacity to ensure early detection and management of COVID-19 cases. The article also suggests practicable measures such as ceasefires, protection of health workers and facilities, and expansion of humanitarian access to support the response to COVID-19 in Syria.","Political influences on outbreak preparedness, response and reporting may also adversely affect control of SARS-CoV-2 in Syria . Political changes have led to the formation of at least three health systems within Syria’s borders, each with its own governance, capacity and planning . As such, COVID-19 could overwhelm the health systems (particularly intensive care capacity), leading to high deaths across the population, particularly for the most vulnerable such as detainees .",0.3333333333333333,0.08433734939759036,0.1904761904761905,0.024652809290978746
275,"This study evaluates the ability to measure local cortical bone thickness and obtain mechanically relevant properties of rib cross-sections from clinical-resolution CT scans of human ribs using a Cortical Bone Mapping (CBM) algorithm. The study compares three modalities: standard clinical CT (clinCT), high-resolution clinical CT (HRclinCT), and microCT (μCT). Results show that CBM substantially reduces measurement errors in cross-sectional rib properties compared to previous work, with accuracy and precision of rib cortical bone thickness measurements marginally higher than other regions of the body. This methodology enables researchers to obtain multiple geometric properties from clinical CT images without the need for more restrictive sources such as microCT, which can aid in understanding and mitigating traumatic injuries.","Results show substantial reduction in measurement error of cross-sectional rib properties when using clinical-resolution computed tomography (CT) scans of human ribs . This study assesses the ability to measure local cortical bone thickness, and to obtain mechanically relevant properties of rib cross-sectors from clinical CT (clinCT), . The study used thirty-four sections of . rib . the study utilized a standard clinical CT .",0.5714285714285714,0.3666666666666667,0.31868131868131866,0.15420333747220824
276,"This systematic review aimed to overview and discuss studies on smartphone-based systems for detecting phase changes in bipolar disorder. The review found that objective data collected via smartphones, such as voice data and smartphone usage data, are valid markers of mood state and can predict mood status with accuracies ranging from 67% to 97%. The use of mobile apps for real-time monitoring of illness activity has the potential to improve the management of bipolar disorder and provide options for early intervention between outpatient visits. The authors suggest that such monitoring could improve diagnosis and provide timely and contextual care delivery for patients with bipolar disorder.",Smartphones can be a useful tool for detecting prodromal symptoms of episode recurrence (through real-time monitoring) and providing options for early intervention between outpatient visits . Objective data automatically collected using smartphones (voice data from phone calls and smartphone usage data reflecting social and physical activities) are valid markers of a mood state . The articles surveyed reported accuracies in the range of 67% to 97% in predicting mood status .,0.5568181818181819,0.27586206896551724,0.2727272727272727,0.1581894967561734
277,"The paper proposes a new method for retinal blood vessel segmentation based on supervised learning. The method combines a set of robust features into a 17-D hybrid feature vector for pixel characterization and uses a random forest classifier for information fusion. The proposed method achieves average classification accuracies of 0.9513 and 0.9605 on the DRIVE and STARE datasets, respectively, outperforming state-of-the-art methods in both cross-training and pathological cases. The varied types of features selected for the method act complementary, boosting the accuracy and reliability of vessel segmentation. The method's training data independency allows for its application on assorted datasets without retraining, making it advantageous for wide screening programs. The proposed method's performance on pathological images is better than other methods, verifying its robustness against abnormal images.","This 17-D feature vector consists of 13 Gabor filter responses computed at different configurations, contrast enhanced intensity, morphological top-hat transformed intensity, vessel-ness measure, and BCOSFIRE filter response . The chosen combination of the different types of individually strong features results in increased local information with better discrimination for vessel and non-vessel pixels in both healthy and pathological retinal images . Our method is evaluated in detail on two publicly available databases DRIVE and STARE .",0.3033175355450237,0.07655502392344499,0.17061611374407584,0.013889579397020164
278,"This study aims to investigate the validity of an energy-based skull fracture criterion using subject-specific finite element head models. 18 different experimental impacts were reconstructed, and each impact was simulated using a homogeneous material model and a subject-specific model based on local bone densities. The study found that subject-specific models predicted the moment of fracture more accurately than the homogeneous material model and had the ability to predict fracture lines with unprecedented precision. However, the modelling of post-fracture behaviour is currently unsatisfactory and needs improvement. The study identified influencing factors on skull strain energy, such as contact area, scalp thickness, and impactor positioning, and concluded that subject-specific modelling leads to a more accurate prediction of the force-displacement curve, but small variations in the computational model significantly influence the results. The study also highlighted the inability of the energy-based fracture criterion to account for differences in geometry and bone properties.","In literature, a strain energy criterion has been proposed to predict skull fractures . The subject-specific models were able to predict fractures who matched visually with the corresponding experimental fracture patterns . These models have the ability to predict the moment of fracture with a higher accuracy than the homogeneous material model . However, the modelling of the post-fracture behaviour is currently not satisfactory and should be improved upon .",0.42666666666666664,0.21524663677130043,0.2666666666666667,0.07360136574337911
279,"This systematic review compared different imaging techniques for the diagnosis of multiple myeloma bone disease, including magnetic resonance imaging (MRI), 18F-fluorodeoxyglucose positron emission tomography (FDG-PET), FDG-PET with computerized tomography (PET-CT), and whole body X-Ray (WBXR) or (whole body) CT. The review found that all newer imaging techniques had a higher detection rate of MM-related bone disease compared to WBXR, except for lesions in the skull and ribs. CT and MRI were found to perform equally with respect to detection rate and sensitivity. The authors recommend additional X-rays of the ribs and skull in cases where no bone lesions are detected with newer imaging techniques to avoid underdiagnosis of MM-related bone disease. The authors suggest incorporating MRI as an equal alternative to CT for diagnosis, as MRI has repeatedly reported prognostic value. FDG-PET-CT is a promising alternative for follow-up as it depicts active lesions and normalization of FDG-uptake during treatment has been found to predict outcome. Further studies will determine which technique, or combination of techniques, should be the new gold standard.","a systematic review of studies compared magnetic resonance imaging (MRI), 18F-fluorodeoxyglucose positron emission tomography (FDG-PET), FDGPET with computerized tomographie (PET-CT) and CT with whole body X-Ray (WBXR) . The mean QUADAS score was 7.1 (3–11), with quality hampered mainly by a poor description of selection and execution criteria . In a direct comparison CT and",0.3140495867768595,0.17500000000000002,0.2644628099173554,0.055979049967616316
280,"This study aimed to examine the association between baseline bone mineral density (BMD), rate of bone loss, weight loss, and weight fluctuation, and all-cause mortality risk in elderly men and women. The study analyzed data from 1059 women and 644 men, aged 60 years or older, of white background who participated in the Dubbo Osteoporosis Epidemiology Study. The results showed that lower baseline BMD was an independent predictor of mortality in women, but not in men. High rates of BMD loss, weight loss, and weight fluctuation were significant predictors of all-cause mortality in both elderly men and women, independent of age, incident fracture, and concomitant diseases. The study emphasized the public health burden of osteoporosis and suggested that reducing bone loss, weight loss, and maintaining stable weight may have beneficial effects on the survival of elderly individuals.","BMD at the femoral neck was measured by DXA (GE-LUNAR) at baseline and at approximately every 2 yr afterward . Data on incident osteoporotic fractures and concomitant diseases, including cardiovascular diseases, all types of cancer, and type I/II diabetes mellitus, was also recorded . In both sexes, baseline weight was not an independent risk factor of mortality in men .",0.27272727272727276,0.08163265306122448,0.15151515151515152,0.01224101077969412
281,"This study aimed to determine the prevalence of low bone mineral density (BMD), fractures, and bone pain in patients with thalassemia across childhood, adolescence, and adulthood, as well as the etiology of bone disease in thalassemia. The study found that low BMD and fractures are common in thalassemia patients across all thalassemia syndromes, with suboptimal peak bone mass. Hypogonadism, increased bone turnover, and older age are independent predictors of low bone mass, and fractures are negatively associated with BMD. The study highlights the need for strategies to improve BMD in thalassemia management, including further research on appropriate forms of gonadal steroid replacement and vitamin D supplementation, and additional strategies to optimize bone accrual. Further longitudinal studies are also needed to address changes in bone mass during puberty and the factors that lead to increased bone resorption in thalassemia.","The purpose of this study was to determine the prevalence of low BMD, fractures, and bone pain in all thalassemia syndromes in childhood, adolescence, and adulthood . Three hundred sixty-one subjects, 49% male, with a mean age of 23.2 yr (range, 6.1–75 Yr), were studied . Peak bone mass was suboptimal. Nine percent of patients had uniformly decreased height of several vertebrae by MXA, which was associated with",0.34615384615384615,0.1941747572815534,0.25961538461538464,0.10318299787476208
282,"This systematic review and meta-analysis found that low bone mineral density (BMD) and fractures are associated with a small but significant increased risk of cardiovascular disease (CVD) and possibly death. The analysis included 28 studies that followed over 1 million participants for a median of 5 years. People with low BMD were at increased risk of developing overall CVD, coronary artery disease, cerebrovascular conditions, and CVD-associated death. The presence of fractures at baseline was associated with an increased risk of cerebrovascular conditions and death due to CVD. The authors suggest that addressing low BMD and fractures could positively influence cardiovascular outcomes and that future studies should evaluate potential preventative interventions. However, the authors note that there were some potential sources of bias in the literature.","Low Bone Mineral Density (BMD) and fractures are associated with cardiovascular disease (CVD) Twenty-eight studies followed a total of 1,107,885 participants for a median of 5 years . The association between low BMD, fractures, and CVD across longitudinal studies was explored by calculating pooled adjusted hazard ratios (HRs) 95% confidence intervals (CIs) with a random-effects meta-analysis .",0.39572192513368987,0.227027027027027,0.32085561497326204,0.12707475206367969
283,"This review article discusses the emerging role of melatonin in bone physiology and its potential as a therapeutic option for preventing or treating bone loss, particularly in conditions such as osteopenia and osteoporosis. The article highlights the multiple mechanisms by which melatonin can maintain bone health, including its ability to induce osteoblastogenesis while inhibiting osteoclastogenesis and its free-radical scavenging and antioxidant properties. The article also notes that disruption of melatonin rhythms, through exposure to light at night or shift work, can adversely impact bone health. The authors call for additional multicentered, randomized control trials to assess the efficacy of melatonin in preventing and treating bone loss.","Clinical use for melatonin in bone-grafting procedures, in reversing bone loss due to osteoporosis, and periodontal disease is discussed . The focus of this review describes the role of the drug in bone physiology and discusses how disruption of melatolin rhythms by light exposure at night, shift work, and disease can adversely impact on bone . This review shows that even with existing osteoporotic therapies, bone-related disease, and mortality are on the rise,",0.4666666666666667,0.14606741573033707,0.2555555555555556,0.05891719114892798
284,"This study aimed to compare the performance and usage of different types of supervised machine learning algorithms for disease risk prediction. The researchers conducted extensive research and selected 48 articles from Scopus and PubMed databases that applied more than one supervised machine learning algorithm on single disease prediction. The results showed that Support Vector Machine (SVM) was the most frequently applied algorithm, followed by Naïve Bayes, while Random Forest (RF) algorithm showed superior accuracy comparatively. RF had the highest accuracy in 53% of the studies where it was applied, followed by SVM which topped in 41% of the studies. The study provides important information on the relative performance of different supervised machine learning algorithms for disease prediction, which can aid researchers in selecting an appropriate algorithm for their studies.","This study aims to identify the key trends among different types of supervised machine learning algorithms, and their performance and usage for disease risk prediction . We found that the Support Vector Machine (SVM) algorithm is applied most frequently (in 29 studies) followed by the Nave Bayes algorithm (in 23 studies) however, the Random Forest (RF) algorithm showed superior accuracy comparatively . Of the 17 studies where it was applied, RF showed the highest accuracy in 9 of them, i.e., 53% . This",0.6066350710900473,0.3253588516746411,0.4170616113744076,0.2350821704308406
285,"This systematic review aimed to identify the disease definition and diagnostic pathway for deep gluteal syndrome (DGS), a condition that clinicians may struggle to diagnose due to its ambiguous definition and diagnostic pathway. Four electronic databases were searched, yielding 14 studies that met the eligibility criteria, involving 853 patients with clinically diagnosed DGS. The review identified the DGS disease definition as a non-discogenic sciatic nerve disorder with entrapment in the deep gluteal space, and proposed a general diagnostic pathway using history taking, physical examination, and imaging tests. The history taking should include posterior hip pain, radicular pain, and difficulty sitting for more than 30 minutes, while the physical examination should involve tenderness in the deep gluteal space, pertinent positive results with the seated piriformis test, and positive Pace sign. The imaging tests should include pelvic radiographs, pelvic MRI, and spine MRI. This review provides useful information for clinicians to diagnose DGS with more confidence.","In the diagnosis of DGS, it was discovered that the DGS disease definition was composed of three parts: (1) non-discogenic, (2) sciatic nerve disorder, and (3) nerve entrapment in the deep gluteal space . In this review it was found that the general diagnostic pathway for DGS consisted of history taking (posterior hip pain, radicular pain, and difficulty sitting for more than 30 min), physical examination (e.g. tenderness in deep glycemic space, and pertinent positive results with",0.45493562231759654,0.29437229437229434,0.3862660944206009,0.14508217553423525
286,"This review paper focuses on the role of machine learning (ML) and deep learning (DL) algorithms in the early diagnosis and tracking of degenerative nerve diseases such as Alzheimer's and Parkinson's disease. The paper covers various ML and DL algorithms and their recent advancements, such as artificial neural networks, deep CNNs, and deep belief networks, that have shown promising results in diagnosing these diseases. However, the paper also discusses the limitations of these methods, such as a lack of available data and lower scalability and accuracy. The conclusion highlights the importance of early diagnosis and progression tracking of these diseases and suggests alternative technologies such as IoT, digital twin, quantum computing, and Big data analytics that can potentially be helpful in the diagnosis of degenerative nerve diseases in the future.","Approximately 1/6th of the world’s population suffers from these disorders . The best way to treat these diseases is to detect them at an earlier stage . Many of these diseases are genetic; this enables machine learning algorithms to give inferences based on the patient’s medical records and history . We also included the recent advancements in each of these models, which improved their capabilities for classifying degenerative nerve diseases .",0.2772277227722772,0.09,0.1683168316831683,0.014943530936466156
287,This study investigated the fecal microbiomes of Parkinson's disease (PD) patients and control subjects and found that the abundance of Prevotellaceae was reduced in PD patients by 77.6% on average. The study also found a positive association between the abundance of Enterobacteriaceae and the severity of postural instability and gait difficulty in PD patients. The findings suggest that the intestinal microbiome is altered in PD and is related to motor phenotype. Further studies are warranted to explore the potential of fecal microbiome analysis as a biomarker for PD and elucidate the temporal and causal relationships between gut microbiota and PD.,"In the course of Parkinson’s disease (PD), the enteric nervous system (ENS) and parasympathetic nerves are amongst the structures earliest and most frequently affected by alpha-synuclein pathology . Accordingly, gastrointestinal dysfunction, in particular constipation, is an important non-motor symptom in PD . Recent research has shown that intestinal microbiota interact with the autonomic and central nervous system via diverse pathways including the ENS and vagal nerve . The",0.30588235294117644,0.05952380952380952,0.21176470588235294,0.03994662782154449
288,"This article discusses the use of high-resolution ultrasound (HRUS) to diagnose posterior interosseous nerve (PIN) syndrome, a rare compression neuropathy. The study evaluated ultrasound images and clinical data of 13 patients with PIN syndrome and 20 healthy volunteers. The results showed that HRUS allows for differentiation between patients with PIN syndrome and healthy volunteers. HRUS can confirm the syndrome in doubtful cases by demonstrating the typical findings of nerve compression. However, HRUS is also indispensable for the diagnosis of a ""primary"" PIN syndrome by providing a quick, inexpensive, and reliable method to exclude other sources of PIN compression apart from the arcade of Frohse.","Ultrasound images and clinical data of 13 patients with PIN syndrome confirmed by neurological examination and electrophysiological testing were evaluated retrospectively . Enlargement of the PIN was seen in all patients, but not in volunteers (statistically significant difference in mean diameter P  0.05). Furthermore, edema and caliber change of PIN were present in all patient . HRUS is an essential tool in the work-up of a patient with a “primary” PIN Syndrome .",0.38418079096045193,0.19428571428571428,0.2824858757062147,0.1135031048174048
289,"The article discusses the growing interest in facial expression recognition (FER) as a crucial aspect of human-machine interface technology, and presents an overview of FER research and characteristics over the past five years. The article proposes a new classification method of feature extraction, which emphasizes the automatic and multi-scale methods currently in use, as well as novel methods utilizing three-dimensional models. The article also emphasizes the need for improved expression classification methods and outlines possible challenges and future directions for FER development, including the integration of other communication channels and the analysis of static images and image sequences. The article concludes that FER has significant market potential in various applications, and further research is needed to advance the technology.



","In this survey we present the facial expression recognition research and characteristics which focus on the development in the past five years . A new classification method of feature extraction is proposed in this paper, through which we can realize the development trend . With the rapid development of the technology of three-dimensional model, some novel methods are used to feature extraction . At the same time, improved expression classification methods (ANN, SVM, HMM) are emphasized . More work has to be done in the field of automatic facial expression interpretation .",0.4761904761904762,0.1923076923076923,0.2952380952380953,0.12908674006022114
290,"Facial Expression Recognition (FER) is a highly active area of research in computer vision, pattern recognition, and artificial intelligence. FER has gained extensive attention due to its potential applications in natural human-computer interaction, human emotion analysis, and image indexing and retrieval. This survey paper provides an overview of FER, emphasizing two crucial aspects of designing an FER system, namely facial feature extraction and facial expression classification. The survey discusses various techniques used for feature extraction and expression classification, and their strengths and limitations. Additionally, future work in FER includes integrating with other communication channels and analyzing static images and image sequences to enhance the accuracy and usability of FER systems. Overall, this survey offers valuable insights into the current state of FER and presents suggestions for future research in this field.","Facial Expression Recognition (FER) is currently a very active research topic in the fields of computer vision, pattern recognition, artificial intelligence . The first is facial feature extraction for static images and dynamic image sequences, the second is facial expression classification . Conclusions and future work are finally discussed in this survey . This survey paper has presented an overview of FER, focusing on the crucial aspects of feature extraction and expression classification, and their strengths and limitations .",0.5990338164251208,0.33170731707317075,0.3671497584541063,0.21263683679281445
291,"The paper proposes an approach to improve the accuracy of facial expression recognition (FER) in static images by considering facial element and muscle movements using salient distance features. The approach uses patch-based 3D Gabor features to extract features, select ""salient"" patches, and perform patch matching operations. The proposed approach shows high correct recognition rate (CRR), significant performance improvements, promising results under face registration errors, and fast processing time. The approach can potentially be applied in various real-world applications such as patient state detection and driver fatigue monitoring. The future work involves extending the approach to video-based FER systems by combining patch-based Gabor features with motion information.","Facial Expression Recognition Using Facial Movement FeaturesFeature extraction , Face recognition , Training , Human factors , Shape analysisFacial expression is an important channel for human communication . Current approaches on FER in static images have not fully considered and utilized the features of facial element and muscle movements . The proposed approach achieves the highest CRR on the JAFFE database and is among the top performers on the Cohn-Kanade database .",0.37499999999999994,0.13793103448275862,0.23863636363636367,0.0691349855171176
292,"In summary, automatic facial expression recognition has many applications, and there are two popular methods based on geometry and appearance. While there has been much research using static images, the development of new methods that are computationally efficient and have less memory usage is ongoing. This paper provides a survey of facial expression recognition and a comparative study of feature extraction techniques using the JAFFE dataset. The goal is to increase the accuracy rate, develop applications based on dynamic images, and handle occlusion.","Facial Expression Recognition has many applications including human behavior understanding, detection of mental disorders, and synthetic human expressions . The research is still going on for the development of new methods which would be quiet easy in computation and would have less memory usage as compared to previous methods . A comparative study is also carried out using various feature extraction techniques on JAFFE dataset.Facial Expression recognition has increasing application areas and requires more accurate and reliable FER system .",0.5590062111801242,0.2389937106918239,0.37267080745341613,0.16949651903472568
293,"This paper discusses the limitations of studying human facial expressions using 2D images or videos and the lack of research on 3D facial expression recognition using 3D range data. The authors present a newly developed 3D facial expression database, including both 3D facial expression shapes and 2D facial textures of 2,500 models from 100 subjects, which is the first of its kind and can serve as a valuable resource for algorithm assessment, comparison, and evaluation. The ultimate goal of the database is to foster research on affective computing and increase the general understanding of facial behavior and the fine 3D structure inherent in human facial expressions.



","A 3D facial expression database for facial behavior researchFace recognition , Humans , Shape , Magnetic heads , Information analysis , Image databases , Video sequences . The 2D-based analysis is incapable of handing large pose variations . A primary factor for preventing such research is the lack of a publicly available 3D face expression database . This is the first attempt at making a third of its kind database available for the research community .",0.39080459770114945,0.11627906976744186,0.24137931034482757,0.05503336884852043
294,"The paper discusses the challenges and applications of facial expression recognition (FER) and proposes a deep transfer learning framework to recognize eight common emotions on the AffectNet dataset. The proposed framework fine-tunes a pre-trained ResNet-50 model on the AffectNet dataset to mitigate the overfitting problem caused by a lack of training data. The experiment results show the effectiveness of the proposed FER model, although the recognition accuracy is still not satisfactory due to the high imbalance of AffectNet data. The future work includes using different models and training processes and applying successful loss functions to further improve the performance of the FER model.","Facial expression recognition (FER) is currently one of the most attractive and also the most challenging topics in the computer vision and artificial fields . FER applications are ranging from medical treatment, virtual reality, to driver fatigue surveillance, and many other human-machine interaction systems . In order to mitigate the effect of small training data, which is prone to overfitting, we proposed a thoughtful transfer learning framework .",0.3488372093023256,0.1411764705882353,0.1744186046511628,0.0772908678400349
295,"This paper presents a method for facial expression recognition in static images for the Emotion Recognition in the Wild Challenge (EmotiW) 2015. The method involves a face detection module based on an ensemble of three face detectors and a classification module based on an ensemble of multiple deep convolutional neural networks (CNN). The CNN models are pre-trained on the Facial Expression Recognition (FER) Challenge 2013 dataset and fine-tuned on the training set of SFEW 2.0. The paper presents two schemes for combining the CNN models: minimizing the log likelihood loss and minimizing the hinge loss. The proposed method achieved state-of-the-art results on the FER dataset and outperformed the challenge baseline on the SFEW 2.0 dataset, achieving 55.96% and 61.29% accuracy on the validation and test sets, respectively.","Image based Static Facial Expression Recognition with Multiple Deep Network LearningFacial expression recognition, static images, ensemble learning, convolutional neural networks, Emotion Recognition in the Wild Challenge . The proposed method contains a face detection module based on the ensemble of three state-of-the-art face detectors . Each CNN model is initialized randomly and pre-trained on a larger dataset provided by the Facial expression Recognition (FER) Challenge 2013 .",0.5098039215686274,0.3366336633663366,0.35294117647058826,0.1426684853978456
296,"The paper proposes a novel approach to facial expression recognition using local binary patterns (LBP) for face representation and linear programming (LP) for classification. The method achieved an average recognition accuracy of 93.8% on the JAFFE database, outperforming all other reported methods. The paper highlights the importance of finding the right combination of face representation and classification for facial expression recognition and suggests that the combination of LBP and LP is a promising approach.","Experimental results demonstrate an average recognition accuracy of 93.8% in the JAFFE database, which outperforms the rates of all other reported methods in the same database . The combination of the local binary pattern operator and the linear programming technique is one solution to this question . We propose a novel approach to recognize facial expressions from static images . This work is promising and it is of interest to experiment with different facial expression databases .",0.563758389261745,0.2993197278911565,0.3221476510067114,0.20239084840041652
297,"Automatic facial expression recognition is a significant research topic that has practical applications in human-computer interaction, psychology, and product marketing. However, classification accuracy for systems using static images as input is limited by factors such as image quality, lighting conditions, and facial orientation. The Active Appearance Model can partially overcome these issues, and a system is described that can accurately classify expressions from six emotional categories and detect small, local facial features based on FACS. The system can also be used for expression analysis and synthesis.","Automatic facial expression recognition is a research topic with interesting applications in the field of human-computer interaction, psychology and product marketing . The classification accuracy for an automatic system which uses static images as input is however largely limited by the image quality, lighting conditions and the orientation of the depicted face . This problems can be partially overcome by using a holistic model based approach called the Active Appearance Model . A system is described that can classify expressions from one of the emotional categories joy, anger, sadness, surprise, fear and",0.6666666666666666,0.4228571428571429,0.576271186440678,0.29959168880715653
298,"This paper describes the techniques used by the authors in the 2015 Emotion Recognition in the Wild contest for the sub-challenge of Static Facial Expression Recognition in the Wild. The approach used is a transfer learning method for deep Convolutional Neural Network (CNN) architectures, where the network is fine-tuned in two stages, first on relevant facial expression datasets and then on the contest's dataset. The results show that this approach outperforms a single-stage fine-tuning with combined datasets. The best submission achieved an accuracy of 48.5% in the validation set and 55.6% in the test set, which is better than the challenge baseline.","We follow a transfer learning approach for deep Convolutional Neural Network (CNN) architectures . Our best submission achieved an overall accuracy of 48.5% in the validation set and 55.6% in the test set, which compares favorably to the respective 35.96% and 39.13% of the challenge baseline . This paper presents the techniques employed in our team's submissions to the 2015 Emotion Recognition in the Wild contest .",0.5730337078651685,0.4204545454545454,0.3707865168539326,0.30730093991594215
299,"The study investigated the facial emotion recognition (FER) deficits in autism spectrum disorder (ASD) compared to typically developing individuals using static and dynamic expressions of the six basic emotions. The results showed that individuals with ASD were impaired in recognizing facial expressions of anger and disgust, and dynamic stimuli did not provide a significant advantage. Moreover, the study highlighted that FER impairments in ASD are limited to negative emotions and that the failure to recognize negative emotions in others may lead to greater interpersonal difficulties. The researchers suggest that neuroimaging studies of people with ASD using the current stimuli will be of great interest.","There is substantial evidence for facial emotion recognition (FER) deficits in autism spectrum disorder (ASD) The extent of this impairment remains unclear, and there is some suggestion that clinical groups might benefit from the use of dynamic rather than static images . The ASD group showed poorer overall performance in identifying anger and disgust and were disadvantaged by dynamic (relative to static) stimuli when presented with sad expressions . This research provides further evidence of specific impairment in the recognition of negative emotions in ASD .",0.4919786096256684,0.1837837837837838,0.31016042780748665,0.1709987056756484
300,"This paper proposes a new framework, called 2Att-2Mt, for accurately estimating emotions from static images. The framework uses a two-level attention mechanism and two-stage multi-task learning to extract and enhance features of corresponding regions and adaptively use relationship features of different layers. The proposed framework also exploits categorical representations to improve the estimation of valence and arousal simultaneously. The results on the AffectNet dataset show significant improvements in Concordance Correlation Coefficient and Root Mean Square Error compared to prior works, demonstrating the effectiveness of the proposed framework.","In this paper, a two-level attention with two-stage multi-task learning framework is proposed for facial emotion estimation on only static images . Firstly, the features of corresponding region (position level features) are extracted and enhanced automatically by first-grade attention mechanism . Then, we utilize Bi-directional Recurrent Neural Network (Bi-RNN) with self-attention to make full use of the relationship features of different layers (layer-level features) adaptively .",0.4814814814814815,0.25,0.2716049382716049,0.09982570113176005
301,"Parkinson's disease is a neurodegenerative disorder characterized by motor symptoms and nonmotor symptoms, including difficulties in recognizing emotions from faces. Understanding this impairment is crucial for improving the quality of life for patients and caregivers. However, studies on this topic have reported contradictory outcomes, and the origins of this inconsistency are unclear. This article undertakes a fresh review of relevant articles on facial emotion recognition in PD and explores potential confounding factors, both clinical and methodological, and probable pathophysiological mechanisms. The article also discusses the impact of hypomimia on patients' and relatives' quality of life and the importance of adapting therapeutic strategies to patients' symptoms. The findings open up a new line of inquiry into patients' masked face and its impact on socioemotional communication.","Parkinson’s disease is a neurodegenerative disorder classically characterized by motor symptoms . Hypomimia affects facial expressiveness and social communication and has a highly negative impact on patients’ and relatives’ quality of life . Studies assessing abilities in recognizing facial emotions in PD still report contradictory outcomes . The origin of this inconsistency are unclear, and several questions (regarding the role of dopamine replacement therapy) remain unanswered .",0.46560846560846564,0.2887700534759359,0.3068783068783069,0.08259774165314371
302,The paper describes a system for emotion recognition in man-machine communication. The system extracts facial animation parameters (FAPs) using a facial analysis system and uses a neurofuzzy rule-based system to classify facial expressions into a 2D emotion space with high accuracy. The system can also be adapted to individual users through a learning procedure. The paper suggests that future extensions could include combining facial and gesture analysis for more expressive interactions and implementing an MPEG-4 visual ontology for emotion recognition. Experimental studies with emotionally expressive datasets indicate the good performance and potential of the developed technologies.,"Emotion recognition through facial expression analysis is of high importance for improving the level of interaction in man machine communication systems . A novel neurofuzzy system is then created, based on rules that have been defined through analysis of FAP variations at the discrete emotional space, as well as in the 2D continuous activation–evaluation one . Experimental studies with emotionally expressive datasets, generated in the EC IST ERMIS project indicate the good performance and potential of the developed technologies.",0.5084745762711863,0.22857142857142856,0.327683615819209,0.17617313883421035
303,This paper proposes a framework for recognizing emotions through still images of faces using an active appearance model (AAM) trained on a public database. The AAM's parameters are used as features for a classification scheme that successfully identifies faces related to the six universal emotions. The paper demonstrates the effectiveness of AAMs in capturing important facial structure for expression identification and suggests a framework for future development. The AAM method has proven successful with a simple Euclidean-distance classification scheme and shows potential for expression classification.,"EMOTION RECOGNITION USING FACIAL EXPRESSIONS WITH ACTIVE APPEARANCE MODELSEmotion, Facial Expression, Expression Recognition, Active Appeara . The technique involves the creation of an active appearance model (AAM) trained on face images from a publicly available database to represent shape and texture variation key to expression recognition . Parameters from the AAM are used as features for a classification scheme that is able to successfully identify faces related to the six universal emotions .",0.5350318471337581,0.2967741935483871,0.3949044585987261,0.27017960539189095
304,"The article discusses a study that evaluated the performance of five commercial emotion recognition systems (Amazon Rekognition, Baidu Research, Face++, Microsoft Azure, and Affectiva) in classifying facial expressions under different image distortion scenarios that simulate realistic image quality reduction problems likely to occur during real-world smartphone usage. The study found that each system has its own strengths and limitations and offers recommendations on how to achieve reliable facial emotion recognition results for applications in the wild, by selecting different systems depending on the nature of the captured image. Finally, the study recommends the use of their image manipulation methods for future testing of facial emotion recognition system performance.","Benchmarking commercial emotion detection systems using realistic facial image datasets . Most research into facial emotion recognition has used high-resolution, front-oriented, full-face images . However, when images are collected in naturalistic settings, these images are likely to be far from ideal due to camera positioning, lighting conditions, and camera shake . The impact these conditions have on the accuracy of commercial emotion recognition services has not been studied in full detail . In Experiment 1, we compared the systems’ accuracy at classifying images drawn from three ",0.32989690721649484,0.0625,0.17525773195876287,0.022669041092671656
305,"The article discusses four experiments that explore how people perceive facial expressions of emotions. The experiments used morphed images derived from prototypes of six emotions, and the results suggest that people categorize facial expressions of emotions into discrete categories rather than perceiving them along two underlying dimensions. The experiments also found that increasing distance from the prototype had a negative effect on the ability to identify emotions, and that people were sensitive to physical properties of these morphed facial expressions. Experiment 4 showed that people could have some insight into the differences between expressions, but this insight was elicited through a forced-choice procedure, and should not be overestimated.","In Experiment 1, morphed images made from all possible pairwise combinations of expressions were presented in random order . This result was replicated in experiment 2, which also included morphs made from a prototype with a neutral expression, and allowed ‘neutral’ as a response category . These findings are inconsistent with the view that facial expressions are recognised by locating them along two underlying dimensions, since such a view predicts that at least some transitions between categories should involve neutral regions or identification as ",0.35602094240837695,0.06349206349206349,0.2198952879581152,0.052785724560263265
306,"The study examined the psychological consequences of wearing face masks during the COVID-19 pandemic. The study found that face masks reduce people's ability to accurately categorize emotional expressions and make the target person appear less close. However, wearing a face mask buffered the negative effect of negative emotions on perceptions of trustworthiness, likability, and closeness. Moreover, associating face masks with the coronavirus predicted higher perceptions of closeness for masked faces. The findings suggest that policymakers need to consider the psychological factors when implementing policies that require face masks.","Face masks reduce emotion-recognition accuracy and perceived closenessFace masks, coronavirus, social judgments, emotional recognition, trustworthiness, likability, closeness, psychological consequences . Our preregistered study with 191 German adults revealed that face masks diminish people’s ability to accurately categorize an emotion expression and make target persons appear less close . Exploratory analyses further revealed that facial masks buffered the negative effect of negative (vs. nonnegative) emotion expressions",0.5161290322580646,0.3137254901960784,0.3741935483870968,0.1585380654091743
307,"The article discusses the development of a new deep neural network model for facial expression recognition in images, which combines convolutional and recurrent neural networks. The proposed hybrid model has been evaluated on two public datasets and has shown promising experimental results in comparison to state-of-the-art methods. The study suggests that the combination of the two neural network models can significantly improve the overall accuracy of detection, making it an efficient method for practical real-time applications.","Deep Neural Networks (DNNs) outperform traditional models in numerous optical recognition missions containing Facial Expression Recognition (FER) Existing FER methods do not have high accuracy and are not sufficient practical in real-time applications . In this paper, a model has been proposed for face emotion recognition . The proposed hybrid model is evaluated based on two public datasets and Promising experimental results have been obtained as compared to the state-of-the-art methods .",0.5359477124183006,0.27814569536423844,0.3529411764705882,0.17225648797299353
308,"The study examines the hypothesis that iconic representations communicate emotional information more efficiently than their realistic counterparts. Experiment 1 shows that cartoonized images enhance accuracy in identifying emotions compared to photorealistic images. Experiment 2 shows that lower levels of contrast and complexity within schematic stimuli are associated with lower P1 amplitudes. These findings suggest that iconic representations serve a distinct role in imparting specific information quickly and efficiently, and highlight the advantages of simplifying image features and increasing contrast to communicate emotion. Future research should explore if iconic images have a communicative advantage for more subtle emotional expressions. Understanding the factors that enhance their communicative role may improve their use in real-world applications.","In Experiment 1, we manipulated low-level features of emotional faces to create five sets of stimuli that ranged from photorealistic to fully iconic . Results showed that, at short presentation times, accuracy for identifying emotion on more “cartoonized” images was enhanced . In addition, increasing contrast and decreasing featural complexity benefited accuracy . Our findings support the view that iconic representations serve a distinct role – to impart specific information, including emotion, quickly and efficiently .",0.48387096774193544,0.17391304347826086,0.26881720430107525,0.08425796802654073
309,This study proposes a framework called KAVAN for human-centered GIF emotion recognition. KAVAN consists of a facial attention module and a hierarchical segment temporal module. The facial attention module focuses on human faces to extract frame-level visual features. The HS-LSTM module learns global GIF representations. KAVAN outperforms the state-of-the-art on the MIT GIFGIF dataset and improves model interpretability. The proposed framework utilizes GIF's unique properties and provides reliable facial region mask predictions.,"Human-Centered Emotion Recognition in Animated GIFsGIF, emotion recognition, facial attention module, Hierarchical Segment LSTM, human-centered, visual feature extraction, interpretability, keypoint-based . Our proposed framework outperforms the state-of-the-art on the MIT GIFGIF dataset . This module provides reliable facial region mask predictions, which improves the model's interpretability . Percentages below the included stimuli indicate the number of correctly recognized emotional expression",0.6013986013986015,0.3120567375886525,0.4055944055944056,0.20077021255777414
310,"The paper presents a Deep Neural Network (DNN) approach for recognizing emotions from cartoon images of characters Tom and Jerry, with four emotions: happy, sad, angry, and surprise. The approach utilizes Mask R-CNN for character detection and state-of-the-art deep learning models, including VGG 16, for emotion classification. VGG 16 outperforms the other models, achieving an accuracy of 96% and an F1 score of 0.85. The proposed approach outperforms state-of-the-art methods and has practical applications for animators, illustrators, and cartoonists. It also has the potential for developing a recommender system and recognizing emotions from body gestures.","Understanding cartoon emotion using integrated deep neural network on large datasetemotion recognition, cartoon images, Mask R-CNN, ResNet-50, MobileNetV2, InceptionV3, VGG 16, for emotion classification, animators, illustrators, cartoonists, recommender system, body gestures, artificial intelligenceEmotion is an instinctive or intuitive feeling as distinguished from reasoning or knowledge . Existing works have mostly focused well on recognizing basic emotions from human faces . However, the emotion recognition from cartoon images has not been extensively covered .",0.33142857142857146,0.16184971098265896,0.24000000000000002,0.1036423246795822
311,"The text discusses sentiment analysis, which aims to identify opinions, emotions, and polarities from user-generated content. There are two main categories of sentiment analysis strategies, lexicon-based and corpus-based. However, both approaches require sentiment-labeled data for evaluation, which is often limited in quantity. Semisupervised learning (SSL) is a promising strategy for dealing with insufficient labeled data. This research focuses on co-training, an SSL algorithm that has not received much attention for sentiment analysis due to its restricted assumptions. The study examines four different co-training strategies and tests them against three data domains with different characteristics. The results suggest that co-training can be more effective than other currently adopted SSL methods for sentiment analysis, particularly for movie reviews. However, it showed limited improvement in other data domains, such as news articles and blog posts. Future research includes investigating co-training strategies for difficult sentiment analysis tasks and other sentiment-analysis tasks such as polarity detection and emotion classification.","Semisupervised learning (SSL) is a machine learning technique that requires only a few labeled examples and can automatically label unlabeled data . Most sentiment analysis strategies fall into 2 categories: lexicon-based and corpus-based approaches . However, most data domains lack sufficient quantities of labels for evaluation . This study focuses on revisiting co-training in depth and discusses several strategies for sentiment analysis following a loose assumption .",0.37554585152838427,0.14977973568281938,0.2096069868995633,0.04411862576777645
312,The text discusses the importance of product feature extraction in opinion mining and highlights the limitations of using only local context information (LCI) for feature extraction. The authors propose a combined approach that integrates both LCI and global context information (GCI) to extract and rank features based on feature score and frequency. The approach uses the HITS algorithm for LCI and SimRank for GCI. Experimental evaluation shows that the combined approach outperforms baseline methods for feature extraction.,"In this paper, we propose a combined approach for feature extraction, which exploits both the local (LCI) and global (GCI) L. Yang et al. / Information Processing Letters 116 (2016) 623–627 627 linking information . LCI contains direct links between opinion words and nouns in a sentence . GCI contains the LCI (direct) links and also indirect links in the corpus .",0.36764705882352944,0.11940298507462686,0.22058823529411764,0.07563576015326957
313,"The paper proposes a three-stage cascade model, called Polarity Shift Detection, Elimination and Ensemble (PSDEE), to address the polarity shift problem in document-level sentiment analysis. The first stage uses a hybrid model to detect different types of polarity shifts, while the second stage introduces a novel method called antonym reversion to eliminate polarity shifts in negations. The final stage uses a weighted ensemble of base classifiers trained on component text subsets to perform sentiment classification. Experiments conducted on various sentiment datasets show that the PSDEE approach outperforms other related methods.","In this paper, we propose a three-stage cascade model to address the polarity shift problem in document-level sentiment analysis . We first split each document into a set of subsentences and build a hybrid model that employs rules and statistical methods to detect explicit and implicit polarities, respectively . Finally, we train base classifiers on training subsets divided by different types of polarization shifts . In the second stage, we introduce a novel method called antonym reversion to",0.6272189349112427,0.40718562874251496,0.4733727810650888,0.24427423373655002
314,"The paper introduces a visual analysis system called OpinionFlow that allows analysts to trace and explore opinion diffusion on Twitter. The system integrates a diffusion model and a visualization technique to display opinion diffusion among users. It uses a hierarchical topic structure built by BRT to explore opinion diffusion across a large number of users. The system is designed for expert users, but it can benefit anyone interested in opinion diffusion on social media. The authors plan to improve the system's performance and conduct a formal user study in the future. The effectiveness and usability of OpinionFlow are demonstrated through experiments and case studies on Twitter data.","In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights . Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model . The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics . In the future, we plan to improve system performance by implementing parallel algorithms of data analysis such as parallel BRT .",0.4787234042553191,0.15053763440860216,0.30851063829787234,0.09240494786380712
315,"The text discusses the issue of polarity shift in sentiment analysis and proposes a three-stage cascade model called Polarity Shift Detection, Elimination and Ensemble (PSDEE) to address this problem in document-level sentiment classification. The first stage uses a hybrid model with rule-based and statistical methods to detect explicit and implicit polarity shifts. The second stage eliminates polarity shift in negations using a novel method called antonym reversion. Finally, a weighted ensemble of base classifiers trained on different subsets of text is used as the final sentiment classifier. The PSDEE approach outperforms several alternative methods for polarity shift detection and elimination in various experiments.","In this paper, we propose a three-stage cascade model to address the polarity shift problem in document-level sentiment analysis . We first split each document into a set of subsentences and build a hybrid model that employs rules and statistical methods to detect explicit and implicit polarities shifts . Finally, we train base classifiers on training subsets divided by different types of shifts, and use a weighted combination of the components for sentiment classification . The results on a range of",0.6021505376344085,0.3043478260869565,0.41935483870967744,0.17216224622893941
316,"The text discusses the challenges and opportunities in sentiment analysis, which involves developing accurate classifiers to detect sentiment in text. Despite the vast amount of work in this area, there are still unresolved questions and new issues emerging. However, sentiment analysis has many applications, such as tracking sentiment towards products, movies, politicians, and companies, improving customer relations, detecting happiness and well-being, tracking the stock market, and improving automatic dialogue systems. While the desired application can guide certain design choices in sentiment analysis systems, it is important to incorporate carefully chosen baselines to accurately capture significant changes in sentiment.","Sentiment analysis is commonly applied in several areas including tracking sentiment towards products, movies, politicians, and companies . In this chapter, we flesh out some of the challenges that remain, questions that have not been explored sufficiently, and new issues emerging from taking on new sentiment analysis problems . The goal of this chapter is to equip researchers and practitioners with pointers to the latest developments in sentiment analysis and encourage more work in the diverse landscape of problems, especially those areas that are relatively less explored .",0.4239130434782608,0.1868131868131868,0.2282608695652174,0.15823252993951478
317,"The article discusses the growth of sentiment analysis research, but notes that most efforts are focused on English language data despite a significant amount of information being available in other languages. The authors provide a review of multilingual sentiment analysis, comparing existing state-of-the-art approaches and implementing them on common data. The authors classify the approaches into corpus-based, lexicon-based, and hybrid ones and emphasize the importance of evaluating the real value of sentiment analysis techniques through reproducible results. The article concludes with a discussion of the authors' own experiments and observations.","We present a state-of-the-art review on multilingual sentiment analysis . The majority of research efforts are devoted to English language data . Precision observed in our experiments is typically lower than that reported by the original authors, which we attribute to lack of detail in the original presentation of those approaches . We compare existing works by what they really offer to the reader, including whether they allow for accurate implementation and reliable reproduction of the reported results .",0.41618497109826597,0.11695906432748537,0.24277456647398846,0.028579833321126288
318,"The text discusses sentiment analysis or opinion mining, which involves determining the writer's attitude or speaker's opinion towards a particular person, product or topic. The use of SentiWordNet (SWN) as a lexical resource for opinion mining is explored, and a framework called ""Enhanced Sentiment Analysis and Polarity Classification (eSAP)"" is proposed. The framework is evaluated on seven benchmark datasets, and a notable performance improvement is observed compared to the baseline SWN classifier. The use of supervised learning for text classification is discussed, as well as the limitations of unsupervised approaches. Future work includes exploring other approaches to improve SWN performance.","SentiWordNet (SWN) has been extensively used as a lexical resource for opinion mining . This research incorporates SWN as the labeled training corpus where the sentiment scores are extracted based on the part of speech information . A vocabulary SWNV with revised sentiment scores, generated from SWN, is then used for Support Vector Machines model learning and classification process . The application of supervised learning has been the prime research focus for text classification .",0.3815028901734104,0.152046783625731,0.23121387283236994,0.10033144113994086
319,"The paper proposes a novel methodology for incorporating human emotion into intelligent computer systems, which includes a method to elicit emotion information from users, a new representation of emotion called the AV-AT model, and a framework for predicting and tracking user's affective trajectory over time. The approach is evaluated using offline and online experiments and a hybrid cloud intelligence infrastructure is used to conduct large-scale experiments to analyze user sentiments and associated emotions. The paper demonstrates the effectiveness of the proposed approach in comparison to other machine learning approaches, and discusses its potential applications in various contexts. Future work will involve the modification of the approach to account for the transition probabilities between affective states and analysis of more up-to-date and larger scale user data.","The proposed approach includes a method to elicit emotion information from users, a new representation of emotion (AV-AT model) that is modelled using a genetically optimized adaptive fuzzy logic technique, and a framework for predicting and tracking user’s affective trajectory over time . The performance of the proposed affect modeling methodology is tested through the deployment of a personalised learning system . A performance analysis of the infrastructure on processing, analyzing, and data storage has been carried out, illustrating its viability for large-scale",0.5514018691588786,0.3207547169811321,0.39252336448598135,0.22549898023014273
320,"The paper discusses the increasing threat of terrorism worldwide and the lack of efficient methods for predicting terrorist activities. The authors propose a framework for predicting different types of terrorist attacks using unsupervised clustering techniques, specifically a combination of density-based and distance-based clustering. This framework incorporates sentiment analysis and class labels to accurately predict terrorism attacks. The authors note that their proposed model has high accuracy and can be useful in dealing with uncertain conditions in advance, increasing trust in security agencies.",Terrorism is increasing day by day by different means . From the last decade terrorism rate is increasing exponentially . But there is no efficient way for prediction of terrorist attacks by using data mining techniques . Our proposed framework gives high level of accuracy and it is useful in prediction of attacks types. It gives us a way to deal with terrorism attacks in advance and makes our society peaceful . We proposed a framework in which we do sentiments analysis of our data and then by using a combination of density based clustering and,0.5227272727272727,0.18390804597701152,0.23863636363636362,0.03106072822421608
321,"The text discusses the recent research interest in sentiment analysis on Twitter, which involves analyzing tweets to determine the opinion they express. Various algorithms and techniques have been proposed and categorized, with machine learning methods being the most prevalent. Lexicons are also commonly used to support sentiment detection, and there are related fields such as opinion retrieval, emotion detection, and tweet sentiment quantification. The article presents a comprehensive overview of the current state of research in TSA, identifying open problems and future research directions.","Sentiment analysis in Twitter tackles the problem of analyzing the tweets in terms of the opinion they express . This survey provides an overview of the topic by investigating and briefly describing the algorithms that have been proposed for sentiment analysis . The presented studies are categorized according to the approach they follow . In addition, we discuss fields related to Twitter sentiment analysis, including Twitter opinion retrieval, tracking sentiments over time, irony detection, emotion detection and tweet sentiment quantification .",0.5341614906832297,0.1761006289308176,0.3105590062111801,0.14980773663379265
322,"The text discusses the challenges of using deep learning models for sentiment analysis of sentences. It explains the limitations of the Long short-term memory (LSTM) network in capturing text structure information and how the Tree-LSTM network uses LSTM forget gate to skip sub-trees to achieve better performance. However, Tree-LSTM struggles to identify which sub-trees are important. The proposed RST-LSTM model builds a deep learning network on Rhetorical Structure Theory (RST) parse tree to automatically enhance nucleus information and filter satellite information while improving semantic representations of text. This approach achieves higher classification accuracy and trains quickly compared to the state-of-the-art methods. The model is trained on the Stanford Sentiment Treebank dataset.","Long-term memory network solves gradient disappeared problem existed in recurrent neural network (RNN) Tree-LSTM is proposed, which uses LSTM forget gate to skip sub-trees that have little effect on the results to get good performance . We propose a simple model which uses Rhetorical Structure Theory (RST) for text parsing . Each node in RST parse tree represents the nucleus segment or the satellite segment .",0.41935483870967744,0.16304347826086957,0.2903225806451613,0.09675568774935556
323,"The text discusses the challenges of detecting sentiment in online reviews using traditional machine learning methods and the potential of recursive autoencoder (RAE) methods for sentence-level sentiment analysis. However, RAE methods have limitations such as generating deep parse trees and requiring a large amount of labeled data for each node. To overcome these limitations, the authors propose a semi-supervised method called CHL-PRAE that combines HowNet lexicon to train a bidirectional PRAE model for sentiment analysis. The experimental results show that CHL-PRAE outperforms other approaches in sentiment classification tasks with reduced training time and computational complexity. However, the Bi-CHL-PRAE model still requires further improvement, and the optimization of syntax parse tree and HowNet Lexicon are important exploring directions in the future.","recursive autoencoder (RAE) methods have been proposed for sentence-level sentiment analysis . They use word embedding to represent each word, and learn compositional vector representation of phrases and sentences . These methods mainly combine adjacent words in sequence with a greedy strategy, which make capturing semantic relations between distant words difficult . To solve these issues, we propose a semi-supervised method which combines HowNet lexicon to train bidirectional PRAE model for sentiment analysis on different datasets.",0.3781094527363184,0.21105527638190955,0.2885572139303482,0.1410998881802879
324,"The article discusses the growth of sentiment analysis in natural language processing due to the massive amount of opinionated data generated by social media. The focus is on classifying documents based on overall sentiment, and the article proposes new term weighting schemes that exploit the class space density based on the class distribution in the whole document set as well as the class documents set. The proposed approaches outperformed traditional and state-of-the-art term weighting schemes, and future work will involve creating more new term weighting schemes and optimizing them with a genetic algorithm.","The proposed new term weighting schemes exploit the class space density based on the class distribution in the whole document set as well as in the class documents set . The proposed approaches provide positive discrimination on frequent and infrequent terms . Some of our proposed terms weighting scheme outperform the traditional and state of art term weighted schemes results . In the future work, some other new termweighting schemes will be created to improve automatic sentiment classification .",0.6549707602339181,0.42603550295857995,0.5146198830409358,0.30181042786203294
325,"The text describes a new approach to sentiment analysis that categorizes opinions based on the role of the source, rather than whether the source is a writer or noun phrase. The approach uses a transductive learning method and a joint prediction model to recognize sources of participant and non-participant opinions. The approach outperforms previous methods in recognizing sources of opinions.",We propose a new categorization of opinions according to the role that the source plays . The source of a non-participant opinion is not a participant . We classify an opinion using phrase-level embeddings . A transductive learning method is used for the classifier since there is no existing annotated corpora . This work improves recognizing sources of opinions in a single model .,0.5573770491803278,0.21666666666666667,0.3606557377049181,0.11657291342699197
326,"The article discusses how sentiment analysis is used to convert social media data into valuable information, and how it is applied in world events, healthcare, politics, and business. A systematic literature review of studies on sentiment analysis in social media published between 2014 and 2019 was conducted, and 24 articles were chosen. The most common method used for sentiment analysis in social media was the opinion-lexicon method, and Twitter was the main microblogging site used for data extraction. The article also discusses the different methods used in sentiment analysis, including lexicon-based methods and machine learning methods such as Naïve Bayes and SVM. The appropriate method of sentiment analysis depends on the data structure, time, and amount of data available.","Sentiment Analysis in Social Media and Its ApplicationSentiment analysis; Big data; Social mediaTwitter and sentiment analysis application can be seen in world events, healthcare, politics and busines its application . A systematic review of studies published between 2014 to 2019 was undertaken using the following trusted and credible database including ACM, Emerald Insight, IEEE Xplore, Science Direct and Scopus . After the initial and in-depth screening of paper, 24 out of 77 articles have been chosen from the review process .",0.42786069651741293,0.16080402010050251,0.29850746268656714,0.10883451124504283
327,"The article discusses the importance of sentiment analysis in various fields and its application in social networks. It reviews existing methods and explores new aspects such as temporal dynamics, causal relationships, and industry applications. The paper highlights the importance of temporal characterization and causal effects in sentiment analysis and explores their applications in different contexts. The paper also notes the uneven distribution of research across domains and techniques. Traditional techniques such as lexicons, Bayesian methods, and bag of words are still widely used, while newer techniques such as transformer-based systems are infrequently cited. The authors believe that the use of large pre-trained models will represent a future paradigm in sentiment analysis. However, preliminary outcomes of reproducibility analyses suggest that careful domain adaptation is still needed.","This paper proposes a comprehensive review of the multifaceted reality of sentiment analysis in social networks . We also explore new aspects such as temporal dynamics, causal relationships, and applications in industry . This interest compares positively with the effort from academia, with more than 2,300 articles published in 15 years . However, these papers are unevenly split across domains: there is a strong presence in marketing, politics, economics, and health, but less activity in other domains such as emergencies .",0.39024390243902435,0.16748768472906403,0.25365853658536586,0.1279111706598295
328,"Sentiment analysis is the automated extraction of positive or negative attitudes from text and has gained attention from researchers due to the increasing popularity of online review sites, social networks, and personal blogs where people express their opinions. Natural language processing and machine learning tools are used to extract sentiments from social media, but there are challenges to this process. In this paper, the authors discuss their approach to sentiment analysis using Twitter, which goes beyond just polarity and includes product profiling, trend analysis, and forecasting. The system is capable of providing useful information for the business world, such as how people of a particular age range, area, and profession feel about a particular product or service and how it will change in the future.","Sentiment Analysis for Social Media, Data Mining, Twitter.Sentiment analysis, Data mining, Twitter, and other approaches to extract sentiments from social media . In this paper we discuss some of the challenges in sentiment extraction . The method can be further developed to cater business environment needs through sentiment analysis in social mediausing the sentiment scores for sentiments regarding particular product or service with the user’s information . So, as overall, the system is capable of saying that how a set of people of a particular age range, ",0.47393364928909953,0.2105263157894737,0.28436018957345977,0.16221054137739704
329,"Social networking platforms have become a popular way for people to express their feelings and opinions using textual content, pictures, audio, and video. Sentiment analysis is a technique used to recognize polarity in texts, assessing whether the author has a negative, positive, or neutral attitude toward a specific item, administration, individual, or location. Emotion detection goes beyond sentiment analysis, determining an individual's emotional/mental state accurately. This paper reviews various techniques for sentiment and emotion analysis, including lexicon-based, dictionary-based, and corpus-based approaches, as well as machine learning and deep learning algorithms. The review suggests that the lexicon-based technique performs well in both sentiment and emotion analysis, while the deep learning approach performs better in situations where the dataset is vast. Recurrent neural networks, particularly the LSTM model, are prevalent in sentiment and emotion analysis.","Text communication via Web-based networking media, on the other hand, is somewhat overwhelming . Each second, a massive amount of unstructured data is generated on the Internet due to social media platforms . The data must be processed as rapidly as generated to comprehend human psychology, and it can be accomplished using sentiment analysis, which recognizes polarity in texts . In some applications, sentiment analysis is insufcient and hence requires emotion detection, which determines an individual’s emotional/mental state precisely .",0.3211009174311927,0.12037037037037038,0.1834862385321101,0.018156467243087806
330,"This paper presents a model for sentiment analysis of data collected from Twitter, where users share information and opinions. The proposed model combines supervised and unsupervised machine learning algorithms to classify tweets as positive, negative, or neutral. The data is highly unstructured, but the model performs well in extracting sentiment. The study focused on analyzing opinions about McDonald's and KFC, and the results show that McDonald's is more popular than KFC in terms of both negative and positive reviews. This methodology can be used in various fields for detecting rumors and analyzing opinions expressed on social media.","Sentiment Analysis of Twitter DataSentiment analysis, social media, Twitter, tweetsNowadays, people from all around the world use social media sites to share information . Twitter for example is a platform in which users send, read posts known as ‘tweets’ and interact with different communities . Companies can benefit from this massive platform by collecting data related to opinions on them . Our proposed model is different from prior work in this field because it combined the use of supervised and unsupervised machine learning algorithms ",0.45555555555555555,0.11235955056179775,0.18888888888888888,0.08510999526315453
331,"The rise of IoT technologies and social media has led to the development of new opportunities to use data analytics for gaining insights from unstructured information. Opinion mining and sentiment analysis (OMSA) have been useful in categorizing opinions and evaluating public mood. This systematic literature review discusses both the technical and non-technical aspects of OMSA, including techniques, types, application areas, and challenges. More articles have been published on sentiment analysis compared to opinion mining since 2015. The significance of sentiment analysis matches the development of social media usage, and more than 80% of social media data can be monitored for analysis purposes.","Sentiment Analysis of Big Data: Methods, Applications, and Open Challenges Opinion mining, sentiment analysis, big data, social media, online social network . The application of opinion mining and sentiment analysis (OMSA) in the era of big data have been used a useful way in categorizing the opinion into different sentiment and in general evaluating the mood of the public . In this regard, this paper presents a comprehensive systematic literature review, aims to discuss both technical aspects of OMSA (techniques and types",0.5901639344262296,0.19889502762430938,0.36065573770491804,0.1259963168715534
332,"This paper provides a review of software tools for social media analysis, including social networking media, wikis, RSS feeds, blogs, newsgroups, chat, and news feeds. It also covers social media scraping, data cleaning, and sentiment analysis. The paper includes a methodology and a critique of social media tools and presents an illustration of a social media analytics platform built by University College London. The paper aims to provide an overview for researchers seeking to utilize social media scraping and analytics in their research or business. However, the rapid change in social media data scraping APIs is a concern, and companies are increasingly restricting access to their data. The paper suggests the need for public-domain computational environments and data facilities for quantitative social science that can be accessed by researchers via a cloud-based facility","This paper presents a comprehensive review of software tools for social networking media, wikis, really simple syndication feeds, blogs, newsgroups, chat and news feeds . For completeness, it also includes introductions to social media scraping, storage, data cleaning and sentiment analysis . It is also a research area undergoing rapid change and evolution due to commercial pressures and the potential for using social media data for computational (social science) research .",0.5024630541871921,0.25870646766169153,0.41379310344827586,0.14904787081902948
333,"This paper focuses on sentiment analysis in the field of natural language processing, which involves extracting positive or negative polarities from social media text. The paper examines the efficacy of four state-of-the-art machine learning classifiers, including Naïve Bayes, J48, BFTree, and OneR, for optimizing sentiment analysis. Three manually compiled datasets, two from Amazon and one from IMDB movie reviews, are used in the experiments. OneR is found to be the most promising classifier, achieving an accuracy of 91.3% in precision, 97% in F-measure, and 92.34% in correctly classified instances. Naïve Bayes is faster in learning, and J48 exhibits adequacy in true positive and false positive rates. The preprocessing methodology involves extracting foreign words, emoticons, and elongated words with their appropriate sentiments. Future work in sentiment analysis could improve preprocessing with word embeddings using deep neural networks and extend the study through convolution","Analysing negative or negative polarities from social media text denominates task of sentiment analysis in the feld of natural language processing . The exponential growth of demands for business organizations and governments, impel researchers to accomplish their research in sentiment analysis . Nave Bayes, J48, BFTree and OneR exploit four machine learning classifers for sentiment analysis using three manually annotated datasets .",0.37320574162679426,0.20289855072463767,0.21052631578947373,0.06306794720111461
334,"This article discusses the importance of sentiment analysis in the context of social media and how it has become increasingly popular to gather and analyze people's reactions towards various topics. The paper explores various sentiment analysis techniques applied to Twitter data, including machine learning, ensemble approaches, and dictionary-based methods. The research outcomes demonstrate that machine learning techniques, particularly SVM and MNB, produce the greatest precision, while ensemble and hybrid-based Twitter sentiment analysis algorithms tend to perform better than supervised machine learning techniques. The article concludes that hybrid methods can obtain reasonable classification accuracy scores by combining both machine learning classifiers and lexicon-based Twitter sentiment analysis approaches.","Sentiment Analysis Techniques of Twitter DataTwitter; sentiment; Web data; text mining; SVM; Bayesian algorithm; hybrid; ensemblesThe entire world is transforming rapidly under the present innovations . The Internet has become a basic requirement for everybody with the Web being utilized in every field . Gathering and analyzing peoples’ reactions toward buying a product, public services, and so on are vital . In recent years, researchers in the field of sentiment analysis have been concerned with analyzing opinions on different topics such",0.3085106382978723,0.10752688172043011,0.1702127659574468,0.021978561092834054
335,"The article discusses a computer-assisted literature review of sentiment analysis, analyzing 6,996 papers from Scopus. The roots of sentiment analysis can be traced back to public opinion analysis and text subjectivity analysis. The majority of sentiment analysis papers have been published after 2004, with a significant increase in the number of papers published in recent years. Sentiment analysis has shifted from analyzing online product reviews to social media texts from Twitter and Facebook. The article provides a taxonomy of research topics and the top-cited papers from Google Scholar and Scopus. The impact of sentiment analysis is evaluated through a citation and bibliometric study, which shows that sentiment analysis has become one of the fastest growing research areas in computer science.","We present a computer-assisted literature review, where we utilize both text mining and qualitative coding, and analyze 6996 papers from Scopus . Sentiment analysis papers are scattered to multiple publication venues, and the combined number of papers in the top-15 venues only represent ca. 30% of the papers in total . In recent years, sentiment analysis has shifted from analyzing online product reviews to social media texts from Twitter and Facebook .",0.5051546391752577,0.34375,0.422680412371134,0.19666068119317154
336,"The article discusses the development of a sentiment analyzer using deep learning to analyze opinions and attitudes expressed on Facebook regarding the COVID-19 pandemic in low-resource languages. The study collected and classified 10,742 comments in Albanian and trained three deep neural networks using fastText pre-trained embedding model, achieving an F1 score of 72.09% by combining BiLSTM with an attention mechanism. The study demonstrates the effectiveness of the proposed approach in handling sentiment analysis on user-generated social media comments in low-resource languages.","We have created a large-scale dataset comprising 10,742 manually classified comments in the Albanian language . To do this, we report our efforts on the design and development of a sentiment analyser that relies on deep learning . The dataset consisted of users’ comments posted on NIPHK Facebook page during the period of March to August 2020 . Our findings show that combining the BiLSTM with an attention mechanism achieved the highest performance on our sentiment analysis task .",0.4484848484848485,0.13496932515337426,0.2545454545454545,0.10454155140038482
337,"The article discusses the use of machine learning and natural language processing techniques for sentiment analysis of English tweets during the COVID-19 pandemic in 2020. The study applies the Logistic Regression algorithm to classify tweets as positive or negative and achieves a classification accuracy of 78.5%. The analysis found that people mostly remained positive about the pandemic, with 54% of users showing positive feelings and 46% showing negative feelings. The proposed methodology has a universal approach that can be replicated in similar works with different data sources.","Social networks and microblogging are a valuable source of information, being mostly used to express personal points of view and thoughts . Based on this knowledge we propose a sentiment analysis of English tweets during the pandemic COVID-19 in 2020 . The tweets were classified as positive or negative by applying the Logistic Regression algorithm, using this method we got a classification accuracy of 78.5% . Despite the fact that the analysis found variation of opinions, it seems that people mostly remain positive .",0.5847953216374269,0.33136094674556216,0.39766081871345027,0.22018874782101197
338,"Sentiment analysis is a method used to extract opinions and attitudes from text, especially social media and online platforms. It involves analyzing text at a fine-grained level, such as the sentence level, to determine its polarity as positive, negative, or neutral. Various techniques have been used to analyze movie reviews, including Naïve Bayes, K-Nearest Neighbour, Random Forest, Maximum Entropy, SVM, and Voted Perceptrons. From these techniques, Naive Bayesian has shown the most promising results. Additionally, sentiment analysis research overlaps with natural language processing, which addresses challenges such as irony detection and multi-lingual support. Using a Sentiment Analyzer module can significantly improve the accuracy of sentiment analysis models. To ensure the success of current models, it is important to research and verify the most beneficial methods and filter research papers. This knowledge and experience can lead to further advancements in sentiment analysis.","Sentiment Analysis is a very useful method widely used to express the opinion of a large group or mass . This sentiment can be based on the attitude of the author or his/her affective state at the moment of writing the text . Social media and other online platforms contain a huge amount of unstructured data in the form of tweets, blogs, posts, etc. This paper aims at analyzing a solution for the sentiment classification at a fined grained level .",0.33035714285714285,0.0990990990990991,0.1875,0.026760911403593775
339,"The paper discusses sentiment analysis of social media data to extract various sentiment behaviors for strategic decision making. The data was preprocessed to remove noise, and classification techniques such as Multi-layer Perceptron (MLP), Convolutional Neural Networks (CNN), SVM, Random Forest, Decision tree, and Naïve Bayes were used to extract sentiment from Twitter data and consumer affairs websites. The proposed work found that MLP and CNN performed better than other classifiers. The study concludes that various techniques can be used to achieve sentiment analysis on social media data, and presence in the spare vector representation recorded better performance than frequency. The proposed system can be applied in other internet communities.","Sentiment Analysis on Social Media Data Using Intelligent TechniquesCNN, Emotions, Multi-layer Perceptron (MLP) and Convolutional Neural Networks (CNN) performed better than others classifier in general . The aim of the paper is to extract various sentiment behaviour and aids to categorize sentiment and affections of people as clear, contradictory or neutral. The data was preprocessed with the help of noise removal for removing the noise .",0.5,0.27586206896551724,0.2840909090909091,0.1514945487037853
340,"The paper discusses the challenges of person recognition in social media photos, which require recognizing people in non-cooperative scenarios and with changes in appearance. The authors propose a framework that uses convnet features from multiple image regions and analyze the importance of different features over time and viewpoint generalizability. They also introduce new splits on the PIPA dataset to simulate different time gaps between training and testing samples. The results show that cues based on face and context are robust across time and viewpoint, and the proposed naeil2 framework achieves state-of-the-art results. The authors suggest that future research could explore non-visual cues such as GPS and time metadata, camera parameters, or social media album/friendship graphs.","People nowadays share large parts of their personal lives through social media . Being able to automatically recognise people in personal photos may greatly enhance user convenience by easing photo album organisation . For human identification task, however, traditional focus of computer vision has been face recognition and pedestrian re-identification . To tackle this problem, we build a simple person recognition framework that leverages convnet features from multiple image regions (head, body, etc.)",0.22916666666666666,0.09473684210526315,0.16666666666666666,0.05534518860310991
341,"The paper discusses the challenges of person recognition in social media photos, including non-cooperative subjects and changes in appearance, and presents a simple approach that uses convnet features from multiple image regions. The authors propose new recognition scenarios that focus on time and appearance gaps between training and testing samples and achieve state-of-the-art results on the PIPA benchmark. They also analyze the importance of different features and present a new method called naeil2 that combines their previous approach with a face recognizer to improve performance. The paper concludes that methodological advances are needed to fully solve the problem of person recognition in social media photos but the methods presented in the paper already collect substantial identity information even from a single sample per person.","People nowadays share large parts of their personal lives through social media . Being able to automatically recognise people in personal photos may greatly enhance user convenience by easing photo album organisation . For human identification task, however, traditional focus of computer vision has been face recognition and pedestrian re-identification . To tackle this problem, we build a simple person recognition framework that leverages convnet features from multiple image regions (head, body, etc.)",0.2814070351758794,0.08121827411167513,0.1507537688442211,0.050741430130533574
342,"The article discusses the role of social media in shaping personal brand, with a focus on celebrities associated with artistic and cultural activities. The first part of the article defines personal brand and discusses the importance of social media in building brand capital. The second part presents empirical research, which shows that online activity of Internet users stimulates the brand capital of famous people. However, celebrities must also be aware of the potential negative impacts of interactions with social media users, such as criticism. The article concludes with implications for celebrities building their personal brand using social media, and suggests future research directions.","The article uses the results of the direct research carried out in the period 2019–2020 . The second (empirical) part of the article presents research hypotheses, methodology, as well as results and conclusions from the research . Famous people building their personal brand using social media may have to face troublesome interactions, criticising their activities, presented photos, videos, initiatives or topics . In the future, in-depth qualitative and quantitative research is planned on a much larger sample of celebrities and online consumers of famous people’s services in",0.4526315789473684,0.14893617021276598,0.25263157894736843,0.12053041087622184
343,"This article summarizes the research progress of images in social media in the past ten years. The research is divided into three parts: the characteristics of images in social media, image publishing behavior, and image perception and acquisition behavior of social media users. The article also identifies the research hotspots and development trends of visual information interaction in image social interaction. The paper concludes by predicting future research in three aspects: the impact of image-based information interaction on users' social relationships, the problem of user privacy disclosure, and the advancement of computer vision technique in image research in social media.","The research progress of images in social media is summarized by comprehensive induction . This paper reveals the research hotspots and development trends of visual information interaction in image social interaction . It is found that the feature of images on social media and user's information interaction behavior based on image are the key content that researchers pay attention to . In terms of user privacy, we can explore the influence of user’s image use behavior on privacy disclosure .",0.5810055865921788,0.2937853107344633,0.4022346368715084,0.23104830609597352
344,"The trend of social media platforms has led to an increase in fake profiles, which harms social and business entities. Existing methods for identifying fake profiles have an average accuracy of 83%, which is not accurate enough. The proposed solution is a Spark ML-based project that can predict fake profiles with higher accuracy than existing methods, with an accuracy of 93% and a 7% false positive rate. The project uses face recognition libraries and trains 70% of the profiles data on machine learning algorithms using Spark ML lib, then tests the remaining 30% data to find accuracy and predictions. The proposed solution's limitations include a false positive rate of up to 6%. Future work includes improving the method to identify fake profiles and reducing the error ratio, implementing with deep learning and bi-models to enhance fake profile recognition, and developing a user-friendly interface for non-tech users to identify fake profiles and avoid scams.","Our proposed solution is a Spark ML-based project that can predict fake profiles with higher accuracy than other present methods of profile recognition . We have described our proposed model diagram and tried to depict our results in graphical representations like confusion matrix, learning curve and ROC plot for better understanding . This proposed system has accuracy of 93% in finding fake profiles over social media platforms, while there is 7% false positive rate in which our system fails to correctly identify a fake profile .",0.4214876033057851,0.21666666666666667,0.2644628099173554,0.11874839198722062
345,"This paper provides a comprehensive review of various face recognition techniques, including a summary of face recognition and its applications, literature reviews of different methods, analysis of algorithms, and modern approaches such as neural networks and line edge mapping. The paper concludes by summarizing the research results and suggesting that face recognition will be one of the major machine learning applications in the future, with various practical methods and approaches to achieve greater scope in this field.","A Review Paper on Face Recognition Methodologiesface recognition, literature review, algorithms, neural networks, line edge mapping . In the previous few years, the procedures of face recognition have been researched thoroughly . We've also learned that way face recognition and different approaches are researched it will be one of the major machine learning applications in the coming future . Several face recognition algorithms are analyzed and elaborated with their limitations as well .",0.5578231292517006,0.2620689655172414,0.43537414965986393,0.2220993316509472
346,"Social media platforms have become a valuable tool for mass communication, including in the promotion of mental health awareness. This qualitative study evaluated the effectiveness of three health promotion campaigns conducted on Facebook and Instagram over a 5-month period in 2019. The campaigns focused on suicide prevention, tobacco cessation, and migraines, and involved script writing, slogan writing, poster making, and short film making. Descriptive statistics showed that the campaigns reached a considerable number of people, with the Facebook and Instagram posts reaching around 10.3k people. The study concludes that using social media platforms for mental health campaigns is an effective way to reach a large number of people in a short time frame and that digital media is increasingly being used for mental health awareness initiatives",Effective use of social media platforms can be a good initiative to reach out to a large number of people in a short time frame . It was conducted over 5 months from May to September 2019 to reach more people for effective information dissemination . The campaigns were as follows (1) The Buddies for Suicide Prevention: an online campaign to create awareness about suicide prevention . #Iquitobacco was a 21day campaign with an idea of tobacco cessation in the community .,0.46601941747572817,0.16666666666666669,0.1941747572815534,0.0941015872800798
347,"This paper presents a new approach to address the challenge of human face recognition on small original datasets. The approach combines a convolutional neural network (CNN) with an augmented dataset, which is created by transforming the face images through flipping, shifting, scaling, and rotation. The augmented dataset allows for effective feature extraction and achieves higher face recognition accuracy. The proposed approach is compared to other face recognition methods and shown to be superior. The paper suggests that this approach could be applied to other fields related to data-based training and learning, such as signal processing, image recognition, and image-based fault detectioon.","a new approach has been developed to deal with the issue of human face recognition on small original dataset . The original small dataset is augmented to be a large dataset via several transformations of the face images . Based on the augmented face image dataset, the feature of the faces can be effectively extracted and higher face recognition accuracy can be achieved by using the ingenious CNN. The effectiveness and superiority of the proposed approach can be verified by several experiments and comparisons with some frequently used face recognition methods.",0.5416666666666667,0.24210526315789477,0.3958333333333333,0.135614336310357
348,"This paper provides an overview of face recognition technology, which is a biometric technology based on identifying facial features. The paper covers the development stages and related technologies of face recognition, research for real conditions, evaluation standards, and general databases. The paper also offers a forward-looking view of the technology, including potential application prospects and areas for improvement. The paper suggests that future improvements could include the use of a special camera for face recognition, 3D technology to supplement 2D images, and solutions to problems such as image filtering, reconstruction, denoising, rotation, and occlusion.","Face recognition technology is based on the identification of facial features of a person . People collect the face images, and the recognition equipment automatically processes the images . The paper describes the development stages and the related technologies of face recognition . Face recognition has become the future development direction and has many potential application prospectsWith the development of science and technology, the face recognition technology has made great achievements, but there is still room for its improvement in practical application .",0.471264367816092,0.18604651162790697,0.31034482758620685,0.10959694844565827
349,"In this review paper, different techniques of sign language 
recognition are reviewed on the basis of sign acquiring 
methods and sign identification methods. For sign acquiring 
methods, vision based methods and for sign identification 
methods, artificial neuron network proves a strong 
candidature","A Review Paper on Sign Language Recognition System For Deaf And Dumb People using Image ProcessingSign language identification, Hidden Morkov Model,Artificial Neural Network, Data glove, Leap motion controller, Kinectic Sensor. This paper reviews a different methods adopted to reduce barrier of communication by developing an assistive device for deaf-mute persons . The main objective is to develop a real time embedded device for physically challenged to aid their communication in effective means .",0.34782608695652173,0.053097345132743355,0.19130434782608693,0.02218816339041215
350,"This survey explores the practical applications of social media data, which serves as a critical information source with large volumes, high velocity, and a wide variety of data. The survey outlines a commonly used pipeline in building social media-based applications and discusses available analysis techniques such as topic analysis, time series analysis, sentiment analysis, and network analysis. The impacts of social media-based applications in disaster management, healthcare, and business are also presented. Existing challenges are listed, and future research directions are suggested in terms of data privacy, 5G wireless network, and multilingual support.","Survey on Data Analysis in Social Media: A Practical Application Aspectsocial media; topic analysis; time series analysis; sentiment analysis; network analysis; disaster management; bio-surveillance; business intelligenceThis survey studies the previous literature and the existing applications from a practical perspective . We outline a commonly used pipeline in building social media-based applications and focus on discussing available analysis techniques . After that, we present the impacts of such applications in three different areas, including disaster management, healthcare, and business .",0.6011560693641619,0.3508771929824561,0.3699421965317919,0.20668019498026333
351,"The paper explores the challenges and potential problems in studying sentiment analysis in social media. It provides insights into the sentiment analysis task's goals, implementation process, and its use in various application domains. The paper also compares different studies and highlights several challenges related to datasets, text languages, analysis methods, and evaluation metrics. The paper aims to help practitioners select a suitable methodology for their applications. However, the review is limited to studies published between 2018 and 2021 and only includes publications written in English, which may lead to an inadequate understanding of sentiment analysis in non-English texts. Future work will expand the timeframe and involve researchers from non-English speaking countries or multilingual scholars.","Sentiment analysis provides an automated method of analyzing sentiment, emotion and opinion in written language to address this issue . In the existing literature, a large number of scholars have worked on improving the performance of various sentiment classifiers or applying them to various domains using data from social networking platforms . It also provides a comparison of different studies and highlights several challenges related to datasets, text languages, analysis methods and evaluation metrics .",0.4444444444444445,0.17112299465240643,0.26455026455026454,0.14177266003158212
352,"This study aims to provide an overview of research analyzing social media data since 2017. The study identifies a lack of clear definitions in the field and identifies predominant research domains, including marketing, hospitality, and tourism. Twitter is the most commonly analyzed platform, and sentiment and content analysis are the prevailing methods. The study suggests future research avenues, including finding suitable procedures for transparently identifying, collecting, processing, and analyzing social media data and focusing on the ethical and legal dimensions of using such data. Limitations include a limited time frame and a focus on only four academic databases.","The nature of social media data poses a challenge to the analysis . An extensive literature review led to the findings that clear definitions are neither established nor commonly applied . Predominant research domains include marketing, hospitality and tourism, disaster management, and disruptive technology . Half of the studies include practical implications, which is why this review proposes such definitions to move the research area forward . In social media, the timeliness of data is crucial .",0.47058823529411764,0.14285714285714285,0.2823529411764706,0.030263566502693465
353,"The paper discusses the growth of social media and the need for sentiment analysis due to the unstructured nature of opinions expressed online. The survey provides a comparative analysis of existing techniques for opinion mining, including machine learning and lexicon-based approaches, cross-domain and cross-lingual methods, and evaluation metrics. The study finds that machine learning methods such as SVM and naive Bayes have the highest accuracy and can be considered as baseline learning methods, while lexicon-based methods are effective in some cases requiring minimal human-labeled documents.","Internet has become a platform for online learning, exchanging ideas and sharing opinions . Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics, have discussion with different communities, or post messages across the world . There hasn’t been lot of work in the field of sentiment analysis of social media . In this paper, it is provided a survey and comparative study of fundamental techniques for opinion mining .",0.388235294117647,0.09523809523809525,0.17647058823529413,0.05835037382561354
354,"The article discusses the potential use of deep-learning approaches based on residual networks for case-finding of chronic obstructive pulmonary disease (COPD) from CT scans. The authors present results indicating an accuracy of more than 88% for identifying COPD subjects from CT scans, which they consider within the clinically acceptable range. They suggest that this approach could be a powerful technique to identify patients with COPD within the general population who have not been previously diagnosed. The proposed pipeline could operate in the background and flag scans identified by the pipeline as COPD. The authors suggest that their overall approach could provide useful indications to radiologists and clinicians about clinically relevant findings that could improve the diagnosis and follow-up of specific patients. The article highlights the urgent need for cost-effective strategies for case-finding of COPD, given the large proportion of undiagnosed patients. With the growing use of CT imaging for pulmonary nodule assessment and lung cancer screening, the authors suggest that deep learning of chest CT data using neural networks could be a valuable assistive tool for COPD case-finding in this setting.","a large body of literature indicates that a considerable proportion of COPD patients are undiagnosed . We hypothesised that deep learning of chest CT data using neural networks could be a valuable assistive tool for COPD case-finding in this setting . By presenting a sufficiently large training data set of CT scans acquired from a pool of individuals of known disease categories (eg, COPD or non-COPD), deep neural networks have the potential to recognise, without any human guidance, recurring but subtle image",0.379182156133829,0.20224719101123595,0.2230483271375465,0.0960609395383142
355,"The paper proposes an emotion recognition system that uses a deep learning approach from emotional Big Data consisting of speech and video. The system involves processing the speech signal to obtain a Mel-spectrogram and treating it as an image, which is fed to a convolutional neural network (CNN), while for video signals, some representative frames are extracted and fed to a 3D CNN. The outputs of the two CNNs are fused using two consecutive extreme learning machines (ELMs), and the output of the fusion is given to a support vector machine (SVM) for final classification of emotions. The proposed system is evaluated using two audio–visual emotional databases, one of which is Big Data. The experimental results show that the proposed system outperforms other similar systems, with the ELM-based fusion performing better than the classifiers’ combination. The proposed system can be extended to be a noise-robust system and can be integrated into any emotion-aware intelligent systems for better service to users or customers. Future work includes evaluating the proposed system in an edge-and-cloud computing framework and investigating other deep architectures to improve its performance.","This paper proposes an emotion recognition system using a deep learning approach from emotional Big Data . The Big Data comprises of speech and video . In the proposed system, a speech signal is first processed in the frequency domain to obtain a Mel-spectrogram, which can be treated as an image . For video signals, some representative frames from a video segment are extracted and fed to the CNN . Different fusion strategies including the proposed ELM-based fusion were investigated .",0.49253731343283585,0.3007518796992481,0.3880597014925373,0.10090996130454159
356,"This paper presents an approach for facial emotion recognition using a deep convolutional neural network model. The model is an extension of the authors' previous work and is trained on two datasets, Extended Cohn-Kanade and Japanese Female Facial Expression. The model outperforms recent state-of-the-art approaches for emotion recognition and shows improved accuracy compared to the authors' previous model. The combination of fully connected networks and residual blocks is found to improve the overall performance of the model. Overall, the proposed deep neural network model is effective for facial emotion recognition and has been tested on public datasets.","In this paper, we present our approach which is the extension of our previous work for facial emotion recognition [1]. The aim of this work is to classify each image into one of six facial emotion classes . The proposed model is based on single Deep Convolutional Neural Networks (DNNs), which contain convolution layers and deep residual blocks . In the proposed model, firstly the image label to all faces has been set for the training .",0.4914285714285714,0.16184971098265896,0.2857142857142857,0.06344300861168292
357,"The paper proposes a classification algorithm called probability and integrated learning (PIL) for recognizing human emotions in complex situations with fuzziness. The algorithm is based on a novel topology of integrated learning, and it adapts to emotional uncertainty by calculating the confidence interval of the classification probability. The paper also presents three new analyses methods based on classification probability, including emotional sensitivity, emotional decision preference, and emotional tube. The proposed method has potential applications in affective computing for videos and may be useful in artificial emotion for robots. The study suggests exploring factors for preference and emotional sensitivity, expanding PIL to valence-arousal space, and optimizing parameters in future research. The paper also mentions the possibility of applying sophisticated algorithms based on advanced genetic programming principles to improve classification accuracy.","a probability and integrated learning based classification algorithm is proposed for solving high-level human emotion recognition problems . In this paper, a novel topology of integrated learning is proposed to obtain the essential material basis for analyzing the complex human emotions . This paper also presented three new analyses methods based on classification probability including the emotional sensitivity, emotional decision preference and emotional tube . The proposed method could be used in the affective computing for video, and may play a reference role in artificial emotion established for robot with a natural and humanized",0.6126126126126126,0.38181818181818183,0.48648648648648657,0.20433030089221962
358,"This paper proposes a framework for facial expression recognition in video sequences, which combines two networks: a local network and a global network. The local network uses a novel approach called LEMHI to aggregate frames into a single frame, which is then fed into a CNN network for prediction. The global network uses an improved CNN-LSTM model for feature extraction and classification. The two networks are integrated using a random search weighted summation strategy. Experiments on the AFEW, CK+, and MMI datasets demonstrate that the integrated framework achieves better performance than using individual networks separately and outperforms state-of-the-art methods. However, the accuracy on the AFEW dataset is still unsatisfactory, and further research is needed to improve performance on wild expression datasets.","This paper presents a facial expression recognition framework using LEMHI-CNN and CNN-RNN . The integrated framework incorporates facial landmarks to enable attention-aware facial motion capturing and utilize neural networks to extract spatial-temporal features and classify them . This approach improves MHI by using detected human facial . landmarks as attention areas to boost local value in difference image calculation . On the other hand, an improved CNN-LSTM model is used as a global feature extractor and classifier for video facial",0.3883495145631068,0.10784313725490197,0.1941747572815534,0.04208595161786238
359,"The paper proposes a simple solution for facial expression recognition using a combination of Convolutional Neural Network and specific image pre-processing steps. The method achieves competitive results compared to other facial expression recognition methods, with 96.76% accuracy on the CK+ database, and allows for real-time recognition. The study evaluates the impact of each pre-processing operation on accuracy and shows that the combination of normalization procedures significantly improves accuracy. The proposed method works in unknown environments, but there is room for improvement. Future work includes investigating other learning methods to increase the method's robustness and fine-tuning a pre-trained deep neural network to focus on more specific features.



","Convolutional Neural Networks: Coping with few data and the training sample order . The recognition of facial expressions is not an easy problem for machine learning methods, since people can vary significantly in the way they show their expressions . Even images of the same person in the same facial expression can vary in brightness, background and pose, and these variations are emphasized if considering different subjects (because of variations in shape, ethnicity among others)",0.3225806451612903,0.05434782608695652,0.16129032258064516,0.009425621649615742
360,"The paper presents a novel model called Deep Attentive Multi-path Convolutional Neural Network (DAM-CNN) for Facial Expression Recognition (FER). The model includes two modules, the attention-based Salient Expressional Region Descriptor (SERD) and the Multi-Path Variation-Suppressing Network (MPVS-Net). SERD identifies expression-related regions in an image, while MPVS-Net disentangles expression information from irrelevant variations. By combining SERD and MPVS-Net, DAM-CNN generates a variation-robust representation for expression classification. The model's effectiveness is demonstrated through experimental results on both constrained and unconstrained datasets. Future work includes modifying the training strategy, optimizing the network structure, and extending the model to other recognition tasks such as face recognition.","In this paper, we present a novel model for FER . Different from most existing models, DAM-CNN can automatically locate expressionrelated regions in an expressional image . SERD can adaptively estimate the importance of different image regions . MPVS-Net disentangles expressional information from irrelevant variations . Extensive experimental results on both constrained datasets demonstrate the effectiveness of our model .",0.40935672514619886,0.17751479289940827,0.3157894736842105,0.07201446778232568
361,"The paper presents a novel model, wSupDocNADE, for simultaneous image classification and annotation, which addresses the shortcomings of previous models related to poor visual word representation and imbalance between visual and annotation words. The proposed model uses a deep convolutional neural network and the LLC coding to generate a more informative representation of the input image, and introduces a weighting mechanism to overcome the imbalance issue. Experimental results on three benchmark datasets show that wSupDocNADE outperforms state-of-the-art models in image classification and annotation tasks. However, the model can still be improved by incorporating attention mechanisms to assign higher weights to more important image patches.","The proposed model, named wSupDocNADE, addresses the above shortcomings by using a new coding and introducing a weighting mechanism . In the coding step of the model, several patches extracted from the input image are first fed to a deep convolutional neural network and the feature vectors obtained from this network are coded using the LLC coding . The weights of the visual words are set based on their frequencies obtained from the pooling method .",0.4555555555555556,0.2471910112359551,0.2555555555555556,0.11195106803718637
362,"This paper proposes a framework for recognizing facial expressions in video sequences using a dynamic descriptor. The framework utilizes a spatio-temporal feature based on local Zernike moment in the spatial domain and motion change frequency, as well as a dynamic feature comprising motion history image and entropy. To recognize a facial expression, a weighting strategy based on the dynamic feature and sub-division of the image frame is applied to the spatio-temporal feature, followed by support vector machine classification. The proposed framework outperforms six state-of-the-art methods on the CK+ and MMI datasets. However, the framework performs slightly worse in distinguishing fear, sadness, and contempt expressions, and computation speed is a factor that needs to be considered when applying the framework in real situations. Further work is needed to design better features to represent these expressions and to increase the computational speed of the framework without degrading the recognition rate.","A dynamic descriptor facilitates robust recognition of facial expressions in video sequences . The current two main approaches to the recognition are basic emotion recognition and recognition based on facial action coding system (FACS) action units . This paper presents a facial expression recognition framework using enMHI_OF and QLZM_MCF. The framework which comprises pre-processing, feature extraction followed by 2D PCA and SVM classification achieves a better performance than most of the state-of-art methods on",0.3636363636363636,0.1572052401746725,0.2077922077922078,0.04375830432285438
363,"This paper proposes a Multi-channel Deep Spatial-Temporal feature Fusion neural Network (MDSTFN) for facial expression recognition (FER) from static images. The proposed method extracts optical flow from changes between peak expression and neutral face images as temporal information, and gray-level images of emotional-face as spatial information. The feature extraction channels of the MDSTFN are fine-tuned from pre-trained CNN models. Three strategies are investigated to fuse temporal and spatial features. The proposed method achieves better accuracy than state-of-the-art methods on benchmark databases including CK+, RaFD, and MMI. The use of average-face in place of neutral-face improves practicality.","Multi-channel Deep Spatial-Temporal feature Fusion neural Network (MDSTFN) is presented to perform the deep spatial-temporal feature extraction and fusion from static images . Each channel of the proposed method is fine-tuned from a pretrained deep convolutional neural networks (CNN) instead of training a new CNN from scratch . Extensive experiments are conducted to evaluate the proposed methodology on benchmarks databases including CK+, MMI, and RaFD .",0.5057471264367815,0.26744186046511637,0.367816091954023,0.1565458868791273
364,"The article presents a novel approach for emotion recognition (ER) using a semi-supervised algorithm with reduced features and a reconstruction error-based feature selection method. The proposed algorithm involves a cascaded structure that first extracts features from facial images, reduces them, and then trains a Deep Belief Network (DBN) using both labeled and unlabeled data. HOG features of the mouth were found to be the most effective, and the semi-supervised approach outperformed SVM and CNN methods in terms of accuracy and computational complexity. The use of reduced-dimensional features with LDA further improved the performance. The authors declare no competing interests and acknowledge funding from the NSF and support from UNM Center for Advanced Research Computing. The future work aims to extend ER technology to videos, especially in emergency response scenarios.","Semi-supervised facial expression recognition using reduced features and Deep Belief Networks.Emotion recognition, Dimensionality reduction, Contrastive divergence, Backpropagation, K-Fold cross-validation. A semi-supervised training with all the available labeled and unlabeled data is applied to a deep belief network (DBN). Results show that HOG features of mouth provide the best performance .",0.3529411764705882,0.16216216216216214,0.2032085561497326,0.051398084225797794
365,"The field of opinion summarization faces obstacles in enhancing current techniques, and there is a need for a summarization corpus from social media to advance the field. Abstractive summarization, deep learning, and GPUs are expected to dominate future research in opinion summarization, with more attention given to software tools like TensorFlow and Microsoft Cognitive Toolkit.","The need for efficient processing of this extensive information resulted in increasing research interest in knowledge engineering tasks such as Opinion Summarization . This survey shows the current opinion summarization challenges for social media, then the necessary pre-summarization steps like preprocessing, features extraction, noise elimination, and handling of synonym features . Next, it covers the various approaches used in opinion summization like Visualization, Abstractive, Aspect based, Query-focused, Real Time .",0.3064516129032258,0.0819672131147541,0.22580645161290322,0.014136246845518192
366,"This paper reviews the current state of scientific article summarization, focusing on solutions, evaluation, and corpora used. Extractive techniques, single-article summarization, and statistical/machine learning approaches are dominant, with intrinsic evaluation methods (ROUGE metrics) used largely. Challenges include lack of benchmark corpora, gold standard summaries, evaluation metrics, and baseline systems. Graph-based methods are successful in multi-document summarization but less studied for scientific articles. More research is needed to improve coherence and readability, shift to multi-article and abstractive summarization, and explore deep learning approaches.","Automatic summarization of scientific articles would help researchers in their investigation by speeding up the research process . Most of the valuable information in scientific articles is presented in tables, figures, and algorithm pseudocode . This paper presents a critical review of the state-of-the-art systems of summarizing scientific articles . The absence of benchmark corpora and gold standard summaries for scientific articles remains the main issue for this task .",0.34615384615384615,0.12987012987012986,0.21794871794871795,0.030997676845161463
367,This review focuses on the identification of modality-specific and multimodal/modality-free regions in the brain that facilitate recognition of person identity. It emphasizes the need to study person-identity recognition from multiple modalities in both healthy individuals and patients. The findings challenge traditional cognitive and neuroscientific models of person-identity recognition and offer a model-driven approach for further research in clinical and experimental settings.,"We identify modality-specific brain areas involved in recognition from different person characteristics and potential multimodal hubs for person processing in the anterior temporal, frontal, and parietal lobes and posterior cingulate . Our combined review is built on cognitive and neuroscientific models of face- and voice-identity recognition and revises them within the multimodal context . The results provide a novel framework for future research .",0.4461538461538461,0.140625,0.29230769230769227,0.09388697862749172
368,"The text proposes a new method for image sentiment analysis that uses the correlation between object semantics and image sentiment to improve accuracy. The proposed method involves a Bayesian network model that represents the correlation between image emotions and object semantics, resulting in a probability distribution for object semantics combinations. Experiments on popular datasets show that the proposed method outperforms existing methods. Future work will include studying attention mechanisms to focus on specific visual emotion regions.



","Image sentiment analysis has become a hotspot in computer vision and attracts more attention . Most of the existing methods focus on identifying the emotions by studying complex models or robust features from the whole image . In this paper, we propose a novel object semantics sentiment correlation model (OSSCM), which is based on Bayesian network, to guide the image sentiment classification . Experiments on public emotion datasets FI and Flickr_LDL demonstrate that our proposed image sentiment analysis method can achieve good performance on image emotion analysis ",0.45962732919254656,0.12578616352201258,0.2608695652173913,0.03218975640368772
369,"The paper presents a method for identifying and classifying the polarity of implicit sentiment sentences that are conveyed through facts. The authors define implicit sentiment and propose a multi-level semantic feature fusion model that considers word-level sentiment, sentence-level implicit sentiment, and document-level context. The proposed method achieved high accuracy in identifying and classifying implicit sentiment polarity in two manually labeled datasets.","a multi-level semantic fusion method is proposed to learn the representation of fact-implied implicit sentiment at the sentence level . This paper focuses on the identification and polarity classification . We analyze in detail the characteristics of fact implied sentiment based on multi-Level semantic fused representation . The current studies on sentiment analysis focus on . the identification, context semantic background and context semantic . background representation at the document level. The proposed method achieved 74.2% and 70.3% in identification accuracy .",0.4657534246575342,0.125,0.30136986301369867,0.07834415817459346
370,"Based on the proposed framework, the sentiment classification of a given image can be summarized as follows. For a given image, salient objects are first generated. In order to reduce redundancy of salient objects for a single image, the candidate selection method is applied based on their sentiment scores and the best candidates are kept. Deep features are extracted using pretrained model and handcrafted features such as visual texture, complexity, colourfulness and Fourier Sigma are extracted by the described equations. All the features are classified individually and also combined with consistent weights. The feature vectors are classified using CNN classifier.  summarize the above text","Salient object based visual sentiment analysis by combining deep features and handcrafted features . First, the salient objects are identified from the entire images . Then a pre-trained model such as VGG16 is used to extract deep features from the images. The performance is measured using Convolutional Neural Network Classifier. The proposed method is tested on ArtPhoto, Emotion6, Abstract, IAPS datasets, Flickr and Flickr & Instagram datasets.",0.4497041420118343,0.11976047904191617,0.20118343195266272,0.024748973133154835
371,"The task of query-focused extractive multi-document text summarization involves generating a summary based on a user's query, while sentiment analysis and opinion mining involves analyzing the polarity and sentiment scores of sentences in a document collection. Combining these tasks results in a summary that includes the most relevant sentences for the user's query, with a similar sentiment orientation. This is known as query-focused sentiment-oriented extractive multi-document text summarization, which optimizes the criteria of query relevance, redundancy reduction, and sentiment relevance.","query-focused summarization consists of generating a summary from one or multiple documents according to a query given by the user . sentiment analysis and opinion mining analyze the polarity of the opinions contained in texts . This problem entails the optimization of different criteria, specifically, query relevance, redundancy reduction, and sentiment relevance . An adaptation of the metaheuristic population-based crow search algorithm has been designed, implemented, and tested to solve this multi-objective problem .",0.5,0.20253164556962022,0.35,0.1889111611999971
